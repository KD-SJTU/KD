{\rtf1\ansi\ansicpg936\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ssh://cx@202.120.36.29:22001/usr/share/anaconda3/bin/python3.6m -u /home/data2/rzf/KD/train_net.py\
\
\{'model': 'student', 'mode': '', 'date': '_907', 'lr': 0.01, 'batch_size': 64, 'epochs': 150, 'weight_decay': 0.0001, 'dataset': 'CUB', 'dataset_dir': '/home/data2/rzf/KD/dataset/CUB/', 'workers': 8, 'seed': 1, 'momentum': 0.9, 'gpu': 0, 'start_epoch': 0, 'print_freq': 30, 'classes': 200, 'logspace': True, 'epoch_step': 40, 'milestones': [50, 100], 'gama': 0.1, 'save_per_epoch': True, 'resume': '', 'pick_sample': False\}\
Time: 2019-09-07 00:06:45.495927\
Python: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \
[GCC 7.3.0]\
Numpy: 1.17.1\
Pytorch: 1.2.0\
lr logspace: [1.00000000e-02 9.54697470e-03 9.11447260e-03 8.70156393e-03\
 8.30736107e-03 7.93101660e-03 7.57172149e-03 7.22870335e-03\
 6.90122480e-03 6.58858186e-03 6.29010244e-03 6.00514488e-03\
 5.73309663e-03 5.47337285e-03 5.22541521e-03 4.98869069e-03\
 4.76269038e-03 4.54692846e-03 4.34094109e-03 4.14428548e-03\
 3.95653887e-03 3.77729765e-03 3.60617651e-03 3.44280759e-03\
 3.28683970e-03 3.13793754e-03 2.99578103e-03 2.86006458e-03\
 2.73049642e-03 2.60679802e-03 2.48870348e-03 2.37595891e-03\
 2.26832196e-03 2.16556124e-03 2.06745584e-03 1.97379486e-03\
 1.88437696e-03 1.79900992e-03 1.71751022e-03 1.63970266e-03\
 1.56541998e-03 1.49450249e-03 1.42679775e-03 1.36216020e-03\
 1.30045090e-03 1.24153719e-03 1.18529241e-03 1.13159567e-03\
 1.08033152e-03 1.03138977e-03 9.84665203e-04 9.40057378e-04\
 8.97470401e-04 8.56812721e-04 8.17996938e-04 7.80939607e-04\
 7.45561067e-04 7.11785265e-04 6.79539592e-04 6.48754729e-04\
 6.19364499e-04 5.91305720e-04 5.64518076e-04 5.38943979e-04\
 5.14528453e-04 4.91219013e-04 4.68965549e-04 4.47720223e-04\
 4.27437364e-04 4.08073370e-04 3.89586614e-04 3.71937355e-04\
 3.55087652e-04 3.39001283e-04 3.23643668e-04 3.08981791e-04\
 2.94984134e-04 2.81620607e-04 2.68862481e-04 2.56682330e-04\
 2.45053971e-04 2.33952406e-04 2.23353771e-04 2.13235280e-04\
 2.03575182e-04 1.94352711e-04 1.85548042e-04 1.77142246e-04\
 1.69117254e-04 1.61455815e-04 1.54141458e-04 1.47158460e-04\
 1.40491810e-04 1.34127175e-04 1.28050875e-04 1.22249846e-04\
 1.16711619e-04 1.11424288e-04 1.06376485e-04 1.01557362e-04\
 9.69565562e-05 9.25641789e-05 8.83707874e-05 8.43673672e-05\
 8.05453121e-05 7.68964057e-05 7.34128040e-05 7.00870182e-05\
 6.69118990e-05 6.38806207e-05 6.09866670e-05 5.82238167e-05\
 5.55861305e-05 5.30679382e-05 5.06638264e-05 4.83686269e-05\
 4.61774057e-05 4.40854524e-05 4.20882699e-05 4.01815648e-05\
 3.83612383e-05 3.66233771e-05 3.49642455e-05 3.33802767e-05\
 3.18680658e-05 3.04243618e-05 2.90460612e-05 2.77302012e-05\
 2.64739529e-05 2.52746159e-05 2.41296118e-05 2.30364794e-05\
 2.19928686e-05 2.09965360e-05 2.00453398e-05 1.91372352e-05\
 1.82702700e-05 1.74425806e-05 1.66523876e-05 1.58979923e-05\
 1.51777730e-05 1.44901815e-05 1.38337396e-05 1.32070362e-05\
 1.26087241e-05 1.20375170e-05 1.14921870e-05 1.09715619e-05\
 1.04745224e-05 1.00000000e-05]\
WARNING: Logging before flag parsing goes to stderr.\
W0907 00:06:52.725677 140657069471552 deprecation_wrapper.py:119] From /home/data2/rzf/KD/function/logger.py:16: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\
\
tensor(0., device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0., grad_fn=<SelectBackward>)\
lr: [0.01]\
Epoch: [0][0/94]	Time 1.850 (1.850)	Data 1.143 (1.143)	Loss 5.4956 (5.4956)	Acc@1 0.000 (0.000)	Acc@5 3.125 (3.125)\
Epoch: [0][30/94]	Time 0.072 (0.139)	Data 0.000 (0.046)	Loss 5.4059 (5.5954)	Acc@1 0.000 (0.504)	Acc@5 1.562 (2.520)\
Epoch: [0][60/94]	Time 0.080 (0.117)	Data 0.000 (0.040)	Loss 5.2759 (5.4578)	Acc@1 3.125 (0.692)	Acc@5 4.688 (3.484)\
Epoch: [0][90/94]	Time 0.070 (0.106)	Data 0.000 (0.030)	Loss 5.0029 (5.3558)	Acc@1 0.000 (0.893)	Acc@5 14.062 (4.602)\
 * Acc@1 0.901 Acc@5 4.688\
W0907 00:07:03.529659 140657069471552 deprecation_wrapper.py:119] From /home/data2/rzf/KD/function/logger.py:20: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\
\
Test: [0/91]	Time 1.190 (1.190)	Loss 4.9306 (4.9306)	Acc@1 1.562 (1.562)	Acc@5 12.500 (12.500)\
Test: [30/91]	Time 0.026 (0.109)	Loss 5.0068 (4.9470)	Acc@1 0.000 (1.764)	Acc@5 7.812 (11.290)\
Test: [60/91]	Time 0.079 (0.089)	Loss 4.9735 (4.9559)	Acc@1 1.562 (2.126)	Acc@5 3.125 (10.630)\
Test: [90/91]	Time 0.016 (0.077)	Loss 4.8989 (4.9612)	Acc@1 0.000 (2.226)	Acc@5 5.882 (10.425)\
 * Acc@1 2.226 Acc@5 10.425\
tensor(1.5624, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0014, grad_fn=<SelectBackward>)\
lr: [0.009546974703287525]\
Epoch: [1][0/94]	Time 1.788 (1.788)	Data 1.739 (1.739)	Loss 4.9613 (4.9613)	Acc@1 3.125 (3.125)	Acc@5 9.375 (9.375)\
Epoch: [1][30/94]	Time 0.226 (0.138)	Data 0.190 (0.064)	Loss 4.7387 (4.8820)	Acc@1 3.125 (2.772)	Acc@5 14.062 (12.802)\
Epoch: [1][60/94]	Time 0.072 (0.111)	Data 0.000 (0.042)	Loss 4.4929 (4.8490)	Acc@1 10.938 (3.099)	Acc@5 21.875 (12.987)\
Epoch: [1][90/94]	Time 0.071 (0.101)	Data 0.000 (0.030)	Loss 4.7613 (4.8175)	Acc@1 4.688 (3.262)	Acc@5 15.625 (13.633)\
 * Acc@1 3.270 Acc@5 13.614\
Test: [0/91]	Time 1.163 (1.163)	Loss 4.3739 (4.3739)	Acc@1 9.375 (9.375)	Acc@5 25.000 (25.000)\
Test: [30/91]	Time 0.032 (0.098)	Loss 4.5303 (4.4463)	Acc@1 3.125 (6.351)	Acc@5 20.312 (20.010)\
Test: [60/91]	Time 0.071 (0.084)	Loss 4.5179 (4.4649)	Acc@1 6.250 (6.352)	Acc@5 17.188 (20.108)\
Test: [90/91]	Time 0.015 (0.075)	Loss 4.5044 (4.4646)	Acc@1 0.000 (6.438)	Acc@5 17.647 (20.280)\
 * Acc@1 6.438 Acc@5 20.280\
tensor(1.7631, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0016, grad_fn=<SelectBackward>)\
lr: [0.009114472598521184]\
Epoch: [2][0/94]	Time 1.393 (1.393)	Data 1.353 (1.353)	Loss 4.5954 (4.5954)	Acc@1 3.125 (3.125)	Acc@5 20.312 (20.312)\
Epoch: [2][30/94]	Time 0.072 (0.129)	Data 0.023 (0.048)	Loss 4.4291 (4.4637)	Acc@1 12.500 (6.401)	Acc@5 23.438 (20.514)\
Epoch: [2][60/94]	Time 0.070 (0.104)	Data 0.000 (0.025)	Loss 4.2454 (4.4495)	Acc@1 6.250 (6.583)	Acc@5 20.312 (20.620)\
Epoch: [2][90/94]	Time 0.071 (0.096)	Data 0.000 (0.018)	Loss 4.4525 (4.4394)	Acc@1 3.125 (6.542)	Acc@5 18.750 (21.308)\
 * Acc@1 6.557 Acc@5 21.288\
Test: [0/91]	Time 1.123 (1.123)	Loss 4.2903 (4.2903)	Acc@1 10.938 (10.938)	Acc@5 21.875 (21.875)\
Test: [30/91]	Time 0.040 (0.111)	Loss 4.2020 (4.2178)	Acc@1 10.938 (8.669)	Acc@5 23.438 (24.950)\
Test: [60/91]	Time 0.028 (0.090)	Loss 4.1149 (4.2059)	Acc@1 12.500 (8.607)	Acc@5 31.250 (24.923)\
Test: [90/91]	Time 0.015 (0.078)	Loss 4.3223 (4.2073)	Acc@1 2.941 (8.630)	Acc@5 29.412 (25.388)\
 * Acc@1 8.630 Acc@5 25.388\
tensor(2.0071, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0018, grad_fn=<SelectBackward>)\
lr: [0.008701563933188907]\
Epoch: [3][0/94]	Time 1.272 (1.272)	Data 1.230 (1.230)	Loss 4.0772 (4.0772)	Acc@1 15.625 (15.625)	Acc@5 32.812 (32.812)\
Epoch: [3][30/94]	Time 0.073 (0.132)	Data 0.000 (0.060)	Loss 4.2182 (4.1514)	Acc@1 6.250 (8.821)	Acc@5 32.812 (29.637)\
Epoch: [3][60/94]	Time 0.078 (0.106)	Data 0.000 (0.032)	Loss 4.1152 (4.1674)	Acc@1 9.375 (8.940)	Acc@5 28.125 (28.432)\
Epoch: [3][90/94]	Time 0.072 (0.097)	Data 0.000 (0.023)	Loss 4.1145 (4.1450)	Acc@1 4.688 (9.341)	Acc@5 29.688 (28.726)\
 * Acc@1 9.459 Acc@5 28.862\
Test: [0/91]	Time 1.073 (1.073)	Loss 3.7739 (3.7739)	Acc@1 12.500 (12.500)	Acc@5 40.625 (40.625)\
Test: [30/91]	Time 0.035 (0.112)	Loss 4.1972 (3.9631)	Acc@1 9.375 (12.651)	Acc@5 20.312 (33.216)\
Test: [60/91]	Time 0.028 (0.093)	Loss 3.8745 (3.9889)	Acc@1 15.625 (12.218)	Acc@5 39.062 (32.326)\
Test: [90/91]	Time 0.015 (0.078)	Loss 3.9664 (3.9864)	Acc@1 8.824 (12.306)	Acc@5 32.353 (32.879)\
 * Acc@1 12.306 Acc@5 32.879\
tensor(2.2608, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0021, grad_fn=<SelectBackward>)\
lr: [0.00830736107491936]\
Epoch: [4][0/94]	Time 1.084 (1.084)	Data 1.043 (1.043)	Loss 3.9425 (3.9425)	Acc@1 12.500 (12.500)	Acc@5 34.375 (34.375)\
Epoch: [4][30/94]	Time 0.067 (0.119)	Data 0.000 (0.044)	Loss 3.7957 (3.9220)	Acc@1 12.500 (12.802)	Acc@5 39.062 (34.829)\
Epoch: [4][60/94]	Time 0.065 (0.100)	Data 0.000 (0.023)	Loss 3.5165 (3.9321)	Acc@1 15.625 (12.628)	Acc@5 39.062 (34.554)\
Epoch: [4][90/94]	Time 0.070 (0.092)	Data 0.000 (0.016)	Loss 3.9654 (3.8892)	Acc@1 10.938 (13.204)	Acc@5 31.250 (35.474)\
 * Acc@1 13.180 Acc@5 35.385\
Test: [0/91]	Time 1.163 (1.163)	Loss 3.8199 (3.8199)	Acc@1 15.625 (15.625)	Acc@5 39.062 (39.062)\
Test: [30/91]	Time 0.030 (0.100)	Loss 3.9445 (3.8161)	Acc@1 14.062 (14.315)	Acc@5 34.375 (37.601)\
Test: [60/91]	Time 0.032 (0.083)	Loss 4.0080 (3.8261)	Acc@1 12.500 (14.216)	Acc@5 37.500 (37.884)\
Test: [90/91]	Time 0.015 (0.071)	Loss 4.0925 (3.8050)	Acc@1 5.882 (14.653)	Acc@5 26.471 (38.281)\
 * Acc@1 14.653 Acc@5 38.281\
tensor(2.5215, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0023, grad_fn=<SelectBackward>)\
lr: [0.007931016603333051]\
Epoch: [5][0/94]	Time 1.466 (1.466)	Data 1.429 (1.429)	Loss 3.5582 (3.5582)	Acc@1 17.188 (17.188)	Acc@5 40.625 (40.625)\
Epoch: [5][30/94]	Time 0.076 (0.134)	Data 0.000 (0.064)	Loss 3.7646 (3.7013)	Acc@1 10.938 (15.625)	Acc@5 32.812 (39.970)\
Epoch: [5][60/94]	Time 0.072 (0.105)	Data 0.000 (0.033)	Loss 3.7649 (3.6731)	Acc@1 20.312 (16.240)	Acc@5 34.375 (41.240)\
Epoch: [5][90/94]	Time 0.071 (0.095)	Data 0.000 (0.023)	Loss 3.2150 (3.6750)	Acc@1 25.000 (15.951)	Acc@5 57.812 (40.642)\
 * Acc@1 15.966 Acc@5 40.607\
Test: [0/91]	Time 1.624 (1.624)	Loss 3.2346 (3.2346)	Acc@1 26.562 (26.562)	Acc@5 53.125 (53.125)\
Test: [30/91]	Time 0.030 (0.136)	Loss 3.6034 (3.5496)	Acc@1 25.000 (18.296)	Acc@5 39.062 (43.095)\
Test: [60/91]	Time 0.027 (0.110)	Loss 3.5957 (3.5640)	Acc@1 12.500 (17.956)	Acc@5 51.562 (42.956)\
Test: [90/91]	Time 0.015 (0.091)	Loss 3.4198 (3.5699)	Acc@1 23.529 (17.639)	Acc@5 38.235 (42.440)\
 * Acc@1 17.639 Acc@5 42.440\
tensor(2.7710, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0026, grad_fn=<SelectBackward>)\
lr: [0.0075717214883374]\
Epoch: [6][0/94]	Time 1.189 (1.189)	Data 1.111 (1.111)	Loss 3.4390 (3.4390)	Acc@1 20.312 (20.312)	Acc@5 43.750 (43.750)\
Epoch: [6][30/94]	Time 0.116 (0.140)	Data 0.070 (0.068)	Loss 3.5271 (3.3848)	Acc@1 26.562 (20.464)	Acc@5 45.312 (47.681)\
Epoch: [6][60/94]	Time 0.089 (0.115)	Data 0.029 (0.049)	Loss 3.7074 (3.4273)	Acc@1 12.500 (19.416)	Acc@5 45.312 (46.849)\
Epoch: [6][90/94]	Time 0.071 (0.104)	Data 0.000 (0.036)	Loss 3.4454 (3.4124)	Acc@1 21.875 (19.488)	Acc@5 48.438 (46.944)\
 * Acc@1 19.453 Acc@5 47.097\
Test: [0/91]	Time 1.211 (1.211)	Loss 3.2484 (3.2484)	Acc@1 20.312 (20.312)	Acc@5 46.875 (46.875)\
Test: [30/91]	Time 0.031 (0.108)	Loss 3.3076 (3.4162)	Acc@1 20.312 (22.228)	Acc@5 35.938 (45.817)\
Test: [60/91]	Time 0.060 (0.094)	Loss 3.2380 (3.4449)	Acc@1 23.438 (21.260)	Acc@5 54.688 (46.209)\
Test: [90/91]	Time 0.016 (0.087)	Loss 3.4464 (3.4639)	Acc@1 23.529 (21.194)	Acc@5 47.059 (45.961)\
 * Acc@1 21.194 Acc@5 45.961\
tensor(2.9959, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0028, grad_fn=<SelectBackward>)\
lr: [0.007228703350949573]\
Epoch: [7][0/94]	Time 1.120 (1.120)	Data 1.065 (1.065)	Loss 3.0344 (3.0344)	Acc@1 23.438 (23.438)	Acc@5 56.250 (56.250)\
Epoch: [7][30/94]	Time 0.062 (0.134)	Data 0.031 (0.063)	Loss 3.3904 (3.1219)	Acc@1 18.750 (25.202)	Acc@5 51.562 (53.276)\
Epoch: [7][60/94]	Time 0.076 (0.115)	Data 0.000 (0.045)	Loss 3.2264 (3.1416)	Acc@1 25.000 (25.128)	Acc@5 50.000 (53.125)\
Epoch: [7][90/94]	Time 0.071 (0.102)	Data 0.000 (0.031)	Loss 3.3009 (3.1801)	Acc@1 25.000 (24.227)	Acc@5 54.688 (52.679)\
 * Acc@1 24.258 Acc@5 52.669\
Test: [0/91]	Time 1.109 (1.109)	Loss 3.4567 (3.4567)	Acc@1 23.438 (23.438)	Acc@5 46.875 (46.875)\
Test: [30/91]	Time 0.044 (0.107)	Loss 3.1420 (3.2566)	Acc@1 28.125 (22.379)	Acc@5 56.250 (50.706)\
Test: [60/91]	Time 0.025 (0.096)	Loss 3.3676 (3.2725)	Acc@1 15.625 (22.848)	Acc@5 43.750 (50.692)\
Test: [90/91]	Time 0.015 (0.084)	Loss 3.1511 (3.2881)	Acc@1 23.529 (22.644)	Acc@5 44.118 (50.207)\
 * Acc@1 22.644 Acc@5 50.207\
tensor(3.2248, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0030, grad_fn=<SelectBackward>)\
lr: [0.006901224802908534]\
Epoch: [8][0/94]	Time 1.112 (1.112)	Data 1.078 (1.078)	Loss 2.7669 (2.7669)	Acc@1 29.688 (29.688)	Acc@5 67.188 (67.188)\
Epoch: [8][30/94]	Time 0.158 (0.138)	Data 0.121 (0.069)	Loss 3.0820 (2.9147)	Acc@1 26.562 (28.075)	Acc@5 59.375 (58.770)\
Epoch: [8][60/94]	Time 0.078 (0.113)	Data 0.000 (0.047)	Loss 2.8575 (2.9484)	Acc@1 25.000 (27.843)	Acc@5 60.938 (58.069)\
Epoch: [8][90/94]	Time 0.069 (0.100)	Data 0.000 (0.036)	Loss 2.8514 (2.9537)	Acc@1 20.312 (28.005)	Acc@5 65.625 (57.898)\
 * Acc@1 28.111 Acc@5 57.991\
Test: [0/91]	Time 1.111 (1.111)	Loss 3.0462 (3.0462)	Acc@1 26.562 (26.562)	Acc@5 53.125 (53.125)\
Test: [30/91]	Time 0.029 (0.111)	Loss 3.4553 (3.1870)	Acc@1 23.438 (25.605)	Acc@5 40.625 (52.218)\
Test: [60/91]	Time 0.127 (0.095)	Loss 2.9198 (3.2105)	Acc@1 31.250 (24.488)	Acc@5 59.375 (52.587)\
Test: [90/91]	Time 0.015 (0.086)	Loss 3.4723 (3.2229)	Acc@1 26.471 (24.336)	Acc@5 52.941 (52.641)\
 * Acc@1 24.336 Acc@5 52.641\
tensor(3.4332, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0032, grad_fn=<SelectBackward>)\
lr: [0.006588581861506815]\
Epoch: [9][0/94]	Time 1.110 (1.110)	Data 1.071 (1.071)	Loss 2.9048 (2.9048)	Acc@1 23.438 (23.438)	Acc@5 56.250 (56.250)\
Epoch: [9][30/94]	Time 0.073 (0.126)	Data 0.000 (0.050)	Loss 2.5587 (2.6740)	Acc@1 39.062 (33.669)	Acc@5 71.875 (65.675)\
Epoch: [9][60/94]	Time 0.080 (0.105)	Data 0.000 (0.035)	Loss 3.1217 (2.7298)	Acc@1 20.312 (31.685)	Acc@5 50.000 (63.166)\
Epoch: [9][90/94]	Time 0.071 (0.096)	Data 0.000 (0.024)	Loss 2.5911 (2.7267)	Acc@1 39.062 (32.040)	Acc@5 60.938 (63.290)\
 * Acc@1 32.099 Acc@5 63.514\
Test: [0/91]	Time 1.466 (1.466)	Loss 2.7102 (2.7102)	Acc@1 31.250 (31.250)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.029 (0.123)	Loss 3.1173 (3.0737)	Acc@1 26.562 (26.361)	Acc@5 56.250 (54.435)\
Test: [60/91]	Time 0.037 (0.105)	Loss 2.8531 (3.0822)	Acc@1 34.375 (27.177)	Acc@5 67.188 (54.585)\
Test: [90/91]	Time 0.015 (0.090)	Loss 2.5602 (3.0986)	Acc@1 29.412 (26.786)	Acc@5 55.882 (54.539)\
 * Acc@1 26.786 Acc@5 54.539\
tensor(3.6289, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0033, grad_fn=<SelectBackward>)\
lr: [0.00629010243623446]\
Epoch: [10][0/94]	Time 1.621 (1.621)	Data 1.568 (1.568)	Loss 2.3454 (2.3454)	Acc@1 39.062 (39.062)	Acc@5 68.750 (68.750)\
Epoch: [10][30/94]	Time 0.067 (0.130)	Data 0.000 (0.052)	Loss 2.3672 (2.4413)	Acc@1 37.500 (37.097)	Acc@5 70.312 (67.843)\
Epoch: [10][60/94]	Time 0.069 (0.107)	Data 0.000 (0.027)	Loss 2.4037 (2.4829)	Acc@1 40.625 (37.705)	Acc@5 73.438 (67.111)\
Epoch: [10][90/94]	Time 0.071 (0.097)	Data 0.000 (0.020)	Loss 2.0312 (2.4815)	Acc@1 50.000 (37.517)	Acc@5 75.000 (67.376)\
 * Acc@1 37.471 Acc@5 67.434\
Test: [0/91]	Time 1.644 (1.644)	Loss 3.0669 (3.0669)	Acc@1 25.000 (25.000)	Acc@5 51.562 (51.562)\
Test: [30/91]	Time 0.095 (0.122)	Loss 2.9998 (3.0234)	Acc@1 21.875 (27.117)	Acc@5 57.812 (55.998)\
Test: [60/91]	Time 0.086 (0.097)	Loss 2.9915 (3.0610)	Acc@1 29.688 (26.511)	Acc@5 64.062 (55.635)\
Test: [90/91]	Time 0.015 (0.082)	Loss 3.5230 (3.0708)	Acc@1 26.471 (26.769)	Acc@5 52.941 (55.627)\
 * Acc@1 26.769 Acc@5 55.627\
tensor(3.8060, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0035, grad_fn=<SelectBackward>)\
lr: [0.006005144883981762]\
Epoch: [11][0/94]	Time 1.379 (1.379)	Data 1.311 (1.311)	Loss 2.2549 (2.2549)	Acc@1 46.875 (46.875)	Acc@5 73.438 (73.438)\
Epoch: [11][30/94]	Time 0.075 (0.134)	Data 0.000 (0.062)	Loss 2.0433 (2.2123)	Acc@1 50.000 (42.893)	Acc@5 85.938 (74.647)\
Epoch: [11][60/94]	Time 0.080 (0.110)	Data 0.000 (0.040)	Loss 2.2364 (2.2297)	Acc@1 39.062 (41.906)	Acc@5 85.938 (73.950)\
Epoch: [11][90/94]	Time 0.072 (0.100)	Data 0.000 (0.029)	Loss 2.5823 (2.2547)	Acc@1 28.125 (40.591)	Acc@5 71.875 (73.712)\
 * Acc@1 40.557 Acc@5 73.757\
Test: [0/91]	Time 1.377 (1.377)	Loss 2.9662 (2.9662)	Acc@1 29.688 (29.688)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.317 (0.123)	Loss 2.7805 (2.9373)	Acc@1 31.250 (27.722)	Acc@5 62.500 (59.022)\
Test: [60/91]	Time 0.117 (0.103)	Loss 2.6805 (2.9279)	Acc@1 31.250 (29.303)	Acc@5 64.062 (59.324)\
Test: [90/91]	Time 0.016 (0.087)	Loss 2.7468 (2.9177)	Acc@1 29.412 (29.962)	Acc@5 58.824 (59.147)\
 * Acc@1 29.962 Acc@5 59.147\
tensor(3.9765, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0037, grad_fn=<SelectBackward>)\
lr: [0.005733096629695033]\
Epoch: [12][0/94]	Time 1.311 (1.311)	Data 1.261 (1.261)	Loss 2.1379 (2.1379)	Acc@1 43.750 (43.750)	Acc@5 75.000 (75.000)\
Epoch: [12][30/94]	Time 0.084 (0.134)	Data 0.000 (0.067)	Loss 2.2284 (1.9455)	Acc@1 45.312 (48.135)	Acc@5 78.125 (79.688)\
Epoch: [12][60/94]	Time 0.071 (0.112)	Data 0.026 (0.046)	Loss 2.0219 (1.9962)	Acc@1 39.062 (47.208)	Acc@5 78.125 (78.125)\
Epoch: [12][90/94]	Time 0.070 (0.101)	Data 0.000 (0.033)	Loss 1.9828 (2.0221)	Acc@1 46.875 (46.532)	Acc@5 76.562 (77.558)\
 * Acc@1 46.230 Acc@5 77.344\
Test: [0/91]	Time 1.133 (1.133)	Loss 2.8223 (2.8223)	Acc@1 34.375 (34.375)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.049 (0.110)	Loss 3.0573 (2.8792)	Acc@1 28.125 (31.250)	Acc@5 54.688 (60.786)\
Test: [60/91]	Time 0.032 (0.101)	Loss 3.6415 (2.8843)	Acc@1 17.188 (31.250)	Acc@5 46.875 (60.937)\
Test: [90/91]	Time 0.016 (0.087)	Loss 2.2672 (2.8836)	Acc@1 44.118 (31.101)	Acc@5 70.588 (60.632)\
 * Acc@1 31.101 Acc@5 60.632\
tensor(4.1257, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0038, grad_fn=<SelectBackward>)\
lr: [0.005473372849520145]\
Epoch: [13][0/94]	Time 1.086 (1.086)	Data 1.053 (1.053)	Loss 1.9578 (1.9578)	Acc@1 48.438 (48.438)	Acc@5 76.562 (76.562)\
Epoch: [13][30/94]	Time 0.076 (0.125)	Data 0.000 (0.048)	Loss 1.6691 (1.7289)	Acc@1 56.250 (53.730)	Acc@5 84.375 (83.468)\
Epoch: [13][60/94]	Time 0.082 (0.103)	Data 0.000 (0.025)	Loss 1.7412 (1.7616)	Acc@1 53.125 (52.587)	Acc@5 81.250 (82.223)\
Epoch: [13][90/94]	Time 0.071 (0.094)	Data 0.000 (0.019)	Loss 1.8070 (1.8121)	Acc@1 50.000 (51.150)	Acc@5 79.688 (81.782)\
 * Acc@1 51.151 Acc@5 81.732\
Test: [0/91]	Time 1.257 (1.257)	Loss 3.4011 (3.4011)	Acc@1 23.438 (23.438)	Acc@5 54.688 (54.688)\
Test: [30/91]	Time 0.040 (0.103)	Loss 3.5028 (2.9715)	Acc@1 18.750 (30.292)	Acc@5 45.312 (59.073)\
Test: [60/91]	Time 0.040 (0.089)	Loss 3.0765 (2.9597)	Acc@1 28.125 (30.815)	Acc@5 57.812 (60.041)\
Test: [90/91]	Time 0.015 (0.078)	Loss 2.8747 (2.9446)	Acc@1 20.588 (30.514)	Acc@5 61.765 (59.907)\
 * Acc@1 30.514 Acc@5 59.907\
tensor(4.2719, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0039, grad_fn=<SelectBackward>)\
lr: [0.005225415213602959]\
Epoch: [14][0/94]	Time 1.354 (1.354)	Data 1.310 (1.310)	Loss 1.6749 (1.6749)	Acc@1 51.562 (51.562)	Acc@5 85.938 (85.938)\
Epoch: [14][30/94]	Time 0.079 (0.124)	Data 0.000 (0.051)	Loss 1.3167 (1.5651)	Acc@1 64.062 (57.510)	Acc@5 89.062 (85.736)\
Epoch: [14][60/94]	Time 0.064 (0.102)	Data 0.031 (0.031)	Loss 1.2647 (1.5706)	Acc@1 62.500 (57.249)	Acc@5 89.062 (85.246)\
Epoch: [14][90/94]	Time 0.072 (0.093)	Data 0.000 (0.023)	Loss 1.5077 (1.5859)	Acc@1 60.938 (56.714)	Acc@5 82.812 (85.062)\
 * Acc@1 56.657 Acc@5 85.035\
Test: [0/91]	Time 1.542 (1.542)	Loss 2.8265 (2.8265)	Acc@1 34.375 (34.375)	Acc@5 54.688 (54.688)\
Test: [30/91]	Time 0.032 (0.103)	Loss 2.9592 (2.8521)	Acc@1 31.250 (32.308)	Acc@5 60.938 (62.450)\
Test: [60/91]	Time 0.026 (0.087)	Loss 2.9101 (2.8455)	Acc@1 28.125 (33.427)	Acc@5 57.812 (62.731)\
Test: [90/91]	Time 0.016 (0.078)	Loss 2.8154 (2.8377)	Acc@1 35.294 (33.466)	Acc@5 52.941 (62.772)\
 * Acc@1 33.466 Acc@5 62.772\
tensor(4.4051, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0041, grad_fn=<SelectBackward>)\
lr: [0.004988690685844118]\
Epoch: [15][0/94]	Time 1.416 (1.416)	Data 1.338 (1.338)	Loss 1.6698 (1.6698)	Acc@1 53.125 (53.125)	Acc@5 82.812 (82.812)\
Epoch: [15][30/94]	Time 0.088 (0.123)	Data 0.000 (0.047)	Loss 1.5623 (1.3789)	Acc@1 56.250 (61.694)	Acc@5 82.812 (88.306)\
Epoch: [15][60/94]	Time 0.088 (0.101)	Data 0.015 (0.025)	Loss 1.4359 (1.3528)	Acc@1 65.625 (62.193)	Acc@5 81.250 (88.729)\
Epoch: [15][90/94]	Time 0.072 (0.093)	Data 0.000 (0.018)	Loss 1.3265 (1.3823)	Acc@1 60.938 (61.538)	Acc@5 92.188 (88.633)\
 * Acc@1 61.512 Acc@5 88.539\
Test: [0/91]	Time 1.073 (1.073)	Loss 2.7148 (2.7148)	Acc@1 37.500 (37.500)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.032 (0.121)	Loss 3.5089 (2.8778)	Acc@1 17.188 (34.627)	Acc@5 64.062 (62.802)\
Test: [60/91]	Time 0.028 (0.105)	Loss 2.8601 (2.8583)	Acc@1 32.812 (34.785)	Acc@5 62.500 (63.422)\
Test: [90/91]	Time 0.016 (0.090)	Loss 3.1480 (2.8488)	Acc@1 26.471 (34.363)	Acc@5 47.059 (63.618)\
 * Acc@1 34.363 Acc@5 63.618\
tensor(4.5180, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0042, grad_fn=<SelectBackward>)\
lr: [0.004762690378027989]\
Epoch: [16][0/94]	Time 1.285 (1.285)	Data 1.239 (1.239)	Loss 1.1873 (1.1873)	Acc@1 70.312 (70.312)	Acc@5 85.938 (85.938)\
Epoch: [16][30/94]	Time 0.074 (0.135)	Data 0.000 (0.060)	Loss 1.2933 (1.1702)	Acc@1 67.188 (66.683)	Acc@5 95.312 (91.532)\
Epoch: [16][60/94]	Time 0.079 (0.110)	Data 0.000 (0.038)	Loss 1.1627 (1.2220)	Acc@1 67.188 (65.343)	Acc@5 92.188 (90.574)\
Epoch: [16][90/94]	Time 0.081 (0.100)	Data 0.000 (0.028)	Loss 1.3219 (1.2424)	Acc@1 68.750 (64.715)	Acc@5 84.375 (90.436)\
 * Acc@1 64.815 Acc@5 90.440\
Test: [0/91]	Time 1.146 (1.146)	Loss 3.1465 (3.1465)	Acc@1 29.688 (29.688)	Acc@5 51.562 (51.562)\
Test: [30/91]	Time 0.026 (0.122)	Loss 2.3412 (2.7426)	Acc@1 45.312 (35.534)	Acc@5 70.312 (64.214)\
Test: [60/91]	Time 0.072 (0.095)	Loss 2.9108 (2.7405)	Acc@1 29.688 (35.502)	Acc@5 64.062 (64.857)\
Test: [90/91]	Time 0.015 (0.081)	Loss 2.6265 (2.7597)	Acc@1 32.353 (35.571)	Acc@5 67.647 (64.394)\
 * Acc@1 35.571 Acc@5 64.394\
tensor(4.6255, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0043, grad_fn=<SelectBackward>)\
lr: [0.004546928455862411]\
Epoch: [17][0/94]	Time 1.166 (1.166)	Data 1.133 (1.133)	Loss 1.1826 (1.1826)	Acc@1 62.500 (62.500)	Acc@5 90.625 (90.625)\
Epoch: [17][30/94]	Time 0.076 (0.124)	Data 0.000 (0.049)	Loss 0.9994 (0.9848)	Acc@1 78.125 (71.573)	Acc@5 92.188 (94.506)\
Epoch: [17][60/94]	Time 0.069 (0.098)	Data 0.000 (0.026)	Loss 1.1174 (1.0282)	Acc@1 68.750 (70.133)	Acc@5 89.062 (93.904)\
Epoch: [17][90/94]	Time 0.072 (0.089)	Data 0.000 (0.018)	Loss 0.9177 (1.0564)	Acc@1 68.750 (69.368)	Acc@5 93.750 (93.286)\
 * Acc@1 69.403 Acc@5 93.243\
Test: [0/91]	Time 1.515 (1.515)	Loss 2.9276 (2.9276)	Acc@1 29.688 (29.688)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.028 (0.103)	Loss 3.1138 (2.7864)	Acc@1 31.250 (35.887)	Acc@5 64.062 (65.020)\
Test: [60/91]	Time 0.027 (0.086)	Loss 3.2571 (2.7968)	Acc@1 34.375 (34.887)	Acc@5 51.562 (64.088)\
Test: [90/91]	Time 0.015 (0.078)	Loss 3.5568 (2.7806)	Acc@1 32.353 (35.295)	Acc@5 50.000 (64.360)\
 * Acc@1 35.295 Acc@5 64.360\
tensor(4.7186, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0043, grad_fn=<SelectBackward>)\
lr: [0.004340941094577661]\
Epoch: [18][0/94]	Time 1.511 (1.511)	Data 1.476 (1.476)	Loss 0.8702 (0.8702)	Acc@1 75.000 (75.000)	Acc@5 92.188 (92.188)\
Epoch: [18][30/94]	Time 0.062 (0.125)	Data 0.000 (0.050)	Loss 0.9572 (0.9249)	Acc@1 71.875 (73.286)	Acc@5 92.188 (94.859)\
Epoch: [18][60/94]	Time 0.064 (0.101)	Data 0.000 (0.026)	Loss 0.9985 (0.9078)	Acc@1 76.562 (74.001)	Acc@5 95.312 (94.800)\
Epoch: [18][90/94]	Time 0.070 (0.092)	Data 0.000 (0.018)	Loss 1.1158 (0.9338)	Acc@1 67.188 (73.094)	Acc@5 92.188 (94.385)\
 * Acc@1 73.073 Acc@5 94.428\
Test: [0/91]	Time 1.347 (1.347)	Loss 3.4125 (3.4125)	Acc@1 25.000 (25.000)	Acc@5 50.000 (50.000)\
Test: [30/91]	Time 0.028 (0.096)	Loss 3.1511 (2.8154)	Acc@1 31.250 (36.341)	Acc@5 68.750 (64.315)\
Test: [60/91]	Time 0.028 (0.084)	Loss 2.9330 (2.8526)	Acc@1 31.250 (36.296)	Acc@5 59.375 (64.191)\
Test: [90/91]	Time 0.016 (0.076)	Loss 2.5437 (2.8521)	Acc@1 35.294 (35.951)	Acc@5 73.529 (64.135)\
 * Acc@1 35.951 Acc@5 64.135\
tensor(4.8015, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0044, grad_fn=<SelectBackward>)\
lr: [0.004144285481839419]\
Epoch: [19][0/94]	Time 1.198 (1.198)	Data 1.170 (1.170)	Loss 0.7618 (0.7618)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)\
Epoch: [19][30/94]	Time 0.082 (0.125)	Data 0.000 (0.057)	Loss 0.6430 (0.7358)	Acc@1 75.000 (78.881)	Acc@5 96.875 (97.379)\
Epoch: [19][60/94]	Time 0.076 (0.104)	Data 0.000 (0.030)	Loss 0.8027 (0.7662)	Acc@1 76.562 (77.664)	Acc@5 100.000 (96.747)\
Epoch: [19][90/94]	Time 0.070 (0.093)	Data 0.000 (0.021)	Loss 0.7402 (0.7655)	Acc@1 82.812 (77.455)	Acc@5 96.875 (96.841)\
 * Acc@1 77.361 Acc@5 96.713\
Test: [0/91]	Time 1.489 (1.489)	Loss 2.9798 (2.9798)	Acc@1 39.062 (39.062)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.027 (0.128)	Loss 2.4603 (2.9284)	Acc@1 45.312 (37.147)	Acc@5 68.750 (64.365)\
Test: [60/91]	Time 0.076 (0.105)	Loss 2.8541 (2.8993)	Acc@1 39.062 (36.578)	Acc@5 68.750 (65.164)\
Test: [90/91]	Time 0.012 (0.091)	Loss 2.6447 (2.9087)	Acc@1 44.118 (37.021)	Acc@5 61.765 (65.361)\
 * Acc@1 37.021 Acc@5 65.361\
tensor(4.8752, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0045, grad_fn=<SelectBackward>)\
lr: [0.003956538865832269]\
Epoch: [20][0/94]	Time 1.357 (1.357)	Data 1.334 (1.334)	Loss 0.5992 (0.5992)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)\
Epoch: [20][30/94]	Time 0.076 (0.127)	Data 0.000 (0.056)	Loss 0.7892 (0.6383)	Acc@1 75.000 (81.099)	Acc@5 96.875 (97.530)\
Epoch: [20][60/94]	Time 0.079 (0.104)	Data 0.000 (0.038)	Loss 0.5573 (0.6654)	Acc@1 84.375 (80.456)	Acc@5 100.000 (97.592)\
Epoch: [20][90/94]	Time 0.062 (0.096)	Data 0.000 (0.031)	Loss 0.7249 (0.6803)	Acc@1 73.438 (80.117)	Acc@5 98.438 (97.304)\
 * Acc@1 80.080 Acc@5 97.281\
Test: [0/91]	Time 1.574 (1.574)	Loss 2.7591 (2.7591)	Acc@1 37.500 (37.500)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.019 (0.115)	Loss 3.0525 (2.8162)	Acc@1 37.500 (38.105)	Acc@5 62.500 (66.734)\
Test: [60/91]	Time 0.027 (0.093)	Loss 3.1235 (2.9617)	Acc@1 29.688 (36.501)	Acc@5 65.625 (65.266)\
Test: [90/91]	Time 0.012 (0.083)	Loss 3.5171 (2.9499)	Acc@1 23.529 (36.935)	Acc@5 55.882 (65.378)\
 * Acc@1 36.935 Acc@5 65.378\
tensor(4.9407, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0045, grad_fn=<SelectBackward>)\
lr: [0.003777297646467455]\
Epoch: [21][0/94]	Time 1.268 (1.268)	Data 1.226 (1.226)	Loss 0.5196 (0.5196)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)\
Epoch: [21][30/94]	Time 0.070 (0.124)	Data 0.000 (0.051)	Loss 0.9231 (0.5738)	Acc@1 75.000 (83.569)	Acc@5 95.312 (97.833)\
Epoch: [21][60/94]	Time 0.076 (0.103)	Data 0.027 (0.031)	Loss 0.2841 (0.5584)	Acc@1 93.750 (83.965)	Acc@5 98.438 (98.028)\
Epoch: [21][90/94]	Time 0.069 (0.097)	Data 0.000 (0.028)	Loss 0.7067 (0.5646)	Acc@1 81.250 (83.705)	Acc@5 98.438 (98.025)\
 * Acc@1 83.617 Acc@5 97.965\
Test: [0/91]	Time 1.104 (1.104)	Loss 2.8563 (2.8563)	Acc@1 37.500 (37.500)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.029 (0.119)	Loss 3.0184 (2.8748)	Acc@1 42.188 (38.508)	Acc@5 59.375 (65.827)\
Test: [60/91]	Time 0.024 (0.100)	Loss 2.2950 (2.9470)	Acc@1 43.750 (37.423)	Acc@5 75.000 (64.933)\
Test: [90/91]	Time 0.031 (0.084)	Loss 3.7394 (2.9228)	Acc@1 32.353 (37.228)	Acc@5 64.706 (65.154)\
 * Acc@1 37.228 Acc@5 65.154\
tensor(4.9983, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0046, grad_fn=<SelectBackward>)\
lr: [0.0036061765077612298]\
Epoch: [22][0/94]	Time 1.494 (1.494)	Data 1.447 (1.447)	Loss 0.5534 (0.5534)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)\
Epoch: [22][30/94]	Time 0.069 (0.123)	Data 0.000 (0.056)	Loss 0.4674 (0.5129)	Acc@1 87.500 (84.627)	Acc@5 98.438 (98.387)\
Epoch: [22][60/94]	Time 0.091 (0.108)	Data 0.000 (0.043)	Loss 0.5032 (0.5064)	Acc@1 82.812 (85.143)	Acc@5 100.000 (98.489)\
Epoch: [22][90/94]	Time 0.065 (0.099)	Data 0.000 (0.036)	Loss 0.6372 (0.5006)	Acc@1 81.250 (85.302)	Acc@5 96.875 (98.352)\
 * Acc@1 85.385 Acc@5 98.348\
Test: [0/91]	Time 1.103 (1.103)	Loss 3.1166 (3.1166)	Acc@1 37.500 (37.500)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.421 (0.107)	Loss 2.8010 (2.9069)	Acc@1 42.188 (36.996)	Acc@5 65.625 (64.516)\
Test: [60/91]	Time 0.032 (0.095)	Loss 2.8900 (2.8565)	Acc@1 32.812 (37.628)	Acc@5 70.312 (65.574)\
Test: [90/91]	Time 0.012 (0.088)	Loss 3.7773 (2.8639)	Acc@1 26.471 (37.608)	Acc@5 52.941 (65.965)\
 * Acc@1 37.608 Acc@5 65.965\
tensor(5.0504, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0046, grad_fn=<SelectBackward>)\
lr: [0.003442807589518621]\
Epoch: [23][0/94]	Time 1.083 (1.083)	Data 1.030 (1.030)	Loss 0.4065 (0.4065)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)\
Epoch: [23][30/94]	Time 0.120 (0.136)	Data 0.068 (0.072)	Loss 0.2961 (0.4140)	Acc@1 92.188 (87.349)	Acc@5 100.000 (99.194)\
Epoch: [23][60/94]	Time 0.068 (0.109)	Data 0.000 (0.043)	Loss 0.4019 (0.4164)	Acc@1 92.188 (87.346)	Acc@5 98.438 (99.027)\
Epoch: [23][90/94]	Time 0.065 (0.099)	Data 0.000 (0.034)	Loss 0.2627 (0.4154)	Acc@1 95.312 (87.517)	Acc@5 100.000 (98.953)\
 * Acc@1 87.588 Acc@5 98.966\
Test: [0/91]	Time 1.395 (1.395)	Loss 2.8057 (2.8057)	Acc@1 45.312 (45.312)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.039 (0.125)	Loss 2.7859 (2.8799)	Acc@1 39.062 (37.198)	Acc@5 65.625 (66.280)\
Test: [60/91]	Time 0.054 (0.100)	Loss 2.5935 (2.8845)	Acc@1 34.375 (37.551)	Acc@5 73.438 (65.830)\
Test: [90/91]	Time 0.012 (0.089)	Loss 2.2760 (2.8882)	Acc@1 52.941 (37.383)	Acc@5 70.588 (66.241)\
 * Acc@1 37.383 Acc@5 66.241\
tensor(5.0913, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0047, grad_fn=<SelectBackward>)\
lr: [0.0032868396965420547]\
Epoch: [24][0/94]	Time 1.124 (1.124)	Data 1.080 (1.080)	Loss 0.3962 (0.3962)	Acc@1 89.062 (89.062)	Acc@5 96.875 (96.875)\
Epoch: [24][30/94]	Time 0.072 (0.125)	Data 0.000 (0.056)	Loss 0.4325 (0.3552)	Acc@1 84.375 (90.020)	Acc@5 100.000 (99.395)\
Epoch: [24][60/94]	Time 0.066 (0.111)	Data 0.000 (0.047)	Loss 0.3242 (0.3569)	Acc@1 89.062 (89.754)	Acc@5 100.000 (99.232)\
Epoch: [24][90/94]	Time 0.066 (0.099)	Data 0.000 (0.034)	Loss 0.3448 (0.3615)	Acc@1 85.938 (89.526)	Acc@5 100.000 (99.210)\
 * Acc@1 89.540 Acc@5 99.233\
Test: [0/91]	Time 1.123 (1.123)	Loss 3.1258 (3.1258)	Acc@1 40.625 (40.625)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.031 (0.125)	Loss 3.2464 (3.0802)	Acc@1 31.250 (36.593)	Acc@5 67.188 (65.827)\
Test: [60/91]	Time 0.123 (0.105)	Loss 2.7271 (3.0462)	Acc@1 46.875 (37.577)	Acc@5 70.312 (65.984)\
Test: [90/91]	Time 0.015 (0.091)	Loss 2.4948 (3.0024)	Acc@1 41.176 (38.091)	Acc@5 73.529 (66.344)\
 * Acc@1 38.091 Acc@5 66.344\
tensor(5.1277, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0047, grad_fn=<SelectBackward>)\
lr: [0.003137937543664824]\
Epoch: [25][0/94]	Time 0.834 (0.834)	Data 0.801 (0.801)	Loss 0.3134 (0.3134)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)\
Epoch: [25][30/94]	Time 0.075 (0.114)	Data 0.000 (0.050)	Loss 0.2608 (0.3133)	Acc@1 92.188 (90.272)	Acc@5 98.438 (99.597)\
Epoch: [25][60/94]	Time 0.067 (0.100)	Data 0.000 (0.036)	Loss 0.4300 (0.3115)	Acc@1 85.938 (90.702)	Acc@5 96.875 (99.513)\
Epoch: [25][90/94]	Time 0.065 (0.095)	Data 0.000 (0.031)	Loss 0.4759 (0.3241)	Acc@1 84.375 (90.213)	Acc@5 98.438 (99.416)\
 * Acc@1 90.224 Acc@5 99.399\
Test: [0/91]	Time 1.566 (1.566)	Loss 3.1152 (3.1152)	Acc@1 35.938 (35.938)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.019 (0.123)	Loss 2.7933 (2.9934)	Acc@1 39.062 (37.046)	Acc@5 65.625 (66.230)\
Test: [60/91]	Time 0.019 (0.106)	Loss 2.2961 (2.9623)	Acc@1 50.000 (38.115)	Acc@5 76.562 (66.778)\
Test: [90/91]	Time 0.012 (0.092)	Loss 3.6950 (2.9188)	Acc@1 26.471 (38.574)	Acc@5 52.941 (66.741)\
 * Acc@1 38.574 Acc@5 66.741\
tensor(5.1558, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0047, grad_fn=<SelectBackward>)\
lr: [0.0029957810349864273]\
Epoch: [26][0/94]	Time 1.193 (1.193)	Data 1.138 (1.138)	Loss 0.1660 (0.1660)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)\
Epoch: [26][30/94]	Time 0.074 (0.119)	Data 0.000 (0.048)	Loss 0.3377 (0.2756)	Acc@1 92.188 (92.288)	Acc@5 96.875 (99.647)\
Epoch: [26][60/94]	Time 0.078 (0.099)	Data 0.000 (0.031)	Loss 0.2924 (0.2739)	Acc@1 89.062 (92.136)	Acc@5 100.000 (99.641)\
Epoch: [26][90/94]	Time 0.065 (0.091)	Data 0.000 (0.022)	Loss 0.2656 (0.2809)	Acc@1 93.750 (91.981)	Acc@5 100.000 (99.605)\
 * Acc@1 91.992 Acc@5 99.616\
Test: [0/91]	Time 1.088 (1.088)	Loss 2.6959 (2.6959)	Acc@1 35.938 (35.938)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.022 (0.116)	Loss 4.2491 (2.9379)	Acc@1 18.750 (38.861)	Acc@5 46.875 (67.087)\
Test: [60/91]	Time 0.043 (0.097)	Loss 3.2764 (2.9709)	Acc@1 39.062 (39.088)	Acc@5 68.750 (67.520)\
Test: [90/91]	Time 0.012 (0.085)	Loss 3.4765 (2.9962)	Acc@1 41.176 (39.109)	Acc@5 61.765 (66.897)\
 * Acc@1 39.109 Acc@5 66.897\
tensor(5.1814, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0048, grad_fn=<SelectBackward>)\
lr: [0.0028600645757603915]\
Epoch: [27][0/94]	Time 1.134 (1.134)	Data 1.083 (1.083)	Loss 0.2308 (0.2308)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)\
Epoch: [27][30/94]	Time 0.082 (0.132)	Data 0.000 (0.063)	Loss 0.1502 (0.2363)	Acc@1 100.000 (94.052)	Acc@5 100.000 (99.698)\
Epoch: [27][60/94]	Time 0.059 (0.112)	Data 0.000 (0.048)	Loss 0.2318 (0.2376)	Acc@1 96.875 (93.673)	Acc@5 100.000 (99.718)\
Epoch: [27][90/94]	Time 0.066 (0.099)	Data 0.000 (0.034)	Loss 0.2373 (0.2352)	Acc@1 95.312 (93.750)	Acc@5 100.000 (99.674)\
 * Acc@1 93.744 Acc@5 99.683\
Test: [0/91]	Time 1.568 (1.568)	Loss 3.4121 (3.4121)	Acc@1 40.625 (40.625)	Acc@5 59.375 (59.375)\
Test: [30/91]	Time 0.021 (0.108)	Loss 3.2446 (3.0911)	Acc@1 45.312 (38.306)	Acc@5 67.188 (65.726)\
Test: [60/91]	Time 0.039 (0.093)	Loss 2.7566 (3.0511)	Acc@1 46.875 (37.782)	Acc@5 71.875 (66.137)\
Test: [90/91]	Time 0.015 (0.082)	Loss 3.7929 (3.0366)	Acc@1 32.353 (38.574)	Acc@5 55.882 (66.707)\
 * Acc@1 38.574 Acc@5 66.707\
tensor(5.2041, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0048, grad_fn=<SelectBackward>)\
lr: [0.0027304964154553227]\
Epoch: [28][0/94]	Time 1.258 (1.258)	Data 1.213 (1.213)	Loss 0.3385 (0.3385)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)\
Epoch: [28][30/94]	Time 0.070 (0.115)	Data 0.000 (0.042)	Loss 0.3195 (0.2265)	Acc@1 92.188 (93.851)	Acc@5 100.000 (99.698)\
Epoch: [28][60/94]	Time 0.068 (0.097)	Data 0.000 (0.025)	Loss 0.3487 (0.2148)	Acc@1 93.750 (94.057)	Acc@5 98.438 (99.744)\
Epoch: [28][90/94]	Time 0.066 (0.092)	Data 0.000 (0.024)	Loss 0.1311 (0.2148)	Acc@1 96.875 (94.128)	Acc@5 100.000 (99.742)\
 * Acc@1 94.077 Acc@5 99.733\
Test: [0/91]	Time 1.137 (1.137)	Loss 2.6424 (2.6424)	Acc@1 40.625 (40.625)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.028 (0.106)	Loss 2.8276 (2.9464)	Acc@1 40.625 (40.222)	Acc@5 68.750 (67.288)\
Test: [60/91]	Time 0.020 (0.095)	Loss 3.3021 (3.0255)	Acc@1 32.812 (39.139)	Acc@5 64.062 (66.573)\
Test: [90/91]	Time 0.016 (0.084)	Loss 2.3251 (2.9617)	Acc@1 44.118 (39.351)	Acc@5 79.412 (67.656)\
 * Acc@1 39.351 Acc@5 67.656\
tensor(5.2211, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0048, grad_fn=<SelectBackward>)\
lr: [0.002606798020576923]\
Epoch: [29][0/94]	Time 1.431 (1.431)	Data 1.402 (1.402)	Loss 0.1911 (0.1911)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)\
Epoch: [29][30/94]	Time 0.074 (0.138)	Data 0.002 (0.078)	Loss 0.3056 (0.1989)	Acc@1 87.500 (94.153)	Acc@5 100.000 (99.748)\
Epoch: [29][60/94]	Time 0.083 (0.107)	Data 0.000 (0.040)	Loss 0.2287 (0.2006)	Acc@1 92.188 (94.416)	Acc@5 100.000 (99.795)\
Epoch: [29][90/94]	Time 0.065 (0.097)	Data 0.000 (0.031)	Loss 0.3792 (0.2096)	Acc@1 89.062 (94.145)	Acc@5 100.000 (99.828)\
 * Acc@1 94.194 Acc@5 99.816\
Test: [0/91]	Time 1.385 (1.385)	Loss 3.0023 (3.0023)	Acc@1 40.625 (40.625)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.028 (0.114)	Loss 2.9770 (2.9795)	Acc@1 43.750 (40.020)	Acc@5 71.875 (67.893)\
Test: [60/91]	Time 0.110 (0.107)	Loss 3.0632 (3.0090)	Acc@1 35.938 (39.216)	Acc@5 70.312 (67.597)\
Test: [90/91]	Time 0.012 (0.093)	Loss 2.6251 (2.9616)	Acc@1 44.118 (39.368)	Acc@5 70.588 (67.932)\
 * Acc@1 39.368 Acc@5 67.932\
tensor(5.2375, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0048, grad_fn=<SelectBackward>)\
lr: [0.002488703475902785]\
Epoch: [30][0/94]	Time 1.367 (1.367)	Data 1.338 (1.338)	Loss 0.1500 (0.1500)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [30][30/94]	Time 0.078 (0.120)	Data 0.000 (0.052)	Loss 0.2035 (0.1866)	Acc@1 95.312 (95.111)	Acc@5 100.000 (99.899)\
Epoch: [30][60/94]	Time 0.084 (0.108)	Data 0.016 (0.043)	Loss 0.1894 (0.1921)	Acc@1 93.750 (94.826)	Acc@5 100.000 (99.923)\
Epoch: [30][90/94]	Time 0.079 (0.103)	Data 0.056 (0.041)	Loss 0.2176 (0.1940)	Acc@1 95.312 (94.660)	Acc@5 100.000 (99.948)\
 * Acc@1 94.678 Acc@5 99.950\
Test: [0/91]	Time 1.249 (1.249)	Loss 2.4232 (2.4232)	Acc@1 48.438 (48.438)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.019 (0.111)	Loss 2.6976 (2.9100)	Acc@1 43.750 (41.331)	Acc@5 67.188 (68.196)\
Test: [60/91]	Time 0.115 (0.099)	Loss 3.1687 (2.9739)	Acc@1 32.812 (40.343)	Acc@5 68.750 (67.853)\
Test: [90/91]	Time 0.041 (0.092)	Loss 2.1974 (3.0025)	Acc@1 61.765 (40.231)	Acc@5 76.471 (67.397)\
 * Acc@1 40.231 Acc@5 67.397\
tensor(5.2528, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0048, grad_fn=<SelectBackward>)\
lr: [0.002375958912842763]\
Epoch: [31][0/94]	Time 1.087 (1.087)	Data 1.054 (1.054)	Loss 0.2376 (0.2376)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)\
Epoch: [31][30/94]	Time 0.078 (0.134)	Data 0.000 (0.068)	Loss 0.1643 (0.1741)	Acc@1 95.312 (95.565)	Acc@5 100.000 (99.798)\
Epoch: [31][60/94]	Time 0.078 (0.110)	Data 0.000 (0.043)	Loss 0.2302 (0.1676)	Acc@1 92.188 (95.748)	Acc@5 100.000 (99.846)\
Epoch: [31][90/94]	Time 0.065 (0.097)	Data 0.000 (0.029)	Loss 0.1757 (0.1643)	Acc@1 93.750 (95.639)	Acc@5 100.000 (99.863)\
 * Acc@1 95.729 Acc@5 99.867\
Test: [0/91]	Time 1.411 (1.411)	Loss 2.7492 (2.7492)	Acc@1 35.938 (35.938)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.076 (0.100)	Loss 2.5288 (3.0533)	Acc@1 45.312 (39.768)	Acc@5 73.438 (65.927)\
Test: [60/91]	Time 0.019 (0.082)	Loss 3.3029 (3.0212)	Acc@1 31.250 (39.677)	Acc@5 62.500 (66.829)\
Test: [90/91]	Time 0.016 (0.075)	Loss 2.6121 (3.0267)	Acc@1 47.059 (40.024)	Acc@5 76.471 (67.035)\
 * Acc@1 40.024 Acc@5 67.035\
tensor(5.2636, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0048, grad_fn=<SelectBackward>)\
lr: [0.0022683219636960386]\
Epoch: [32][0/94]	Time 1.092 (1.092)	Data 1.046 (1.046)	Loss 0.0972 (0.0972)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [32][30/94]	Time 0.082 (0.119)	Data 0.000 (0.049)	Loss 0.1601 (0.1419)	Acc@1 93.750 (96.421)	Acc@5 100.000 (100.000)\
Epoch: [32][60/94]	Time 0.073 (0.097)	Data 0.004 (0.026)	Loss 0.2583 (0.1435)	Acc@1 92.188 (96.260)	Acc@5 100.000 (100.000)\
Epoch: [32][90/94]	Time 0.065 (0.089)	Data 0.000 (0.018)	Loss 0.1984 (0.1441)	Acc@1 95.312 (96.102)	Acc@5 100.000 (99.983)\
 * Acc@1 96.079 Acc@5 99.983\
Test: [0/91]	Time 1.418 (1.418)	Loss 3.2237 (3.2237)	Acc@1 40.625 (40.625)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.019 (0.103)	Loss 3.5396 (2.9635)	Acc@1 45.312 (41.331)	Acc@5 64.062 (67.944)\
Test: [60/91]	Time 0.027 (0.087)	Loss 2.8807 (3.0583)	Acc@1 37.500 (40.190)	Acc@5 64.062 (67.059)\
Test: [90/91]	Time 0.016 (0.074)	Loss 3.3413 (3.0326)	Acc@1 35.294 (40.421)	Acc@5 73.529 (67.466)\
 * Acc@1 40.421 Acc@5 67.466\
tensor(5.2730, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0021655612406317566]\
Epoch: [33][0/94]	Time 1.105 (1.105)	Data 1.070 (1.070)	Loss 0.0837 (0.0837)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [33][30/94]	Time 0.077 (0.124)	Data 0.000 (0.051)	Loss 0.1404 (0.1280)	Acc@1 95.312 (96.522)	Acc@5 100.000 (99.899)\
Epoch: [33][60/94]	Time 0.061 (0.099)	Data 0.000 (0.028)	Loss 0.1377 (0.1216)	Acc@1 96.875 (96.747)	Acc@5 100.000 (99.949)\
Epoch: [33][90/94]	Time 0.066 (0.090)	Data 0.000 (0.019)	Loss 0.1202 (0.1302)	Acc@1 96.875 (96.566)	Acc@5 100.000 (99.931)\
 * Acc@1 96.530 Acc@5 99.933\
Test: [0/91]	Time 1.147 (1.147)	Loss 3.6068 (3.6068)	Acc@1 39.062 (39.062)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.030 (0.101)	Loss 3.1469 (3.0760)	Acc@1 35.938 (40.474)	Acc@5 62.500 (67.238)\
Test: [60/91]	Time 0.318 (0.093)	Loss 3.7884 (3.0346)	Acc@1 39.062 (40.574)	Acc@5 60.938 (68.135)\
Test: [90/91]	Time 0.012 (0.081)	Loss 3.3637 (3.0715)	Acc@1 38.235 (40.024)	Acc@5 58.824 (67.673)\
 * Acc@1 40.024 Acc@5 67.673\
tensor(5.2820, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.002067455838273133]\
Epoch: [34][0/94]	Time 1.291 (1.291)	Data 1.254 (1.254)	Loss 0.0511 (0.0511)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [34][30/94]	Time 0.064 (0.125)	Data 0.023 (0.063)	Loss 0.1939 (0.1264)	Acc@1 95.312 (96.724)	Acc@5 100.000 (99.899)\
Epoch: [34][60/94]	Time 0.075 (0.104)	Data 0.000 (0.038)	Loss 0.1101 (0.1316)	Acc@1 96.875 (96.440)	Acc@5 100.000 (99.898)\
Epoch: [34][90/94]	Time 0.068 (0.093)	Data 0.000 (0.026)	Loss 0.2965 (0.1321)	Acc@1 90.625 (96.514)	Acc@5 100.000 (99.897)\
 * Acc@1 96.530 Acc@5 99.883\
Test: [0/91]	Time 1.419 (1.419)	Loss 2.2191 (2.2191)	Acc@1 45.312 (45.312)	Acc@5 76.562 (76.562)\
Test: [30/91]	Time 0.052 (0.099)	Loss 3.4723 (3.0715)	Acc@1 37.500 (41.532)	Acc@5 64.062 (67.440)\
Test: [60/91]	Time 0.019 (0.088)	Loss 2.5357 (3.0658)	Acc@1 46.875 (41.393)	Acc@5 82.812 (67.674)\
Test: [90/91]	Time 0.012 (0.081)	Loss 4.6453 (3.0614)	Acc@1 29.412 (40.818)	Acc@5 61.765 (68.295)\
 * Acc@1 40.818 Acc@5 68.295\
tensor(5.2923, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0019737948588157686]\
Epoch: [35][0/94]	Time 1.119 (1.119)	Data 1.046 (1.046)	Loss 0.0779 (0.0779)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [35][30/94]	Time 0.067 (0.120)	Data 0.000 (0.048)	Loss 0.0941 (0.1246)	Acc@1 96.875 (96.925)	Acc@5 100.000 (100.000)\
Epoch: [35][60/94]	Time 0.069 (0.099)	Data 0.026 (0.026)	Loss 0.1356 (0.1302)	Acc@1 93.750 (96.670)	Acc@5 100.000 (99.949)\
Epoch: [35][90/94]	Time 0.065 (0.093)	Data 0.000 (0.020)	Loss 0.1406 (0.1250)	Acc@1 95.312 (96.823)	Acc@5 100.000 (99.931)\
 * Acc@1 96.864 Acc@5 99.933\
Test: [0/91]	Time 1.291 (1.291)	Loss 3.4168 (3.4168)	Acc@1 34.375 (34.375)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.027 (0.128)	Loss 3.4558 (3.0677)	Acc@1 34.375 (38.659)	Acc@5 64.062 (67.843)\
Test: [60/91]	Time 0.025 (0.099)	Loss 3.6416 (3.0705)	Acc@1 34.375 (40.061)	Acc@5 60.938 (67.777)\
Test: [90/91]	Time 0.015 (0.086)	Loss 2.4812 (3.0676)	Acc@1 44.118 (40.352)	Acc@5 73.529 (68.347)\
 * Acc@1 40.352 Acc@5 68.347\
tensor(5.2983, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0018843769586593118]\
Epoch: [36][0/94]	Time 1.142 (1.142)	Data 1.070 (1.070)	Loss 0.1255 (0.1255)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)\
Epoch: [36][30/94]	Time 0.085 (0.136)	Data 0.000 (0.074)	Loss 0.0734 (0.1119)	Acc@1 98.438 (97.329)	Acc@5 100.000 (99.849)\
Epoch: [36][60/94]	Time 0.064 (0.107)	Data 0.000 (0.042)	Loss 0.1496 (0.1186)	Acc@1 93.750 (97.080)	Acc@5 100.000 (99.872)\
Epoch: [36][90/94]	Time 0.064 (0.098)	Data 0.000 (0.033)	Loss 0.1193 (0.1175)	Acc@1 96.875 (96.944)	Acc@5 100.000 (99.914)\
 * Acc@1 97.030 Acc@5 99.917\
Test: [0/91]	Time 1.123 (1.123)	Loss 3.0612 (3.0612)	Acc@1 32.812 (32.812)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.051 (0.099)	Loss 4.2869 (3.1901)	Acc@1 23.438 (37.601)	Acc@5 50.000 (66.079)\
Test: [60/91]	Time 0.032 (0.086)	Loss 2.7884 (3.1210)	Acc@1 43.750 (39.088)	Acc@5 78.125 (66.931)\
Test: [90/91]	Time 0.015 (0.080)	Loss 2.2533 (3.0325)	Acc@1 47.059 (40.369)	Acc@5 73.529 (67.604)\
 * Acc@1 40.369 Acc@5 67.604\
tensor(5.3051, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0017990099155778332]\
Epoch: [37][0/94]	Time 1.091 (1.091)	Data 1.042 (1.042)	Loss 0.1345 (0.1345)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [37][30/94]	Time 0.073 (0.132)	Data 0.000 (0.062)	Loss 0.0353 (0.0938)	Acc@1 100.000 (97.984)	Acc@5 100.000 (100.000)\
Epoch: [37][60/94]	Time 0.078 (0.107)	Data 0.000 (0.039)	Loss 0.1534 (0.0934)	Acc@1 96.875 (97.925)	Acc@5 100.000 (100.000)\
Epoch: [37][90/94]	Time 0.066 (0.095)	Data 0.000 (0.027)	Loss 0.2053 (0.0987)	Acc@1 93.750 (97.579)	Acc@5 100.000 (99.966)\
 * Acc@1 97.581 Acc@5 99.967\
Test: [0/91]	Time 1.276 (1.276)	Loss 3.4807 (3.4807)	Acc@1 37.500 (37.500)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.025 (0.102)	Loss 2.9456 (3.1163)	Acc@1 40.625 (39.415)	Acc@5 65.625 (68.095)\
Test: [60/91]	Time 0.192 (0.081)	Loss 3.7867 (3.0820)	Acc@1 31.250 (39.703)	Acc@5 54.688 (68.776)\
Test: [90/91]	Time 0.012 (0.069)	Loss 2.4988 (3.0867)	Acc@1 50.000 (40.300)	Acc@5 70.588 (67.967)\
 * Acc@1 40.300 Acc@5 67.967\
tensor(5.3101, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0017175102154984984]\
Epoch: [38][0/94]	Time 1.425 (1.425)	Data 1.391 (1.391)	Loss 0.0983 (0.0983)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [38][30/94]	Time 0.065 (0.146)	Data 0.039 (0.093)	Loss 0.1125 (0.1029)	Acc@1 96.875 (97.631)	Acc@5 100.000 (99.950)\
Epoch: [38][60/94]	Time 0.146 (0.120)	Data 0.097 (0.064)	Loss 0.0929 (0.0986)	Acc@1 98.438 (97.772)	Acc@5 100.000 (99.974)\
Epoch: [38][90/94]	Time 0.065 (0.107)	Data 0.000 (0.049)	Loss 0.0877 (0.0977)	Acc@1 95.312 (97.630)	Acc@5 100.000 (99.948)\
 * Acc@1 97.564 Acc@5 99.950\
Test: [0/91]	Time 1.119 (1.119)	Loss 2.7417 (2.7417)	Acc@1 43.750 (43.750)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.160 (0.112)	Loss 3.8986 (3.0443)	Acc@1 32.812 (41.431)	Acc@5 59.375 (68.700)\
Test: [60/91]	Time 0.035 (0.100)	Loss 4.3541 (3.0753)	Acc@1 25.000 (41.214)	Acc@5 56.250 (68.571)\
Test: [90/91]	Time 0.012 (0.086)	Loss 3.4492 (3.0928)	Acc@1 26.471 (40.853)	Acc@5 61.765 (67.881)\
 * Acc@1 40.853 Acc@5 67.881\
tensor(5.3138, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.001639702658000207]\
Epoch: [39][0/94]	Time 1.358 (1.358)	Data 1.328 (1.328)	Loss 0.0652 (0.0652)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [39][30/94]	Time 0.068 (0.130)	Data 0.031 (0.069)	Loss 0.0556 (0.0745)	Acc@1 98.438 (98.639)	Acc@5 100.000 (100.000)\
Epoch: [39][60/94]	Time 0.069 (0.116)	Data 0.004 (0.061)	Loss 0.0678 (0.0880)	Acc@1 100.000 (98.130)	Acc@5 100.000 (100.000)\
Epoch: [39][90/94]	Time 0.065 (0.104)	Data 0.000 (0.046)	Loss 0.0606 (0.0928)	Acc@1 100.000 (97.940)	Acc@5 100.000 (99.966)\
 * Acc@1 97.965 Acc@5 99.967\
Test: [0/91]	Time 1.214 (1.214)	Loss 3.3551 (3.3551)	Acc@1 34.375 (34.375)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.031 (0.125)	Loss 2.4756 (3.1376)	Acc@1 42.188 (39.012)	Acc@5 68.750 (67.944)\
Test: [60/91]	Time 0.096 (0.111)	Loss 2.1321 (3.0706)	Acc@1 56.250 (40.523)	Acc@5 75.000 (68.801)\
Test: [90/91]	Time 0.015 (0.095)	Loss 2.6743 (3.0662)	Acc@1 52.941 (40.749)	Acc@5 64.706 (68.571)\
 * Acc@1 40.749 Acc@5 68.571\
tensor(5.3171, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0015654199796841294]\
Epoch: [40][0/94]	Time 1.112 (1.112)	Data 1.064 (1.064)	Loss 0.2090 (0.2090)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)\
Epoch: [40][30/94]	Time 0.209 (0.128)	Data 0.176 (0.060)	Loss 0.0752 (0.0878)	Acc@1 96.875 (97.883)	Acc@5 100.000 (100.000)\
Epoch: [40][60/94]	Time 0.075 (0.104)	Data 0.000 (0.038)	Loss 0.1164 (0.0824)	Acc@1 96.875 (98.104)	Acc@5 100.000 (100.000)\
Epoch: [40][90/94]	Time 0.071 (0.094)	Data 0.000 (0.028)	Loss 0.0965 (0.0881)	Acc@1 95.312 (97.837)	Acc@5 100.000 (99.983)\
 * Acc@1 97.848 Acc@5 99.983\
Test: [0/91]	Time 1.250 (1.250)	Loss 3.3902 (3.3902)	Acc@1 48.438 (48.438)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.047 (0.106)	Loss 3.1739 (3.0608)	Acc@1 34.375 (41.230)	Acc@5 68.750 (68.095)\
Test: [60/91]	Time 0.038 (0.092)	Loss 3.6680 (3.1013)	Acc@1 37.500 (40.599)	Acc@5 60.938 (68.110)\
Test: [90/91]	Time 0.012 (0.079)	Loss 3.7420 (3.1075)	Acc@1 38.235 (40.697)	Acc@5 67.647 (68.674)\
 * Acc@1 40.697 Acc@5 68.674\
tensor(5.3214, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0014945024946065241]\
Epoch: [41][0/94]	Time 1.497 (1.497)	Data 1.415 (1.415)	Loss 0.1035 (0.1035)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [41][30/94]	Time 0.072 (0.125)	Data 0.000 (0.051)	Loss 0.0360 (0.0740)	Acc@1 100.000 (98.438)	Acc@5 100.000 (99.950)\
Epoch: [41][60/94]	Time 0.106 (0.112)	Data 0.000 (0.043)	Loss 0.0909 (0.0808)	Acc@1 98.438 (98.258)	Acc@5 100.000 (99.949)\
Epoch: [41][90/94]	Time 0.072 (0.101)	Data 0.000 (0.029)	Loss 0.0961 (0.0823)	Acc@1 98.438 (98.128)	Acc@5 100.000 (99.948)\
 * Acc@1 98.098 Acc@5 99.950\
Test: [0/91]	Time 1.295 (1.295)	Loss 3.2873 (3.2873)	Acc@1 32.812 (32.812)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.019 (0.110)	Loss 3.8286 (3.0698)	Acc@1 35.938 (40.827)	Acc@5 68.750 (68.498)\
Test: [60/91]	Time 0.027 (0.093)	Loss 2.1603 (3.0954)	Acc@1 50.000 (40.420)	Acc@5 75.000 (68.238)\
Test: [90/91]	Time 0.012 (0.088)	Loss 2.7290 (3.1172)	Acc@1 52.941 (40.404)	Acc@5 73.529 (68.070)\
 * Acc@1 40.404 Acc@5 68.070\
tensor(5.3248, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0014267977510008588]\
Epoch: [42][0/94]	Time 1.232 (1.232)	Data 1.170 (1.170)	Loss 0.0232 (0.0232)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [42][30/94]	Time 0.072 (0.128)	Data 0.000 (0.061)	Loss 0.0484 (0.0770)	Acc@1 98.438 (98.387)	Acc@5 100.000 (100.000)\
Epoch: [42][60/94]	Time 0.084 (0.111)	Data 0.000 (0.050)	Loss 0.0838 (0.0736)	Acc@1 98.438 (98.514)	Acc@5 100.000 (100.000)\
Epoch: [42][90/94]	Time 0.072 (0.102)	Data 0.000 (0.040)	Loss 0.0536 (0.0753)	Acc@1 100.000 (98.352)	Acc@5 100.000 (99.983)\
 * Acc@1 98.332 Acc@5 99.983\
Test: [0/91]	Time 1.393 (1.393)	Loss 3.6231 (3.6231)	Acc@1 42.188 (42.188)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.036 (0.117)	Loss 3.0920 (3.1423)	Acc@1 42.188 (39.869)	Acc@5 64.062 (68.095)\
Test: [60/91]	Time 0.224 (0.099)	Loss 3.8424 (3.0892)	Acc@1 34.375 (41.112)	Acc@5 53.125 (68.596)\
Test: [90/91]	Time 0.012 (0.084)	Loss 4.4131 (3.1500)	Acc@1 26.471 (40.456)	Acc@5 61.765 (68.381)\
 * Acc@1 40.456 Acc@5 68.381\
tensor(5.3283, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0013621602035512731]\
Epoch: [43][0/94]	Time 1.157 (1.157)	Data 1.097 (1.097)	Loss 0.0314 (0.0314)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [43][30/94]	Time 0.070 (0.121)	Data 0.000 (0.055)	Loss 0.1101 (0.0722)	Acc@1 96.875 (98.034)	Acc@5 100.000 (100.000)\
Epoch: [43][60/94]	Time 0.065 (0.100)	Data 0.000 (0.036)	Loss 0.0861 (0.0773)	Acc@1 98.438 (97.951)	Acc@5 100.000 (99.949)\
Epoch: [43][90/94]	Time 0.065 (0.092)	Data 0.000 (0.026)	Loss 0.0683 (0.0747)	Acc@1 96.875 (98.077)	Acc@5 100.000 (99.966)\
 * Acc@1 98.065 Acc@5 99.967\
Test: [0/91]	Time 1.070 (1.070)	Loss 3.0332 (3.0332)	Acc@1 31.250 (31.250)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.149 (0.103)	Loss 2.7813 (3.0636)	Acc@1 40.625 (40.625)	Acc@5 67.188 (68.196)\
Test: [60/91]	Time 0.031 (0.082)	Loss 3.9096 (3.1067)	Acc@1 29.688 (40.446)	Acc@5 54.688 (67.700)\
Test: [90/91]	Time 0.016 (0.074)	Loss 3.5630 (3.0780)	Acc@1 52.941 (41.060)	Acc@5 61.765 (68.243)\
 * Acc@1 41.060 Acc@5 68.243\
tensor(5.3313, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0013004509005128978]\
Epoch: [44][0/94]	Time 1.355 (1.355)	Data 1.329 (1.329)	Loss 0.0791 (0.0791)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [44][30/94]	Time 0.060 (0.130)	Data 0.000 (0.059)	Loss 0.0593 (0.0733)	Acc@1 98.438 (98.236)	Acc@5 100.000 (100.000)\
Epoch: [44][60/94]	Time 0.139 (0.109)	Data 0.100 (0.040)	Loss 0.0577 (0.0731)	Acc@1 98.438 (98.309)	Acc@5 100.000 (99.974)\
Epoch: [44][90/94]	Time 0.071 (0.098)	Data 0.000 (0.028)	Loss 0.0838 (0.0721)	Acc@1 98.438 (98.352)	Acc@5 100.000 (99.983)\
 * Acc@1 98.365 Acc@5 99.983\
Test: [0/91]	Time 1.331 (1.331)	Loss 3.3224 (3.3224)	Acc@1 37.500 (37.500)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.044 (0.107)	Loss 3.8215 (3.1658)	Acc@1 35.938 (40.575)	Acc@5 59.375 (68.044)\
Test: [60/91]	Time 0.023 (0.082)	Loss 2.8794 (3.0903)	Acc@1 40.625 (40.727)	Acc@5 73.438 (68.315)\
Test: [90/91]	Time 0.012 (0.074)	Loss 2.2406 (3.1259)	Acc@1 47.059 (40.801)	Acc@5 76.471 (68.139)\
 * Acc@1 40.801 Acc@5 68.139\
tensor(5.3336, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.001241537185006412]\
Epoch: [45][0/94]	Time 1.131 (1.131)	Data 1.062 (1.062)	Loss 0.0360 (0.0360)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [45][30/94]	Time 0.074 (0.124)	Data 0.000 (0.053)	Loss 0.0598 (0.0653)	Acc@1 98.438 (98.337)	Acc@5 100.000 (100.000)\
Epoch: [45][60/94]	Time 0.083 (0.107)	Data 0.038 (0.041)	Loss 0.0519 (0.0635)	Acc@1 98.438 (98.412)	Acc@5 100.000 (100.000)\
Epoch: [45][90/94]	Time 0.056 (0.099)	Data 0.000 (0.034)	Loss 0.0606 (0.0644)	Acc@1 98.438 (98.455)	Acc@5 100.000 (99.983)\
 * Acc@1 98.482 Acc@5 99.983\
Test: [0/91]	Time 1.108 (1.108)	Loss 3.4540 (3.4540)	Acc@1 37.500 (37.500)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.086 (0.121)	Loss 3.0318 (3.1753)	Acc@1 34.375 (39.466)	Acc@5 68.750 (67.238)\
Test: [60/91]	Time 0.030 (0.101)	Loss 3.4967 (3.1405)	Acc@1 26.562 (40.599)	Acc@5 60.938 (67.623)\
Test: [90/91]	Time 0.012 (0.088)	Loss 2.8763 (3.1097)	Acc@1 41.176 (40.870)	Acc@5 79.412 (68.295)\
 * Acc@1 40.870 Acc@5 68.295\
tensor(5.3358, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.001185292409844702]\
Epoch: [46][0/94]	Time 1.427 (1.427)	Data 1.376 (1.376)	Loss 0.0916 (0.0916)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [46][30/94]	Time 0.076 (0.142)	Data 0.000 (0.074)	Loss 0.0340 (0.0647)	Acc@1 100.000 (98.538)	Acc@5 100.000 (100.000)\
Epoch: [46][60/94]	Time 0.072 (0.117)	Data 0.000 (0.052)	Loss 0.0654 (0.0647)	Acc@1 98.438 (98.566)	Acc@5 100.000 (100.000)\
Epoch: [46][90/94]	Time 0.071 (0.106)	Data 0.000 (0.042)	Loss 0.1090 (0.0644)	Acc@1 95.312 (98.541)	Acc@5 100.000 (100.000)\
 * Acc@1 98.565 Acc@5 100.000\
Test: [0/91]	Time 1.221 (1.221)	Loss 3.0719 (3.0719)	Acc@1 40.625 (40.625)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.020 (0.118)	Loss 2.8072 (3.2011)	Acc@1 51.562 (40.171)	Acc@5 67.188 (67.742)\
Test: [60/91]	Time 0.124 (0.105)	Loss 3.3218 (3.1956)	Acc@1 45.312 (41.265)	Acc@5 65.625 (67.956)\
Test: [90/91]	Time 0.037 (0.094)	Loss 3.1269 (3.1465)	Acc@1 35.294 (41.491)	Acc@5 73.529 (68.226)\
 * Acc@1 41.491 Acc@5 68.226\
tensor(5.3376, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0011315956652786067]\
Epoch: [47][0/94]	Time 1.231 (1.231)	Data 1.184 (1.184)	Loss 0.0637 (0.0637)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [47][30/94]	Time 0.081 (0.142)	Data 0.000 (0.072)	Loss 0.0600 (0.0596)	Acc@1 98.438 (98.387)	Acc@5 100.000 (100.000)\
Epoch: [47][60/94]	Time 0.069 (0.121)	Data 0.000 (0.051)	Loss 0.0258 (0.0609)	Acc@1 100.000 (98.463)	Acc@5 100.000 (100.000)\
Epoch: [47][90/94]	Time 0.054 (0.105)	Data 0.000 (0.035)	Loss 0.0424 (0.0628)	Acc@1 100.000 (98.489)	Acc@5 100.000 (99.983)\
 * Acc@1 98.498 Acc@5 99.983\
Test: [0/91]	Time 1.381 (1.381)	Loss 2.6469 (2.6469)	Acc@1 48.438 (48.438)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.022 (0.131)	Loss 4.3425 (3.2121)	Acc@1 31.250 (39.567)	Acc@5 54.688 (67.994)\
Test: [60/91]	Time 0.026 (0.112)	Loss 2.2886 (3.1588)	Acc@1 46.875 (40.266)	Acc@5 81.250 (68.340)\
Test: [90/91]	Time 0.015 (0.099)	Loss 2.4263 (3.1497)	Acc@1 47.059 (40.645)	Acc@5 76.471 (68.295)\
 * Acc@1 40.645 Acc@5 68.295\
tensor(5.3388, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0010803315190764677]\
Epoch: [48][0/94]	Time 1.674 (1.674)	Data 1.640 (1.640)	Loss 0.0659 (0.0659)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [48][30/94]	Time 0.140 (0.142)	Data 0.107 (0.082)	Loss 0.0811 (0.0681)	Acc@1 96.875 (98.236)	Acc@5 100.000 (99.950)\
Epoch: [48][60/94]	Time 0.136 (0.115)	Data 0.097 (0.055)	Loss 0.0456 (0.0649)	Acc@1 98.438 (98.258)	Acc@5 100.000 (99.974)\
Epoch: [48][90/94]	Time 0.072 (0.103)	Data 0.023 (0.041)	Loss 0.0329 (0.0663)	Acc@1 98.438 (98.266)	Acc@5 100.000 (99.983)\
 * Acc@1 98.315 Acc@5 99.983\
Test: [0/91]	Time 1.395 (1.395)	Loss 2.6745 (2.6745)	Acc@1 45.312 (45.312)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.136 (0.132)	Loss 3.8397 (3.2450)	Acc@1 32.812 (40.020)	Acc@5 62.500 (68.296)\
Test: [60/91]	Time 0.130 (0.110)	Loss 2.8002 (3.1142)	Acc@1 46.875 (41.855)	Acc@5 67.188 (68.494)\
Test: [90/91]	Time 0.015 (0.095)	Loss 2.6551 (3.1138)	Acc@1 44.118 (41.181)	Acc@5 73.529 (68.674)\
 * Acc@1 41.181 Acc@5 68.674\
tensor(5.3407, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0010313897683787222]\
Epoch: [49][0/94]	Time 1.646 (1.646)	Data 1.578 (1.578)	Loss 0.0206 (0.0206)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [49][30/94]	Time 0.139 (0.137)	Data 0.115 (0.070)	Loss 0.0637 (0.0664)	Acc@1 98.438 (98.387)	Acc@5 100.000 (99.950)\
Epoch: [49][60/94]	Time 0.184 (0.118)	Data 0.138 (0.057)	Loss 0.0720 (0.0658)	Acc@1 98.438 (98.233)	Acc@5 100.000 (99.974)\
Epoch: [49][90/94]	Time 0.067 (0.104)	Data 0.000 (0.041)	Loss 0.0412 (0.0617)	Acc@1 98.438 (98.420)	Acc@5 100.000 (99.983)\
 * Acc@1 98.415 Acc@5 99.983\
Test: [0/91]	Time 0.859 (0.859)	Loss 2.9750 (2.9750)	Acc@1 32.812 (32.812)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.026 (0.110)	Loss 3.1560 (3.1428)	Acc@1 29.688 (41.683)	Acc@5 71.875 (68.296)\
Test: [60/91]	Time 0.066 (0.092)	Loss 3.3755 (3.1392)	Acc@1 39.062 (41.726)	Acc@5 67.188 (68.545)\
Test: [90/91]	Time 0.012 (0.086)	Loss 3.3351 (3.1408)	Acc@1 32.353 (41.457)	Acc@5 64.706 (68.605)\
 * Acc@1 41.457 Acc@5 68.605\
tensor(5.3422, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.000984665202794123]\
Epoch: [50][0/94]	Time 1.572 (1.572)	Data 1.541 (1.541)	Loss 0.0377 (0.0377)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [50][30/94]	Time 0.105 (0.137)	Data 0.000 (0.058)	Loss 0.0291 (0.0627)	Acc@1 100.000 (98.589)	Acc@5 100.000 (100.000)\
Epoch: [50][60/94]	Time 0.074 (0.118)	Data 0.000 (0.042)	Loss 0.0358 (0.0626)	Acc@1 98.438 (98.540)	Acc@5 100.000 (100.000)\
Epoch: [50][90/94]	Time 0.072 (0.104)	Data 0.000 (0.029)	Loss 0.0420 (0.0624)	Acc@1 100.000 (98.609)	Acc@5 100.000 (100.000)\
 * Acc@1 98.599 Acc@5 100.000\
Test: [0/91]	Time 1.383 (1.383)	Loss 3.3100 (3.3100)	Acc@1 43.750 (43.750)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.025 (0.138)	Loss 2.6618 (3.2431)	Acc@1 48.438 (40.121)	Acc@5 67.188 (67.692)\
Test: [60/91]	Time 0.055 (0.108)	Loss 2.6879 (3.1393)	Acc@1 48.438 (41.035)	Acc@5 76.562 (68.443)\
Test: [90/91]	Time 0.012 (0.091)	Loss 2.3156 (3.1005)	Acc@1 55.882 (41.474)	Acc@5 82.353 (68.778)\
 * Acc@1 41.474 Acc@5 68.778\
tensor(5.3432, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0009400573782282974]\
Epoch: [51][0/94]	Time 1.177 (1.177)	Data 1.116 (1.116)	Loss 0.1085 (0.1085)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [51][30/94]	Time 0.100 (0.120)	Data 0.059 (0.055)	Loss 0.0618 (0.0586)	Acc@1 98.438 (98.639)	Acc@5 100.000 (100.000)\
Epoch: [51][60/94]	Time 0.068 (0.101)	Data 0.000 (0.036)	Loss 0.0440 (0.0539)	Acc@1 100.000 (98.847)	Acc@5 100.000 (100.000)\
Epoch: [51][90/94]	Time 0.087 (0.095)	Data 0.063 (0.030)	Loss 0.0555 (0.0530)	Acc@1 96.875 (98.884)	Acc@5 100.000 (100.000)\
 * Acc@1 98.882 Acc@5 100.000\
Test: [0/91]	Time 1.169 (1.169)	Loss 3.0872 (3.0872)	Acc@1 46.875 (46.875)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.334 (0.132)	Loss 3.0388 (3.1621)	Acc@1 43.750 (40.474)	Acc@5 67.188 (68.296)\
Test: [60/91]	Time 0.064 (0.107)	Loss 3.5058 (3.0545)	Acc@1 40.625 (42.034)	Acc@5 67.188 (69.672)\
Test: [90/91]	Time 0.012 (0.092)	Loss 3.9355 (3.1138)	Acc@1 44.118 (41.854)	Acc@5 55.882 (69.037)\
 * Acc@1 41.854 Acc@5 69.037\
tensor(5.3448, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0008974704009584349]\
Epoch: [52][0/94]	Time 1.472 (1.472)	Data 1.440 (1.440)	Loss 0.0528 (0.0528)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [52][30/94]	Time 0.064 (0.120)	Data 0.000 (0.050)	Loss 0.0620 (0.0509)	Acc@1 96.875 (98.992)	Acc@5 100.000 (100.000)\
Epoch: [52][60/94]	Time 0.093 (0.103)	Data 0.020 (0.040)	Loss 0.0401 (0.0529)	Acc@1 100.000 (98.873)	Acc@5 100.000 (100.000)\
Epoch: [52][90/94]	Time 0.064 (0.094)	Data 0.000 (0.031)	Loss 0.0489 (0.0516)	Acc@1 98.438 (98.884)	Acc@5 100.000 (100.000)\
 * Acc@1 98.916 Acc@5 100.000\
Test: [0/91]	Time 1.235 (1.235)	Loss 2.4800 (2.4800)	Acc@1 54.688 (54.688)	Acc@5 79.688 (79.688)\
Test: [30/91]	Time 0.042 (0.133)	Loss 3.1074 (3.0123)	Acc@1 42.188 (41.935)	Acc@5 71.875 (69.657)\
Test: [60/91]	Time 0.136 (0.115)	Loss 3.1381 (3.1146)	Acc@1 48.438 (41.470)	Acc@5 64.062 (68.904)\
Test: [90/91]	Time 0.015 (0.097)	Loss 3.2175 (3.1288)	Acc@1 47.059 (41.681)	Acc@5 70.588 (68.899)\
 * Acc@1 41.681 Acc@5 68.899\
tensor(5.3460, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0008568127214899482]\
Epoch: [53][0/94]	Time 1.404 (1.404)	Data 1.377 (1.377)	Loss 0.0474 (0.0474)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [53][30/94]	Time 0.080 (0.128)	Data 0.000 (0.059)	Loss 0.1066 (0.0528)	Acc@1 95.312 (98.286)	Acc@5 100.000 (100.000)\
Epoch: [53][60/94]	Time 0.074 (0.107)	Data 0.000 (0.044)	Loss 0.0902 (0.0627)	Acc@1 96.875 (98.104)	Acc@5 100.000 (100.000)\
Epoch: [53][90/94]	Time 0.065 (0.096)	Data 0.000 (0.030)	Loss 0.0549 (0.0661)	Acc@1 98.438 (98.111)	Acc@5 100.000 (100.000)\
 * Acc@1 98.115 Acc@5 100.000\
Test: [0/91]	Time 1.198 (1.198)	Loss 2.9448 (2.9448)	Acc@1 46.875 (46.875)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.132 (0.131)	Loss 2.7358 (3.1248)	Acc@1 54.688 (41.280)	Acc@5 76.562 (68.246)\
Test: [60/91]	Time 0.041 (0.112)	Loss 2.0465 (3.0622)	Acc@1 48.438 (41.752)	Acc@5 82.812 (69.057)\
Test: [90/91]	Time 0.016 (0.098)	Loss 2.6271 (3.0865)	Acc@1 35.294 (41.508)	Acc@5 73.529 (68.623)\
 * Acc@1 41.508 Acc@5 68.623\
tensor(5.3470, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0008179969377519476]\
Epoch: [54][0/94]	Time 1.410 (1.410)	Data 1.318 (1.318)	Loss 0.0831 (0.0831)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [54][30/94]	Time 0.093 (0.142)	Data 0.000 (0.070)	Loss 0.0384 (0.0555)	Acc@1 100.000 (98.992)	Acc@5 100.000 (100.000)\
Epoch: [54][60/94]	Time 0.092 (0.113)	Data 0.022 (0.043)	Loss 0.0528 (0.0560)	Acc@1 96.875 (98.745)	Acc@5 100.000 (100.000)\
Epoch: [54][90/94]	Time 0.072 (0.106)	Data 0.000 (0.037)	Loss 0.0215 (0.0549)	Acc@1 100.000 (98.850)	Acc@5 100.000 (100.000)\
 * Acc@1 98.832 Acc@5 100.000\
Test: [0/91]	Time 1.507 (1.507)	Loss 2.7013 (2.7013)	Acc@1 40.625 (40.625)	Acc@5 76.562 (76.562)\
Test: [30/91]	Time 0.026 (0.135)	Loss 3.2728 (3.2551)	Acc@1 39.062 (39.264)	Acc@5 64.062 (66.935)\
Test: [60/91]	Time 0.079 (0.112)	Loss 3.7684 (3.2082)	Acc@1 37.500 (39.703)	Acc@5 68.750 (67.930)\
Test: [90/91]	Time 0.015 (0.098)	Loss 2.1357 (3.1236)	Acc@1 41.176 (41.232)	Acc@5 79.412 (69.123)\
 * Acc@1 41.232 Acc@5 69.123\
tensor(5.3479, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0007809396072084504]\
Epoch: [55][0/94]	Time 1.585 (1.585)	Data 1.507 (1.507)	Loss 0.0332 (0.0332)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [55][30/94]	Time 0.089 (0.133)	Data 0.000 (0.062)	Loss 0.0572 (0.0423)	Acc@1 98.438 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [55][60/94]	Time 0.063 (0.109)	Data 0.000 (0.040)	Loss 0.0490 (0.0478)	Acc@1 98.438 (99.103)	Acc@5 100.000 (100.000)\
Epoch: [55][90/94]	Time 0.070 (0.100)	Data 0.000 (0.030)	Loss 0.0286 (0.0472)	Acc@1 100.000 (99.141)	Acc@5 100.000 (100.000)\
 * Acc@1 99.149 Acc@5 100.000\
Test: [0/91]	Time 1.203 (1.203)	Loss 3.0883 (3.0883)	Acc@1 42.188 (42.188)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.020 (0.125)	Loss 3.6240 (3.1898)	Acc@1 31.250 (40.625)	Acc@5 67.188 (68.246)\
Test: [60/91]	Time 0.115 (0.109)	Loss 2.4420 (3.1534)	Acc@1 50.000 (41.393)	Acc@5 70.312 (68.852)\
Test: [90/91]	Time 0.012 (0.094)	Loss 3.6305 (3.1442)	Acc@1 23.529 (41.474)	Acc@5 64.706 (68.744)\
 * Acc@1 41.474 Acc@5 68.744\
tensor(5.3490, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0007455610674814365]\
Epoch: [56][0/94]	Time 1.066 (1.066)	Data 1.024 (1.024)	Loss 0.0623 (0.0623)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [56][30/94]	Time 0.198 (0.134)	Data 0.172 (0.065)	Loss 0.0945 (0.0487)	Acc@1 95.312 (98.942)	Acc@5 100.000 (100.000)\
Epoch: [56][60/94]	Time 0.077 (0.109)	Data 0.003 (0.044)	Loss 0.0504 (0.0460)	Acc@1 100.000 (99.027)	Acc@5 100.000 (100.000)\
Epoch: [56][90/94]	Time 0.064 (0.099)	Data 0.000 (0.035)	Loss 0.0435 (0.0468)	Acc@1 98.438 (98.918)	Acc@5 100.000 (100.000)\
 * Acc@1 98.949 Acc@5 100.000\
Test: [0/91]	Time 1.700 (1.700)	Loss 3.1671 (3.1671)	Acc@1 45.312 (45.312)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.118 (0.132)	Loss 3.1086 (3.1545)	Acc@1 43.750 (41.734)	Acc@5 73.438 (68.347)\
Test: [60/91]	Time 0.019 (0.115)	Loss 2.4790 (3.1888)	Acc@1 46.875 (41.598)	Acc@5 78.125 (68.648)\
Test: [90/91]	Time 0.015 (0.097)	Loss 3.2128 (3.1607)	Acc@1 55.882 (41.819)	Acc@5 61.765 (68.951)\
 * Acc@1 41.819 Acc@5 68.951\
tensor(5.3498, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0007117852651001318]\
Epoch: [57][0/94]	Time 1.729 (1.729)	Data 1.686 (1.686)	Loss 0.0312 (0.0312)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [57][30/94]	Time 0.142 (0.141)	Data 0.114 (0.075)	Loss 0.0309 (0.0499)	Acc@1 100.000 (98.589)	Acc@5 100.000 (100.000)\
Epoch: [57][60/94]	Time 0.082 (0.115)	Data 0.000 (0.046)	Loss 0.0713 (0.0466)	Acc@1 98.438 (98.899)	Acc@5 98.438 (99.974)\
Epoch: [57][90/94]	Time 0.068 (0.101)	Data 0.000 (0.032)	Loss 0.1144 (0.0505)	Acc@1 96.875 (98.764)	Acc@5 100.000 (99.983)\
 * Acc@1 98.749 Acc@5 99.983\
Test: [0/91]	Time 1.447 (1.447)	Loss 2.8124 (2.8124)	Acc@1 46.875 (46.875)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.136 (0.117)	Loss 3.9453 (3.2948)	Acc@1 29.688 (39.567)	Acc@5 51.562 (67.994)\
Test: [60/91]	Time 0.100 (0.103)	Loss 3.0364 (3.2000)	Acc@1 48.438 (40.804)	Acc@5 65.625 (68.801)\
Test: [90/91]	Time 0.016 (0.085)	Loss 2.0928 (3.1557)	Acc@1 55.882 (41.353)	Acc@5 73.529 (69.140)\
 * Acc@1 41.353 Acc@5 69.140\
tensor(5.3505, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0006795395920083764]\
Epoch: [58][0/94]	Time 1.235 (1.235)	Data 1.172 (1.172)	Loss 0.0632 (0.0632)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [58][30/94]	Time 0.059 (0.124)	Data 0.001 (0.062)	Loss 0.0331 (0.0513)	Acc@1 100.000 (98.790)	Acc@5 100.000 (99.950)\
Epoch: [58][60/94]	Time 0.073 (0.101)	Data 0.000 (0.036)	Loss 0.0604 (0.0581)	Acc@1 98.438 (98.745)	Acc@5 100.000 (99.949)\
Epoch: [58][90/94]	Time 0.065 (0.094)	Data 0.000 (0.029)	Loss 0.0867 (0.0551)	Acc@1 98.438 (98.832)	Acc@5 100.000 (99.966)\
 * Acc@1 98.849 Acc@5 99.967\
Test: [0/91]	Time 1.217 (1.217)	Loss 3.2829 (3.2829)	Acc@1 32.812 (32.812)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.045 (0.120)	Loss 3.1296 (3.1913)	Acc@1 39.062 (41.734)	Acc@5 65.625 (68.901)\
Test: [60/91]	Time 0.048 (0.094)	Loss 2.7969 (3.1128)	Acc@1 40.625 (41.880)	Acc@5 71.875 (68.852)\
Test: [90/91]	Time 0.012 (0.082)	Loss 3.6603 (3.1343)	Acc@1 32.353 (41.353)	Acc@5 67.647 (69.020)\
 * Acc@1 41.353 Acc@5 69.020\
tensor(5.3509, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0006487547294786288]\
Epoch: [59][0/94]	Time 1.241 (1.241)	Data 1.171 (1.171)	Loss 0.0744 (0.0744)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [59][30/94]	Time 0.077 (0.128)	Data 0.000 (0.053)	Loss 0.0304 (0.0434)	Acc@1 100.000 (99.143)	Acc@5 100.000 (100.000)\
Epoch: [59][60/94]	Time 0.073 (0.108)	Data 0.026 (0.036)	Loss 0.0602 (0.0406)	Acc@1 98.438 (99.232)	Acc@5 100.000 (100.000)\
Epoch: [59][90/94]	Time 0.072 (0.096)	Data 0.000 (0.025)	Loss 0.0234 (0.0428)	Acc@1 100.000 (99.107)	Acc@5 100.000 (100.000)\
 * Acc@1 99.116 Acc@5 100.000\
Test: [0/91]	Time 1.458 (1.458)	Loss 2.9345 (2.9345)	Acc@1 37.500 (37.500)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.115 (0.128)	Loss 3.1062 (3.2001)	Acc@1 39.062 (40.827)	Acc@5 71.875 (67.994)\
Test: [60/91]	Time 0.136 (0.108)	Loss 2.4156 (3.1580)	Acc@1 48.438 (41.240)	Acc@5 76.562 (68.468)\
Test: [90/91]	Time 0.012 (0.093)	Loss 2.9278 (3.1424)	Acc@1 29.412 (41.319)	Acc@5 73.529 (68.985)\
 * Acc@1 41.319 Acc@5 68.985\
tensor(5.3516, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0006193644990970612]\
Epoch: [60][0/94]	Time 1.229 (1.229)	Data 1.169 (1.169)	Loss 0.0449 (0.0449)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [60][30/94]	Time 0.064 (0.143)	Data 0.000 (0.061)	Loss 0.0610 (0.0521)	Acc@1 98.438 (98.841)	Acc@5 100.000 (100.000)\
Epoch: [60][60/94]	Time 0.102 (0.122)	Data 0.000 (0.045)	Loss 0.0758 (0.0493)	Acc@1 96.875 (98.899)	Acc@5 100.000 (100.000)\
Epoch: [60][90/94]	Time 0.074 (0.106)	Data 0.000 (0.032)	Loss 0.0904 (0.0510)	Acc@1 98.438 (98.867)	Acc@5 100.000 (100.000)\
 * Acc@1 98.899 Acc@5 100.000\
Test: [0/91]	Time 1.550 (1.550)	Loss 3.5515 (3.5515)	Acc@1 32.812 (32.812)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.029 (0.131)	Loss 2.3932 (3.0990)	Acc@1 50.000 (39.869)	Acc@5 79.688 (69.355)\
Test: [60/91]	Time 0.411 (0.106)	Loss 3.7466 (3.1658)	Acc@1 43.750 (40.241)	Acc@5 64.062 (68.571)\
Test: [90/91]	Time 0.016 (0.090)	Loss 3.4586 (3.1561)	Acc@1 41.176 (41.284)	Acc@5 64.706 (68.778)\
 * Acc@1 41.284 Acc@5 68.778\
tensor(5.3525, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0005913057204993993]\
Epoch: [61][0/94]	Time 1.577 (1.577)	Data 1.539 (1.539)	Loss 0.0370 (0.0370)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [61][30/94]	Time 0.074 (0.143)	Data 0.000 (0.076)	Loss 0.0525 (0.0443)	Acc@1 98.438 (98.992)	Acc@5 100.000 (100.000)\
Epoch: [61][60/94]	Time 0.067 (0.115)	Data 0.000 (0.044)	Loss 0.0271 (0.0460)	Acc@1 100.000 (98.950)	Acc@5 100.000 (100.000)\
Epoch: [61][90/94]	Time 0.066 (0.101)	Data 0.000 (0.031)	Loss 0.0571 (0.0483)	Acc@1 98.438 (98.935)	Acc@5 100.000 (99.983)\
 * Acc@1 98.966 Acc@5 99.983\
Test: [0/91]	Time 1.836 (1.836)	Loss 2.7599 (2.7599)	Acc@1 45.312 (45.312)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.019 (0.133)	Loss 3.0256 (3.1190)	Acc@1 42.188 (40.726)	Acc@5 73.438 (68.347)\
Test: [60/91]	Time 0.233 (0.113)	Loss 2.8972 (3.1217)	Acc@1 43.750 (41.086)	Acc@5 71.875 (68.878)\
Test: [90/91]	Time 0.012 (0.096)	Loss 2.8842 (3.1232)	Acc@1 50.000 (41.267)	Acc@5 70.588 (69.140)\
 * Acc@1 41.267 Acc@5 69.140\
tensor(5.3531, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0005645180755516963]\
Epoch: [62][0/94]	Time 1.605 (1.605)	Data 1.562 (1.562)	Loss 0.0298 (0.0298)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [62][30/94]	Time 0.084 (0.140)	Data 0.000 (0.070)	Loss 0.0385 (0.0461)	Acc@1 98.438 (98.942)	Acc@5 100.000 (100.000)\
Epoch: [62][60/94]	Time 0.076 (0.110)	Data 0.000 (0.043)	Loss 0.1619 (0.0460)	Acc@1 96.875 (98.924)	Acc@5 98.438 (99.974)\
Epoch: [62][90/94]	Time 0.066 (0.099)	Data 0.000 (0.033)	Loss 0.0351 (0.0442)	Acc@1 100.000 (99.038)	Acc@5 100.000 (99.983)\
 * Acc@1 99.049 Acc@5 99.983\
Test: [0/91]	Time 1.896 (1.896)	Loss 2.5378 (2.5378)	Acc@1 39.062 (39.062)	Acc@5 76.562 (76.562)\
Test: [30/91]	Time 0.122 (0.133)	Loss 3.4696 (3.1849)	Acc@1 37.500 (40.423)	Acc@5 70.312 (68.952)\
Test: [60/91]	Time 0.028 (0.108)	Loss 3.1038 (3.2059)	Acc@1 50.000 (40.932)	Acc@5 73.438 (68.648)\
Test: [90/91]	Time 0.015 (0.090)	Loss 3.5083 (3.1530)	Acc@1 50.000 (41.560)	Acc@5 70.588 (69.071)\
 * Acc@1 41.560 Acc@5 69.071\
tensor(5.3537, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0005389439786840606]\
Epoch: [63][0/94]	Time 1.947 (1.947)	Data 1.908 (1.908)	Loss 0.0495 (0.0495)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [63][30/94]	Time 0.089 (0.153)	Data 0.000 (0.085)	Loss 0.0289 (0.0495)	Acc@1 100.000 (98.639)	Acc@5 100.000 (100.000)\
Epoch: [63][60/94]	Time 0.077 (0.122)	Data 0.000 (0.055)	Loss 0.0485 (0.0464)	Acc@1 98.438 (98.924)	Acc@5 100.000 (100.000)\
Epoch: [63][90/94]	Time 0.069 (0.106)	Data 0.000 (0.041)	Loss 0.0599 (0.0476)	Acc@1 96.875 (98.884)	Acc@5 100.000 (100.000)\
 * Acc@1 98.899 Acc@5 100.000\
Test: [0/91]	Time 1.711 (1.711)	Loss 2.5347 (2.5347)	Acc@1 45.312 (45.312)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.320 (0.152)	Loss 3.0666 (3.2212)	Acc@1 45.312 (41.280)	Acc@5 65.625 (68.196)\
Test: [60/91]	Time 0.324 (0.117)	Loss 2.3568 (3.1839)	Acc@1 50.000 (41.342)	Acc@5 81.250 (68.571)\
Test: [90/91]	Time 0.012 (0.099)	Loss 2.9963 (3.1470)	Acc@1 52.941 (41.629)	Acc@5 76.471 (68.795)\
 * Acc@1 41.629 Acc@5 68.795\
tensor(5.3542, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0005145284530985853]\
Epoch: [64][0/94]	Time 2.451 (2.451)	Data 2.374 (2.374)	Loss 0.0486 (0.0486)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [64][30/94]	Time 0.123 (0.158)	Data 0.000 (0.090)	Loss 0.0992 (0.0479)	Acc@1 98.438 (98.942)	Acc@5 100.000 (100.000)\
Epoch: [64][60/94]	Time 0.073 (0.125)	Data 0.000 (0.057)	Loss 0.0257 (0.0457)	Acc@1 100.000 (99.129)	Acc@5 100.000 (100.000)\
Epoch: [64][90/94]	Time 0.070 (0.108)	Data 0.000 (0.039)	Loss 0.0290 (0.0464)	Acc@1 100.000 (99.021)	Acc@5 100.000 (100.000)\
 * Acc@1 99.032 Acc@5 100.000\
Test: [0/91]	Time 1.408 (1.408)	Loss 2.7818 (2.7818)	Acc@1 50.000 (50.000)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.033 (0.121)	Loss 2.3153 (3.0799)	Acc@1 48.438 (42.540)	Acc@5 75.000 (69.808)\
Test: [60/91]	Time 0.029 (0.099)	Loss 2.9673 (3.1551)	Acc@1 39.062 (41.445)	Acc@5 71.875 (68.750)\
Test: [90/91]	Time 0.012 (0.086)	Loss 3.1701 (3.1454)	Acc@1 44.118 (41.854)	Acc@5 70.588 (68.985)\
 * Acc@1 41.854 Acc@5 68.985\
tensor(5.3549, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0004912190125853851]\
Epoch: [65][0/94]	Time 1.803 (1.803)	Data 1.773 (1.773)	Loss 0.0726 (0.0726)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [65][30/94]	Time 0.060 (0.149)	Data 0.000 (0.083)	Loss 0.0402 (0.0400)	Acc@1 98.438 (99.093)	Acc@5 100.000 (100.000)\
Epoch: [65][60/94]	Time 0.076 (0.112)	Data 0.000 (0.043)	Loss 0.1027 (0.0434)	Acc@1 96.875 (99.129)	Acc@5 100.000 (100.000)\
Epoch: [65][90/94]	Time 0.068 (0.100)	Data 0.000 (0.030)	Loss 0.0178 (0.0429)	Acc@1 100.000 (99.056)	Acc@5 100.000 (100.000)\
 * Acc@1 99.082 Acc@5 100.000\
Test: [0/91]	Time 1.868 (1.868)	Loss 3.1096 (3.1096)	Acc@1 35.938 (35.938)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.390 (0.152)	Loss 2.6391 (3.0955)	Acc@1 46.875 (42.641)	Acc@5 71.875 (69.405)\
Test: [60/91]	Time 0.333 (0.125)	Loss 2.5949 (3.1177)	Acc@1 48.438 (41.726)	Acc@5 71.875 (68.878)\
Test: [90/91]	Time 0.012 (0.101)	Loss 2.6257 (3.1418)	Acc@1 50.000 (41.681)	Acc@5 73.529 (68.968)\
 * Acc@1 41.681 Acc@5 68.968\
tensor(5.3553, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0004689655486926553]\
Epoch: [66][0/94]	Time 1.647 (1.647)	Data 1.611 (1.611)	Loss 0.0316 (0.0316)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [66][30/94]	Time 0.065 (0.154)	Data 0.000 (0.089)	Loss 0.0261 (0.0326)	Acc@1 100.000 (99.546)	Acc@5 100.000 (100.000)\
Epoch: [66][60/94]	Time 0.160 (0.121)	Data 0.134 (0.057)	Loss 0.0297 (0.0353)	Acc@1 100.000 (99.385)	Acc@5 100.000 (100.000)\
Epoch: [66][90/94]	Time 0.065 (0.106)	Data 0.000 (0.040)	Loss 0.0722 (0.0374)	Acc@1 95.312 (99.262)	Acc@5 100.000 (100.000)\
 * Acc@1 99.249 Acc@5 100.000\
Test: [0/91]	Time 2.160 (2.160)	Loss 2.7474 (2.7474)	Acc@1 45.312 (45.312)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.071 (0.138)	Loss 3.5549 (3.2197)	Acc@1 39.062 (42.036)	Acc@5 67.188 (68.599)\
Test: [60/91]	Time 0.451 (0.120)	Loss 3.9114 (3.1780)	Acc@1 29.688 (41.291)	Acc@5 59.375 (68.315)\
Test: [90/91]	Time 0.012 (0.096)	Loss 3.6481 (3.1604)	Acc@1 38.235 (41.716)	Acc@5 70.588 (68.778)\
 * Acc@1 41.716 Acc@5 68.778\
tensor(5.3556, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.000447720223008213]\
Epoch: [67][0/94]	Time 1.987 (1.987)	Data 1.953 (1.953)	Loss 0.0959 (0.0959)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [67][30/94]	Time 0.069 (0.147)	Data 0.000 (0.079)	Loss 0.1149 (0.0522)	Acc@1 98.438 (98.942)	Acc@5 100.000 (99.950)\
Epoch: [67][60/94]	Time 0.063 (0.110)	Data 0.000 (0.042)	Loss 0.0769 (0.0466)	Acc@1 98.438 (99.103)	Acc@5 100.000 (99.974)\
Epoch: [67][90/94]	Time 0.069 (0.101)	Data 0.000 (0.033)	Loss 0.0629 (0.0465)	Acc@1 98.438 (98.935)	Acc@5 100.000 (99.983)\
 * Acc@1 98.949 Acc@5 99.983\
Test: [0/91]	Time 1.267 (1.267)	Loss 3.3213 (3.3213)	Acc@1 45.312 (45.312)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.243 (0.134)	Loss 3.5800 (3.1352)	Acc@1 43.750 (41.986)	Acc@5 65.625 (69.153)\
Test: [60/91]	Time 0.026 (0.117)	Loss 2.6559 (3.1443)	Acc@1 50.000 (41.752)	Acc@5 76.562 (68.955)\
Test: [90/91]	Time 0.012 (0.100)	Loss 3.5251 (3.1179)	Acc@1 29.412 (41.888)	Acc@5 64.706 (68.951)\
 * Acc@1 41.888 Acc@5 68.951\
tensor(5.3559, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0004274373643209659]\
Epoch: [68][0/94]	Time 1.401 (1.401)	Data 1.370 (1.370)	Loss 0.0334 (0.0334)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [68][30/94]	Time 0.072 (0.424)	Data 0.000 (0.353)	Loss 0.1272 (0.0493)	Acc@1 95.312 (98.992)	Acc@5 100.000 (100.000)\
Epoch: [68][60/94]	Time 0.079 (0.263)	Data 0.000 (0.196)	Loss 0.0300 (0.0452)	Acc@1 100.000 (99.052)	Acc@5 100.000 (100.000)\
Epoch: [68][90/94]	Time 0.070 (0.204)	Data 0.000 (0.138)	Loss 0.0425 (0.0432)	Acc@1 98.438 (99.073)	Acc@5 100.000 (100.000)\
 * Acc@1 99.082 Acc@5 100.000\
Test: [0/91]	Time 1.606 (1.606)	Loss 3.1366 (3.1366)	Acc@1 39.062 (39.062)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.115 (0.111)	Loss 2.7891 (3.1843)	Acc@1 46.875 (40.423)	Acc@5 70.312 (68.901)\
Test: [60/91]	Time 0.045 (0.090)	Loss 3.1134 (3.1721)	Acc@1 48.438 (41.342)	Acc@5 75.000 (69.134)\
Test: [90/91]	Time 0.014 (0.079)	Loss 2.1975 (3.1502)	Acc@1 55.882 (41.871)	Acc@5 79.412 (69.054)\
 * Acc@1 41.871 Acc@5 69.054\
tensor(5.3562, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0004080733704412155]\
Epoch: [69][0/94]	Time 1.488 (1.488)	Data 1.454 (1.454)	Loss 0.0243 (0.0243)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [69][30/94]	Time 0.268 (0.144)	Data 0.228 (0.077)	Loss 0.0591 (0.0344)	Acc@1 98.438 (99.446)	Acc@5 100.000 (100.000)\
Epoch: [69][60/94]	Time 0.072 (0.111)	Data 0.000 (0.040)	Loss 0.0453 (0.0369)	Acc@1 98.438 (99.436)	Acc@5 100.000 (100.000)\
Epoch: [69][90/94]	Time 0.066 (0.098)	Data 0.000 (0.028)	Loss 0.0674 (0.0411)	Acc@1 98.438 (99.279)	Acc@5 100.000 (99.983)\
 * Acc@1 99.266 Acc@5 99.983\
Test: [0/91]	Time 1.270 (1.270)	Loss 3.0961 (3.0961)	Acc@1 40.625 (40.625)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.025 (0.132)	Loss 2.2716 (3.1339)	Acc@1 42.188 (41.885)	Acc@5 82.812 (69.153)\
Test: [60/91]	Time 0.036 (0.108)	Loss 3.1323 (3.1429)	Acc@1 35.938 (41.624)	Acc@5 67.188 (68.955)\
Test: [90/91]	Time 0.012 (0.090)	Loss 3.0537 (3.1333)	Acc@1 38.235 (41.923)	Acc@5 67.647 (69.313)\
 * Acc@1 41.923 Acc@5 69.313\
tensor(5.3564, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.000389586614468756]\
Epoch: [70][0/94]	Time 1.435 (1.435)	Data 1.370 (1.370)	Loss 0.0118 (0.0118)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [70][30/94]	Time 0.066 (0.131)	Data 0.000 (0.062)	Loss 0.0592 (0.0452)	Acc@1 96.875 (98.841)	Acc@5 100.000 (100.000)\
Epoch: [70][60/94]	Time 0.076 (0.103)	Data 0.000 (0.033)	Loss 0.0361 (0.0434)	Acc@1 100.000 (98.975)	Acc@5 100.000 (100.000)\
Epoch: [70][90/94]	Time 0.065 (0.093)	Data 0.000 (0.022)	Loss 0.0427 (0.0429)	Acc@1 100.000 (98.953)	Acc@5 100.000 (100.000)\
 * Acc@1 98.966 Acc@5 100.000\
Test: [0/91]	Time 2.139 (2.139)	Loss 2.9722 (2.9722)	Acc@1 40.625 (40.625)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.019 (0.132)	Loss 2.2431 (3.1518)	Acc@1 51.562 (41.179)	Acc@5 71.875 (69.204)\
Test: [60/91]	Time 0.132 (0.107)	Loss 3.0886 (3.1343)	Acc@1 39.062 (41.829)	Acc@5 64.062 (69.237)\
Test: [90/91]	Time 0.012 (0.091)	Loss 2.7788 (3.1446)	Acc@1 38.235 (41.681)	Acc@5 73.529 (69.158)\
 * Acc@1 41.681 Acc@5 69.158\
tensor(5.3566, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0003719373553072644]\
Epoch: [71][0/94]	Time 1.372 (1.372)	Data 1.314 (1.314)	Loss 0.0288 (0.0288)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [71][30/94]	Time 0.084 (0.148)	Data 0.023 (0.089)	Loss 0.0364 (0.0397)	Acc@1 100.000 (99.042)	Acc@5 100.000 (100.000)\
Epoch: [71][60/94]	Time 0.100 (0.119)	Data 0.042 (0.061)	Loss 0.0349 (0.0417)	Acc@1 100.000 (99.103)	Acc@5 100.000 (99.974)\
Epoch: [71][90/94]	Time 0.070 (0.107)	Data 0.000 (0.045)	Loss 0.0601 (0.0421)	Acc@1 98.438 (99.107)	Acc@5 100.000 (99.966)\
 * Acc@1 99.082 Acc@5 99.967\
Test: [0/91]	Time 1.943 (1.943)	Loss 3.1770 (3.1770)	Acc@1 45.312 (45.312)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.019 (0.121)	Loss 2.6997 (3.1928)	Acc@1 48.438 (41.683)	Acc@5 71.875 (67.137)\
Test: [60/91]	Time 0.043 (0.101)	Loss 3.3693 (3.2126)	Acc@1 39.062 (41.470)	Acc@5 59.375 (68.340)\
Test: [90/91]	Time 0.012 (0.088)	Loss 2.4434 (3.1679)	Acc@1 47.059 (41.767)	Acc@5 76.471 (68.709)\
 * Acc@1 41.767 Acc@5 68.709\
tensor(5.3569, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00035508765223261175]\
Epoch: [72][0/94]	Time 1.731 (1.731)	Data 1.693 (1.693)	Loss 0.0120 (0.0120)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [72][30/94]	Time 0.103 (0.139)	Data 0.062 (0.073)	Loss 0.0917 (0.0430)	Acc@1 96.875 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [72][60/94]	Time 0.078 (0.111)	Data 0.010 (0.047)	Loss 0.0369 (0.0406)	Acc@1 98.438 (99.232)	Acc@5 100.000 (100.000)\
Epoch: [72][90/94]	Time 0.065 (0.100)	Data 0.000 (0.035)	Loss 0.0161 (0.0408)	Acc@1 100.000 (99.124)	Acc@5 100.000 (100.000)\
 * Acc@1 99.132 Acc@5 100.000\
Test: [0/91]	Time 1.345 (1.345)	Loss 3.5066 (3.5066)	Acc@1 39.062 (39.062)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.186 (0.134)	Loss 3.2509 (3.1744)	Acc@1 40.625 (41.784)	Acc@5 68.750 (69.607)\
Test: [60/91]	Time 0.078 (0.114)	Loss 3.2545 (3.1544)	Acc@1 43.750 (41.803)	Acc@5 73.438 (69.262)\
Test: [90/91]	Time 0.012 (0.094)	Loss 2.0427 (3.1318)	Acc@1 58.824 (41.733)	Acc@5 73.529 (69.175)\
 * Acc@1 41.733 Acc@5 69.175\
tensor(5.3573, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0003390012833314499]\
Epoch: [73][0/94]	Time 1.982 (1.982)	Data 1.940 (1.940)	Loss 0.0110 (0.0110)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [73][30/94]	Time 0.142 (0.149)	Data 0.116 (0.080)	Loss 0.0962 (0.0441)	Acc@1 98.438 (99.143)	Acc@5 98.438 (99.950)\
Epoch: [73][60/94]	Time 0.113 (0.120)	Data 0.066 (0.058)	Loss 0.0499 (0.0412)	Acc@1 98.438 (99.283)	Acc@5 100.000 (99.974)\
Epoch: [73][90/94]	Time 0.070 (0.108)	Data 0.000 (0.045)	Loss 0.0170 (0.0394)	Acc@1 100.000 (99.313)	Acc@5 100.000 (99.983)\
 * Acc@1 99.283 Acc@5 99.983\
Test: [0/91]	Time 1.633 (1.633)	Loss 2.7830 (2.7830)	Acc@1 54.688 (54.688)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.029 (0.113)	Loss 2.2511 (3.1347)	Acc@1 48.438 (41.784)	Acc@5 78.125 (68.952)\
Test: [60/91]	Time 0.142 (0.087)	Loss 2.9912 (3.1316)	Acc@1 45.312 (41.778)	Acc@5 70.312 (68.776)\
Test: [90/91]	Time 0.019 (0.076)	Loss 3.5890 (3.1726)	Acc@1 35.294 (41.957)	Acc@5 64.706 (68.864)\
 * Acc@1 41.957 Acc@5 68.864\
tensor(5.3576, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00032364366763473594]\
Epoch: [74][0/94]	Time 1.652 (1.652)	Data 1.595 (1.595)	Loss 0.0225 (0.0225)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [74][30/94]	Time 0.062 (0.136)	Data 0.000 (0.066)	Loss 0.0262 (0.0380)	Acc@1 100.000 (99.093)	Acc@5 100.000 (100.000)\
Epoch: [74][60/94]	Time 0.066 (0.113)	Data 0.028 (0.047)	Loss 0.0980 (0.0395)	Acc@1 96.875 (99.001)	Acc@5 100.000 (100.000)\
Epoch: [74][90/94]	Time 0.062 (0.103)	Data 0.000 (0.040)	Loss 0.0297 (0.0397)	Acc@1 98.438 (99.090)	Acc@5 100.000 (100.000)\
 * Acc@1 99.099 Acc@5 100.000\
Test: [0/91]	Time 1.496 (1.496)	Loss 3.8072 (3.8072)	Acc@1 34.375 (34.375)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.056 (0.127)	Loss 2.9691 (3.1697)	Acc@1 43.750 (42.742)	Acc@5 68.750 (69.758)\
Test: [60/91]	Time 0.035 (0.100)	Loss 2.9455 (3.1263)	Acc@1 51.562 (42.853)	Acc@5 68.750 (70.133)\
Test: [90/91]	Time 0.012 (0.085)	Loss 3.4551 (3.1683)	Acc@1 38.235 (41.785)	Acc@5 67.647 (69.158)\
 * Acc@1 41.785 Acc@5 69.158\
tensor(5.3578, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.000308981790778802]\
Epoch: [75][0/94]	Time 1.998 (1.998)	Data 1.956 (1.956)	Loss 0.0317 (0.0317)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [75][30/94]	Time 0.056 (0.152)	Data 0.000 (0.090)	Loss 0.0548 (0.0392)	Acc@1 98.438 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [75][60/94]	Time 0.074 (0.117)	Data 0.000 (0.051)	Loss 0.0219 (0.0378)	Acc@1 100.000 (99.257)	Acc@5 100.000 (99.974)\
Epoch: [75][90/94]	Time 0.065 (0.104)	Data 0.000 (0.040)	Loss 0.0289 (0.0384)	Acc@1 100.000 (99.296)	Acc@5 100.000 (99.983)\
 * Acc@1 99.316 Acc@5 99.983\
Test: [0/91]	Time 1.276 (1.276)	Loss 3.1675 (3.1675)	Acc@1 46.875 (46.875)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.329 (0.134)	Loss 3.2299 (3.1233)	Acc@1 37.500 (42.036)	Acc@5 70.312 (70.111)\
Test: [60/91]	Time 0.019 (0.106)	Loss 2.6853 (3.1388)	Acc@1 50.000 (41.880)	Acc@5 71.875 (69.621)\
Test: [90/91]	Time 0.012 (0.094)	Loss 2.8654 (3.1558)	Acc@1 41.176 (41.854)	Acc@5 76.471 (69.210)\
 * Acc@1 41.854 Acc@5 69.210\
tensor(5.3581, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0002949841340341698]\
Epoch: [76][0/94]	Time 1.544 (1.544)	Data 1.502 (1.502)	Loss 0.0421 (0.0421)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [76][30/94]	Time 0.060 (0.132)	Data 0.000 (0.060)	Loss 0.0120 (0.0350)	Acc@1 100.000 (99.446)	Acc@5 100.000 (99.950)\
Epoch: [76][60/94]	Time 0.063 (0.108)	Data 0.000 (0.042)	Loss 0.0167 (0.0401)	Acc@1 100.000 (99.180)	Acc@5 100.000 (99.974)\
Epoch: [76][90/94]	Time 0.066 (0.096)	Data 0.000 (0.029)	Loss 0.0101 (0.0409)	Acc@1 100.000 (99.193)	Acc@5 100.000 (99.983)\
 * Acc@1 99.216 Acc@5 99.983\
Test: [0/91]	Time 1.520 (1.520)	Loss 3.1255 (3.1255)	Acc@1 39.062 (39.062)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.128 (0.134)	Loss 3.1798 (3.2121)	Acc@1 43.750 (40.827)	Acc@5 68.750 (68.750)\
Test: [60/91]	Time 0.104 (0.103)	Loss 3.2457 (3.1450)	Acc@1 35.938 (41.547)	Acc@5 71.875 (69.262)\
Test: [90/91]	Time 0.015 (0.087)	Loss 2.8238 (3.1708)	Acc@1 47.059 (41.785)	Acc@5 79.412 (69.123)\
 * Acc@1 41.785 Acc@5 69.123\
tensor(5.3582, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0002816206065495396]\
Epoch: [77][0/94]	Time 1.409 (1.409)	Data 1.357 (1.357)	Loss 0.0349 (0.0349)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [77][30/94]	Time 0.075 (0.148)	Data 0.000 (0.092)	Loss 0.0324 (0.0341)	Acc@1 100.000 (99.294)	Acc@5 100.000 (100.000)\
Epoch: [77][60/94]	Time 0.068 (0.113)	Data 0.026 (0.054)	Loss 0.0606 (0.0406)	Acc@1 98.438 (99.103)	Acc@5 100.000 (100.000)\
Epoch: [77][90/94]	Time 0.065 (0.100)	Data 0.000 (0.039)	Loss 0.0537 (0.0432)	Acc@1 98.438 (99.073)	Acc@5 100.000 (99.983)\
 * Acc@1 99.049 Acc@5 99.983\
Test: [0/91]	Time 1.507 (1.507)	Loss 2.7992 (2.7992)	Acc@1 42.188 (42.188)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.032 (0.132)	Loss 3.3007 (3.1458)	Acc@1 45.312 (42.440)	Acc@5 65.625 (68.851)\
Test: [60/91]	Time 0.155 (0.110)	Loss 2.3734 (3.1304)	Acc@1 51.562 (41.983)	Acc@5 76.562 (69.185)\
Test: [90/91]	Time 0.012 (0.090)	Loss 2.7027 (3.1598)	Acc@1 52.941 (41.612)	Acc@5 73.529 (68.933)\
 * Acc@1 41.612 Acc@5 68.933\
tensor(5.3584, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0002688624806652944]\
Epoch: [78][0/94]	Time 1.686 (1.686)	Data 1.652 (1.652)	Loss 0.0331 (0.0331)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [78][30/94]	Time 0.077 (0.131)	Data 0.000 (0.070)	Loss 0.0792 (0.0423)	Acc@1 95.312 (98.841)	Acc@5 100.000 (100.000)\
Epoch: [78][60/94]	Time 0.059 (0.104)	Data 0.000 (0.040)	Loss 0.0144 (0.0428)	Acc@1 100.000 (98.899)	Acc@5 100.000 (100.000)\
Epoch: [78][90/94]	Time 0.070 (0.094)	Data 0.000 (0.027)	Loss 0.0178 (0.0401)	Acc@1 100.000 (99.073)	Acc@5 100.000 (100.000)\
 * Acc@1 99.082 Acc@5 100.000\
Test: [0/91]	Time 1.114 (1.114)	Loss 2.8709 (2.8709)	Acc@1 46.875 (46.875)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.115 (0.117)	Loss 3.1670 (3.1771)	Acc@1 43.750 (41.028)	Acc@5 68.750 (69.909)\
Test: [60/91]	Time 0.126 (0.100)	Loss 2.4357 (3.1210)	Acc@1 48.438 (41.931)	Acc@5 71.875 (69.826)\
Test: [90/91]	Time 0.012 (0.089)	Loss 3.1399 (3.1310)	Acc@1 41.176 (41.767)	Acc@5 73.529 (69.382)\
 * Acc@1 41.767 Acc@5 69.382\
tensor(5.3586, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00025668233015746944]\
Epoch: [79][0/94]	Time 1.761 (1.761)	Data 1.684 (1.684)	Loss 0.0189 (0.0189)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [79][30/94]	Time 0.065 (0.145)	Data 0.000 (0.074)	Loss 0.0677 (0.0383)	Acc@1 98.438 (99.244)	Acc@5 100.000 (99.950)\
Epoch: [79][60/94]	Time 0.075 (0.114)	Data 0.000 (0.046)	Loss 0.0421 (0.0361)	Acc@1 98.438 (99.308)	Acc@5 100.000 (99.974)\
Epoch: [79][90/94]	Time 0.075 (0.099)	Data 0.000 (0.031)	Loss 0.0607 (0.0373)	Acc@1 100.000 (99.313)	Acc@5 100.000 (99.983)\
 * Acc@1 99.283 Acc@5 99.983\
Test: [0/91]	Time 1.820 (1.820)	Loss 3.0885 (3.0885)	Acc@1 40.625 (40.625)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.107 (0.128)	Loss 3.3574 (3.1208)	Acc@1 37.500 (41.381)	Acc@5 65.625 (68.901)\
Test: [60/91]	Time 0.098 (0.114)	Loss 3.5284 (3.1271)	Acc@1 35.938 (41.317)	Acc@5 64.062 (68.827)\
Test: [90/91]	Time 0.016 (0.096)	Loss 3.0218 (3.1402)	Acc@1 50.000 (41.543)	Acc@5 61.765 (69.020)\
 * Acc@1 41.543 Acc@5 69.020\
tensor(5.3587, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00024505397127942577]\
Epoch: [80][0/94]	Time 1.537 (1.537)	Data 1.494 (1.494)	Loss 0.0381 (0.0381)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [80][30/94]	Time 0.066 (0.132)	Data 0.021 (0.064)	Loss 0.0105 (0.0352)	Acc@1 100.000 (99.294)	Acc@5 100.000 (100.000)\
Epoch: [80][60/94]	Time 0.076 (0.108)	Data 0.035 (0.043)	Loss 0.0463 (0.0353)	Acc@1 98.438 (99.308)	Acc@5 100.000 (100.000)\
Epoch: [80][90/94]	Time 0.066 (0.099)	Data 0.000 (0.036)	Loss 0.0855 (0.0360)	Acc@1 98.438 (99.296)	Acc@5 100.000 (100.000)\
 * Acc@1 99.316 Acc@5 100.000\
Test: [0/91]	Time 1.463 (1.463)	Loss 3.0330 (3.0330)	Acc@1 42.188 (42.188)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.036 (0.128)	Loss 2.8240 (3.1615)	Acc@1 46.875 (41.179)	Acc@5 71.875 (69.708)\
Test: [60/91]	Time 0.130 (0.114)	Loss 3.2828 (3.1082)	Acc@1 35.938 (42.008)	Acc@5 67.188 (69.570)\
Test: [90/91]	Time 0.012 (0.097)	Loss 2.2511 (3.1669)	Acc@1 41.176 (41.819)	Acc@5 76.471 (69.365)\
 * Acc@1 41.819 Acc@5 69.365\
tensor(5.3588, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00023395240647448254]\
Epoch: [81][0/94]	Time 1.406 (1.406)	Data 1.364 (1.364)	Loss 0.0187 (0.0187)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [81][30/94]	Time 0.080 (0.130)	Data 0.000 (0.056)	Loss 0.1074 (0.0415)	Acc@1 98.438 (99.143)	Acc@5 100.000 (100.000)\
Epoch: [81][60/94]	Time 0.075 (0.102)	Data 0.000 (0.029)	Loss 0.0142 (0.0402)	Acc@1 100.000 (99.232)	Acc@5 100.000 (100.000)\
Epoch: [81][90/94]	Time 0.065 (0.094)	Data 0.000 (0.027)	Loss 0.0085 (0.0382)	Acc@1 100.000 (99.245)	Acc@5 100.000 (100.000)\
 * Acc@1 99.266 Acc@5 100.000\
Test: [0/91]	Time 1.366 (1.366)	Loss 2.6086 (2.6086)	Acc@1 45.312 (45.312)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.028 (0.129)	Loss 3.3682 (3.2520)	Acc@1 39.062 (40.776)	Acc@5 65.625 (67.339)\
Test: [60/91]	Time 0.115 (0.103)	Loss 2.8296 (3.1943)	Acc@1 45.312 (41.522)	Acc@5 71.875 (68.750)\
Test: [90/91]	Time 0.012 (0.088)	Loss 2.6866 (3.1481)	Acc@1 50.000 (41.647)	Acc@5 76.471 (69.192)\
 * Acc@1 41.647 Acc@5 69.192\
tensor(5.3589, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00022335377063851234]\
Epoch: [82][0/94]	Time 1.794 (1.794)	Data 1.753 (1.753)	Loss 0.0514 (0.0514)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [82][30/94]	Time 0.080 (0.134)	Data 0.016 (0.070)	Loss 0.0416 (0.0380)	Acc@1 100.000 (99.345)	Acc@5 100.000 (99.950)\
Epoch: [82][60/94]	Time 0.073 (0.112)	Data 0.000 (0.050)	Loss 0.0181 (0.0411)	Acc@1 100.000 (99.155)	Acc@5 100.000 (99.974)\
Epoch: [82][90/94]	Time 0.065 (0.099)	Data 0.000 (0.036)	Loss 0.0349 (0.0404)	Acc@1 98.438 (99.141)	Acc@5 100.000 (99.966)\
 * Acc@1 99.166 Acc@5 99.967\
Test: [0/91]	Time 1.716 (1.716)	Loss 3.5875 (3.5875)	Acc@1 40.625 (40.625)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.033 (0.133)	Loss 3.1165 (3.1126)	Acc@1 40.625 (42.288)	Acc@5 73.438 (69.556)\
Test: [60/91]	Time 0.036 (0.103)	Loss 3.4944 (3.1840)	Acc@1 45.312 (41.598)	Acc@5 71.875 (68.519)\
Test: [90/91]	Time 0.012 (0.089)	Loss 3.3845 (3.1517)	Acc@1 41.176 (41.854)	Acc@5 64.706 (69.158)\
 * Acc@1 41.854 Acc@5 69.158\
tensor(5.3590, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00021323527981697614]\
Epoch: [83][0/94]	Time 1.370 (1.370)	Data 1.331 (1.331)	Loss 0.0167 (0.0167)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [83][30/94]	Time 0.065 (0.136)	Data 0.019 (0.079)	Loss 0.0304 (0.0408)	Acc@1 100.000 (98.992)	Acc@5 100.000 (100.000)\
Epoch: [83][60/94]	Time 0.160 (0.113)	Data 0.123 (0.055)	Loss 0.0391 (0.0396)	Acc@1 100.000 (98.975)	Acc@5 100.000 (100.000)\
Epoch: [83][90/94]	Time 0.069 (0.103)	Data 0.000 (0.042)	Loss 0.0540 (0.0383)	Acc@1 98.438 (99.090)	Acc@5 100.000 (99.983)\
 * Acc@1 99.082 Acc@5 99.983\
Test: [0/91]	Time 1.936 (1.936)	Loss 2.8754 (2.8754)	Acc@1 45.312 (45.312)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.168 (0.135)	Loss 3.5096 (3.1685)	Acc@1 43.750 (42.692)	Acc@5 64.062 (68.800)\
Test: [60/91]	Time 0.023 (0.112)	Loss 3.9531 (3.2020)	Acc@1 39.062 (42.059)	Acc@5 59.375 (68.366)\
Test: [90/91]	Time 0.012 (0.093)	Loss 3.0633 (3.1463)	Acc@1 44.118 (42.199)	Acc@5 76.471 (69.054)\
 * Acc@1 42.199 Acc@5 69.054\
tensor(5.3592, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00020357518222611083]\
Epoch: [84][0/94]	Time 1.619 (1.619)	Data 1.585 (1.585)	Loss 0.0167 (0.0167)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [84][30/94]	Time 0.088 (0.146)	Data 0.059 (0.080)	Loss 0.0259 (0.0394)	Acc@1 100.000 (99.143)	Acc@5 100.000 (99.899)\
Epoch: [84][60/94]	Time 0.071 (0.113)	Data 0.000 (0.049)	Loss 0.0305 (0.0381)	Acc@1 98.438 (99.206)	Acc@5 100.000 (99.949)\
Epoch: [84][90/94]	Time 0.068 (0.100)	Data 0.000 (0.035)	Loss 0.0301 (0.0382)	Acc@1 100.000 (99.107)	Acc@5 100.000 (99.966)\
 * Acc@1 99.116 Acc@5 99.967\
Test: [0/91]	Time 1.628 (1.628)	Loss 2.4470 (2.4470)	Acc@1 45.312 (45.312)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.103 (0.117)	Loss 3.1563 (3.2045)	Acc@1 43.750 (40.978)	Acc@5 71.875 (68.397)\
Test: [60/91]	Time 0.020 (0.098)	Loss 2.9248 (3.1642)	Acc@1 42.188 (41.803)	Acc@5 70.312 (68.852)\
Test: [90/91]	Time 0.012 (0.085)	Loss 2.5486 (3.1584)	Acc@1 41.176 (41.940)	Acc@5 76.471 (69.348)\
 * Acc@1 41.940 Acc@5 69.348\
tensor(5.3593, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00019435271149298265]\
Epoch: [85][0/94]	Time 1.763 (1.763)	Data 1.699 (1.699)	Loss 0.0147 (0.0147)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [85][30/94]	Time 0.072 (0.141)	Data 0.000 (0.067)	Loss 0.0108 (0.0346)	Acc@1 100.000 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [85][60/94]	Time 0.072 (0.108)	Data 0.000 (0.035)	Loss 0.0265 (0.0383)	Acc@1 100.000 (99.206)	Acc@5 100.000 (100.000)\
Epoch: [85][90/94]	Time 0.052 (0.097)	Data 0.000 (0.028)	Loss 0.0270 (0.0380)	Acc@1 100.000 (99.210)	Acc@5 100.000 (100.000)\
 * Acc@1 99.183 Acc@5 100.000\
Test: [0/91]	Time 1.541 (1.541)	Loss 3.2879 (3.2879)	Acc@1 39.062 (39.062)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.026 (0.137)	Loss 3.5638 (3.1947)	Acc@1 32.812 (42.137)	Acc@5 70.312 (69.002)\
Test: [60/91]	Time 0.021 (0.109)	Loss 2.5192 (3.0885)	Acc@1 43.750 (42.879)	Acc@5 81.250 (69.928)\
Test: [90/91]	Time 0.012 (0.091)	Loss 3.3611 (3.1444)	Acc@1 29.412 (42.026)	Acc@5 67.647 (69.175)\
 * Acc@1 42.026 Acc@5 69.175\
tensor(5.3594, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0001855480420138844]\
Epoch: [86][0/94]	Time 1.533 (1.533)	Data 1.500 (1.500)	Loss 0.0385 (0.0385)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [86][30/94]	Time 0.077 (0.136)	Data 0.043 (0.073)	Loss 0.0893 (0.0386)	Acc@1 98.438 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [86][60/94]	Time 0.108 (0.109)	Data 0.000 (0.043)	Loss 0.0299 (0.0354)	Acc@1 100.000 (99.334)	Acc@5 100.000 (100.000)\
Epoch: [86][90/94]	Time 0.066 (0.097)	Data 0.000 (0.029)	Loss 0.0276 (0.0351)	Acc@1 100.000 (99.348)	Acc@5 100.000 (100.000)\
 * Acc@1 99.333 Acc@5 100.000\
Test: [0/91]	Time 1.733 (1.733)	Loss 3.6612 (3.6612)	Acc@1 32.812 (32.812)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.019 (0.137)	Loss 3.7421 (3.0816)	Acc@1 40.625 (42.440)	Acc@5 62.500 (70.060)\
Test: [60/91]	Time 0.116 (0.116)	Loss 3.8886 (3.1395)	Acc@1 43.750 (42.111)	Acc@5 65.625 (69.723)\
Test: [90/91]	Time 0.012 (0.096)	Loss 2.7746 (3.1445)	Acc@1 41.176 (41.940)	Acc@5 67.647 (69.227)\
 * Acc@1 41.940 Acc@5 69.227\
tensor(5.3595, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00017714224633510854]\
Epoch: [87][0/94]	Time 1.434 (1.434)	Data 1.378 (1.378)	Loss 0.0246 (0.0246)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [87][30/94]	Time 0.060 (0.136)	Data 0.000 (0.064)	Loss 0.0307 (0.0288)	Acc@1 98.438 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [87][60/94]	Time 0.073 (0.105)	Data 0.000 (0.034)	Loss 0.0283 (0.0308)	Acc@1 100.000 (99.488)	Acc@5 100.000 (100.000)\
Epoch: [87][90/94]	Time 0.070 (0.094)	Data 0.000 (0.023)	Loss 0.0301 (0.0323)	Acc@1 98.438 (99.348)	Acc@5 100.000 (100.000)\
 * Acc@1 99.349 Acc@5 100.000\
Test: [0/91]	Time 2.118 (2.118)	Loss 3.0116 (3.0116)	Acc@1 39.062 (39.062)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.213 (0.133)	Loss 2.2819 (3.2020)	Acc@1 46.875 (41.532)	Acc@5 78.125 (68.296)\
Test: [60/91]	Time 0.027 (0.105)	Loss 3.5721 (3.1874)	Acc@1 39.062 (41.855)	Acc@5 65.625 (68.545)\
Test: [90/91]	Time 0.012 (0.084)	Loss 3.3448 (3.1622)	Acc@1 41.176 (41.871)	Acc@5 61.765 (69.071)\
 * Acc@1 41.871 Acc@5 69.071\
tensor(5.3596, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0001691172544644807]\
Epoch: [88][0/94]	Time 1.350 (1.350)	Data 1.317 (1.317)	Loss 0.0317 (0.0317)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [88][30/94]	Time 0.317 (0.155)	Data 0.280 (0.092)	Loss 0.0271 (0.0382)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [88][60/94]	Time 0.096 (0.122)	Data 0.052 (0.058)	Loss 0.0290 (0.0367)	Acc@1 98.438 (99.334)	Acc@5 100.000 (100.000)\
Epoch: [88][90/94]	Time 0.069 (0.108)	Data 0.000 (0.044)	Loss 0.0192 (0.0369)	Acc@1 100.000 (99.279)	Acc@5 100.000 (99.983)\
 * Acc@1 99.283 Acc@5 99.983\
Test: [0/91]	Time 1.450 (1.450)	Loss 3.8429 (3.8429)	Acc@1 31.250 (31.250)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.244 (0.123)	Loss 3.3596 (3.1784)	Acc@1 42.188 (40.726)	Acc@5 73.438 (68.700)\
Test: [60/91]	Time 0.027 (0.107)	Loss 4.2649 (3.1888)	Acc@1 34.375 (41.317)	Acc@5 64.062 (69.365)\
Test: [90/91]	Time 0.012 (0.087)	Loss 3.0529 (3.1630)	Acc@1 52.941 (42.043)	Acc@5 76.471 (69.037)\
 * Acc@1 42.043 Acc@5 69.037\
tensor(5.3597, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00016145581502618366]\
Epoch: [89][0/94]	Time 1.400 (1.400)	Data 1.346 (1.346)	Loss 0.0247 (0.0247)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [89][30/94]	Time 0.063 (0.137)	Data 0.000 (0.072)	Loss 0.0301 (0.0360)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [89][60/94]	Time 0.086 (0.106)	Data 0.000 (0.040)	Loss 0.0395 (0.0359)	Acc@1 100.000 (99.488)	Acc@5 100.000 (100.000)\
Epoch: [89][90/94]	Time 0.065 (0.095)	Data 0.000 (0.029)	Loss 0.0403 (0.0361)	Acc@1 98.438 (99.433)	Acc@5 100.000 (100.000)\
 * Acc@1 99.449 Acc@5 100.000\
Test: [0/91]	Time 1.888 (1.888)	Loss 3.3653 (3.3653)	Acc@1 39.062 (39.062)	Acc@5 59.375 (59.375)\
Test: [30/91]	Time 0.110 (0.126)	Loss 3.6763 (3.1753)	Acc@1 37.500 (41.583)	Acc@5 65.625 (68.800)\
Test: [60/91]	Time 0.031 (0.109)	Loss 2.9358 (3.1888)	Acc@1 42.188 (41.317)	Acc@5 71.875 (68.494)\
Test: [90/91]	Time 0.012 (0.094)	Loss 2.6465 (3.1611)	Acc@1 58.824 (42.164)	Acc@5 73.529 (69.261)\
 * Acc@1 42.164 Acc@5 69.261\
tensor(5.3598, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00015414145817536454]\
Epoch: [90][0/94]	Time 1.504 (1.504)	Data 1.456 (1.456)	Loss 0.0741 (0.0741)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [90][30/94]	Time 0.067 (0.138)	Data 0.000 (0.076)	Loss 0.0519 (0.0384)	Acc@1 98.438 (99.093)	Acc@5 100.000 (100.000)\
Epoch: [90][60/94]	Time 0.061 (0.107)	Data 0.000 (0.043)	Loss 0.0319 (0.0427)	Acc@1 98.438 (99.027)	Acc@5 100.000 (100.000)\
Epoch: [90][90/94]	Time 0.065 (0.096)	Data 0.000 (0.031)	Loss 0.0147 (0.0388)	Acc@1 100.000 (99.141)	Acc@5 100.000 (100.000)\
 * Acc@1 99.149 Acc@5 100.000\
Test: [0/91]	Time 1.105 (1.105)	Loss 3.0755 (3.0755)	Acc@1 42.188 (42.188)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.080 (0.112)	Loss 3.9847 (3.1063)	Acc@1 32.812 (42.540)	Acc@5 60.938 (69.506)\
Test: [60/91]	Time 0.049 (0.093)	Loss 3.2794 (3.1178)	Acc@1 45.312 (42.674)	Acc@5 71.875 (69.851)\
Test: [90/91]	Time 0.012 (0.084)	Loss 3.9855 (3.1663)	Acc@1 41.176 (41.957)	Acc@5 70.588 (69.106)\
 * Acc@1 41.957 Acc@5 69.106\
tensor(5.3599, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0001471584601928056]\
Epoch: [91][0/94]	Time 1.446 (1.446)	Data 1.418 (1.418)	Loss 0.0538 (0.0538)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [91][30/94]	Time 0.082 (0.140)	Data 0.000 (0.074)	Loss 0.0632 (0.0434)	Acc@1 98.438 (98.942)	Acc@5 100.000 (100.000)\
Epoch: [91][60/94]	Time 0.073 (0.107)	Data 0.000 (0.041)	Loss 0.0425 (0.0411)	Acc@1 100.000 (99.078)	Acc@5 100.000 (100.000)\
Epoch: [91][90/94]	Time 0.065 (0.095)	Data 0.000 (0.028)	Loss 0.0140 (0.0389)	Acc@1 100.000 (99.107)	Acc@5 100.000 (100.000)\
 * Acc@1 99.132 Acc@5 100.000\
Test: [0/91]	Time 1.429 (1.429)	Loss 2.8644 (2.8644)	Acc@1 43.750 (43.750)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.019 (0.105)	Loss 2.9245 (3.1214)	Acc@1 45.312 (42.893)	Acc@5 71.875 (70.161)\
Test: [60/91]	Time 0.054 (0.087)	Loss 2.1994 (3.1317)	Acc@1 46.875 (42.623)	Acc@5 73.438 (69.211)\
Test: [90/91]	Time 0.012 (0.074)	Loss 4.1287 (3.1622)	Acc@1 20.588 (42.026)	Acc@5 55.882 (69.037)\
 * Acc@1 42.026 Acc@5 69.037\
tensor(5.3599, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00014049180968354593]\
Epoch: [92][0/94]	Time 1.182 (1.182)	Data 1.150 (1.150)	Loss 0.0297 (0.0297)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [92][30/94]	Time 0.095 (0.125)	Data 0.000 (0.054)	Loss 0.0285 (0.0374)	Acc@1 100.000 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [92][60/94]	Time 0.044 (0.102)	Data 0.000 (0.035)	Loss 0.0727 (0.0360)	Acc@1 96.875 (99.180)	Acc@5 100.000 (100.000)\
Epoch: [92][90/94]	Time 0.072 (0.092)	Data 0.000 (0.024)	Loss 0.0190 (0.0349)	Acc@1 100.000 (99.227)	Acc@5 100.000 (100.000)\
 * Acc@1 99.249 Acc@5 100.000\
Test: [0/91]	Time 1.665 (1.665)	Loss 3.4231 (3.4231)	Acc@1 29.688 (29.688)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.041 (0.106)	Loss 3.7421 (3.2219)	Acc@1 39.062 (41.028)	Acc@5 67.188 (68.498)\
Test: [60/91]	Time 0.184 (0.090)	Loss 3.1520 (3.2108)	Acc@1 39.062 (41.214)	Acc@5 71.875 (68.340)\
Test: [90/91]	Time 0.012 (0.077)	Loss 3.5057 (3.1475)	Acc@1 41.176 (41.905)	Acc@5 67.647 (69.071)\
 * Acc@1 41.905 Acc@5 69.071\
tensor(5.3600, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00013412717530678984]\
Epoch: [93][0/94]	Time 1.457 (1.457)	Data 1.428 (1.428)	Loss 0.0362 (0.0362)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [93][30/94]	Time 0.075 (0.126)	Data 0.020 (0.060)	Loss 0.0161 (0.0383)	Acc@1 100.000 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [93][60/94]	Time 0.062 (0.102)	Data 0.000 (0.041)	Loss 0.0363 (0.0351)	Acc@1 98.438 (99.283)	Acc@5 100.000 (100.000)\
Epoch: [93][90/94]	Time 0.072 (0.093)	Data 0.000 (0.028)	Loss 0.0218 (0.0347)	Acc@1 100.000 (99.348)	Acc@5 100.000 (100.000)\
 * Acc@1 99.366 Acc@5 100.000\
Test: [0/91]	Time 1.095 (1.095)	Loss 3.5851 (3.5851)	Acc@1 39.062 (39.062)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.023 (0.102)	Loss 3.0045 (3.0612)	Acc@1 54.688 (43.145)	Acc@5 78.125 (70.262)\
Test: [60/91]	Time 0.028 (0.089)	Loss 3.6737 (3.1085)	Acc@1 32.812 (42.905)	Acc@5 65.625 (69.595)\
Test: [90/91]	Time 0.012 (0.077)	Loss 4.4746 (3.1515)	Acc@1 32.353 (42.009)	Acc@5 50.000 (69.002)\
 * Acc@1 42.009 Acc@5 69.002\
tensor(5.3601, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00012805087496773324]\
Epoch: [94][0/94]	Time 1.098 (1.098)	Data 1.062 (1.062)	Loss 0.0348 (0.0348)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [94][30/94]	Time 0.084 (0.123)	Data 0.000 (0.054)	Loss 0.0190 (0.0327)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [94][60/94]	Time 0.071 (0.099)	Data 0.000 (0.028)	Loss 0.0171 (0.0337)	Acc@1 100.000 (99.488)	Acc@5 100.000 (100.000)\
Epoch: [94][90/94]	Time 0.066 (0.090)	Data 0.000 (0.019)	Loss 0.0172 (0.0357)	Acc@1 100.000 (99.348)	Acc@5 100.000 (100.000)\
 * Acc@1 99.366 Acc@5 100.000\
Test: [0/91]	Time 1.184 (1.184)	Loss 3.1751 (3.1751)	Acc@1 39.062 (39.062)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.072 (0.106)	Loss 3.6271 (3.2084)	Acc@1 45.312 (42.188)	Acc@5 65.625 (67.792)\
Test: [60/91]	Time 0.024 (0.087)	Loss 3.5529 (3.1956)	Acc@1 32.812 (41.189)	Acc@5 67.188 (68.494)\
Test: [90/91]	Time 0.012 (0.075)	Loss 3.0494 (3.1595)	Acc@1 47.059 (41.819)	Acc@5 70.588 (69.175)\
 * Acc@1 41.819 Acc@5 69.175\
tensor(5.3602, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00012224984640507843]\
Epoch: [95][0/94]	Time 1.316 (1.316)	Data 1.276 (1.276)	Loss 0.0247 (0.0247)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [95][30/94]	Time 0.078 (0.124)	Data 0.000 (0.057)	Loss 0.0238 (0.0300)	Acc@1 100.000 (99.647)	Acc@5 100.000 (100.000)\
Epoch: [95][60/94]	Time 0.065 (0.101)	Data 0.000 (0.035)	Loss 0.0873 (0.0319)	Acc@1 98.438 (99.539)	Acc@5 100.000 (100.000)\
Epoch: [95][90/94]	Time 0.070 (0.092)	Data 0.000 (0.024)	Loss 0.0327 (0.0347)	Acc@1 98.438 (99.433)	Acc@5 100.000 (99.983)\
 * Acc@1 99.433 Acc@5 99.983\
Test: [0/91]	Time 1.158 (1.158)	Loss 3.0439 (3.0439)	Acc@1 42.188 (42.188)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.063 (0.111)	Loss 2.6355 (3.1938)	Acc@1 42.188 (41.986)	Acc@5 76.562 (68.548)\
Test: [60/91]	Time 0.040 (0.090)	Loss 3.1234 (3.1647)	Acc@1 46.875 (41.829)	Acc@5 68.750 (69.160)\
Test: [90/91]	Time 0.012 (0.078)	Loss 2.4622 (3.1401)	Acc@1 44.118 (42.130)	Acc@5 85.294 (68.882)\
 * Acc@1 42.130 Acc@5 68.882\
tensor(5.3603, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00011671161911100682]\
Epoch: [96][0/94]	Time 1.258 (1.258)	Data 1.221 (1.221)	Loss 0.0330 (0.0330)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [96][30/94]	Time 0.071 (0.116)	Data 0.000 (0.045)	Loss 0.0371 (0.0304)	Acc@1 100.000 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [96][60/94]	Time 0.079 (0.096)	Data 0.000 (0.025)	Loss 0.0243 (0.0315)	Acc@1 100.000 (99.488)	Acc@5 100.000 (100.000)\
Epoch: [96][90/94]	Time 0.065 (0.089)	Data 0.000 (0.017)	Loss 0.0405 (0.0345)	Acc@1 100.000 (99.313)	Acc@5 100.000 (100.000)\
 * Acc@1 99.299 Acc@5 100.000\
Test: [0/91]	Time 1.866 (1.866)	Loss 2.7799 (2.7799)	Acc@1 42.188 (42.188)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.032 (0.104)	Loss 2.6552 (3.1700)	Acc@1 50.000 (42.843)	Acc@5 76.562 (68.599)\
Test: [60/91]	Time 0.019 (0.085)	Loss 2.9935 (3.1917)	Acc@1 45.312 (41.778)	Acc@5 71.875 (68.699)\
Test: [90/91]	Time 0.016 (0.076)	Loss 3.4333 (3.1572)	Acc@1 38.235 (41.802)	Acc@5 52.941 (68.968)\
 * Acc@1 41.802 Acc@5 68.968\
tensor(5.3604, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00011142428752325099]\
Epoch: [97][0/94]	Time 1.139 (1.139)	Data 1.076 (1.076)	Loss 0.0314 (0.0314)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [97][30/94]	Time 0.074 (0.119)	Data 0.000 (0.046)	Loss 0.0330 (0.0334)	Acc@1 100.000 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [97][60/94]	Time 0.067 (0.095)	Data 0.000 (0.026)	Loss 0.0121 (0.0341)	Acc@1 100.000 (99.283)	Acc@5 100.000 (100.000)\
Epoch: [97][90/94]	Time 0.068 (0.088)	Data 0.000 (0.018)	Loss 0.0233 (0.0328)	Acc@1 100.000 (99.416)	Acc@5 100.000 (99.983)\
 * Acc@1 99.433 Acc@5 99.983\
Test: [0/91]	Time 1.070 (1.070)	Loss 3.4700 (3.4700)	Acc@1 39.062 (39.062)	Acc@5 59.375 (59.375)\
Test: [30/91]	Time 0.023 (0.112)	Loss 4.3269 (3.2487)	Acc@1 32.812 (42.540)	Acc@5 60.938 (67.994)\
Test: [60/91]	Time 0.052 (0.087)	Loss 4.0278 (3.1792)	Acc@1 31.250 (41.957)	Acc@5 65.625 (68.724)\
Test: [90/91]	Time 0.012 (0.074)	Loss 2.5768 (3.1603)	Acc@1 47.059 (41.888)	Acc@5 76.471 (68.951)\
 * Acc@1 41.888 Acc@5 68.951\
tensor(5.3605, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.00010637648543163141]\
Epoch: [98][0/94]	Time 1.901 (1.901)	Data 1.847 (1.847)	Loss 0.0587 (0.0587)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [98][30/94]	Time 0.086 (0.135)	Data 0.000 (0.061)	Loss 0.0337 (0.0413)	Acc@1 100.000 (99.143)	Acc@5 100.000 (100.000)\
Epoch: [98][60/94]	Time 0.079 (0.105)	Data 0.000 (0.032)	Loss 0.0341 (0.0380)	Acc@1 98.438 (99.155)	Acc@5 100.000 (100.000)\
Epoch: [98][90/94]	Time 0.066 (0.094)	Data 0.000 (0.022)	Loss 0.0245 (0.0372)	Acc@1 100.000 (99.159)	Acc@5 100.000 (100.000)\
 * Acc@1 99.183 Acc@5 100.000\
Test: [0/91]	Time 1.727 (1.727)	Loss 3.4308 (3.4308)	Acc@1 32.812 (32.812)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.019 (0.110)	Loss 4.5063 (3.1599)	Acc@1 28.125 (41.230)	Acc@5 56.250 (68.095)\
Test: [60/91]	Time 0.042 (0.085)	Loss 3.3058 (3.1586)	Acc@1 40.625 (42.264)	Acc@5 64.062 (69.083)\
Test: [90/91]	Time 0.015 (0.072)	Loss 2.8856 (3.1761)	Acc@1 50.000 (42.113)	Acc@5 79.412 (69.261)\
 * Acc@1 42.113 Acc@5 69.261\
tensor(5.3605, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [0.0001015573615440418]\
Epoch: [99][0/94]	Time 1.143 (1.143)	Data 1.093 (1.093)	Loss 0.0292 (0.0292)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [99][30/94]	Time 0.071 (0.119)	Data 0.000 (0.046)	Loss 0.0195 (0.0339)	Acc@1 100.000 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [99][60/94]	Time 0.079 (0.098)	Data 0.000 (0.024)	Loss 0.0176 (0.0344)	Acc@1 100.000 (99.180)	Acc@5 100.000 (100.000)\
Epoch: [99][90/94]	Time 0.072 (0.090)	Data 0.000 (0.017)	Loss 0.0237 (0.0338)	Acc@1 100.000 (99.279)	Acc@5 100.000 (100.000)\
 * Acc@1 99.266 Acc@5 100.000\
Test: [0/91]	Time 1.095 (1.095)	Loss 2.9789 (2.9789)	Acc@1 43.750 (43.750)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.031 (0.091)	Loss 3.0039 (3.1747)	Acc@1 48.438 (41.532)	Acc@5 70.312 (67.742)\
Test: [60/91]	Time 0.030 (0.083)	Loss 3.8532 (3.2032)	Acc@1 28.125 (41.342)	Acc@5 65.625 (68.750)\
Test: [90/91]	Time 0.012 (0.069)	Loss 4.1791 (3.1640)	Acc@1 29.412 (41.888)	Acc@5 58.824 (69.330)\
 * Acc@1 41.888 Acc@5 69.330\
tensor(5.3606, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [9.695655615935915e-05]\
Epoch: [100][0/94]	Time 1.149 (1.149)	Data 1.097 (1.097)	Loss 0.0084 (0.0084)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [100][30/94]	Time 0.081 (0.128)	Data 0.000 (0.050)	Loss 0.0571 (0.0362)	Acc@1 96.875 (99.093)	Acc@5 100.000 (100.000)\
Epoch: [100][60/94]	Time 0.084 (0.102)	Data 0.000 (0.026)	Loss 0.0218 (0.0362)	Acc@1 100.000 (99.155)	Acc@5 100.000 (100.000)\
Epoch: [100][90/94]	Time 0.072 (0.092)	Data 0.000 (0.018)	Loss 0.0547 (0.0363)	Acc@1 98.438 (99.176)	Acc@5 100.000 (100.000)\
 * Acc@1 99.199 Acc@5 100.000\
Test: [0/91]	Time 1.572 (1.572)	Loss 3.2329 (3.2329)	Acc@1 34.375 (34.375)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.032 (0.102)	Loss 2.9416 (3.1847)	Acc@1 42.188 (41.179)	Acc@5 68.750 (68.750)\
Test: [60/91]	Time 0.040 (0.084)	Loss 3.5828 (3.2255)	Acc@1 34.375 (41.137)	Acc@5 62.500 (68.571)\
Test: [90/91]	Time 0.016 (0.072)	Loss 3.7751 (3.1728)	Acc@1 35.294 (41.923)	Acc@5 61.765 (69.279)\
 * Acc@1 41.923 Acc@5 69.279\
tensor(5.3607, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [9.256417889712791e-05]\
Epoch: [101][0/94]	Time 1.659 (1.659)	Data 1.614 (1.614)	Loss 0.0179 (0.0179)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [101][30/94]	Time 0.077 (0.127)	Data 0.000 (0.054)	Loss 0.0264 (0.0331)	Acc@1 100.000 (99.294)	Acc@5 100.000 (100.000)\
Epoch: [101][60/94]	Time 0.065 (0.102)	Data 0.000 (0.028)	Loss 0.0396 (0.0322)	Acc@1 100.000 (99.360)	Acc@5 100.000 (100.000)\
Epoch: [101][90/94]	Time 0.071 (0.092)	Data 0.000 (0.020)	Loss 0.0279 (0.0326)	Acc@1 100.000 (99.451)	Acc@5 100.000 (100.000)\
 * Acc@1 99.449 Acc@5 100.000\
Test: [0/91]	Time 1.374 (1.374)	Loss 3.3326 (3.3326)	Acc@1 39.062 (39.062)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.040 (0.113)	Loss 3.7565 (3.2418)	Acc@1 39.062 (39.768)	Acc@5 60.938 (67.440)\
Test: [60/91]	Time 0.019 (0.090)	Loss 3.2214 (3.1486)	Acc@1 40.625 (41.547)	Acc@5 71.875 (69.314)\
Test: [90/91]	Time 0.012 (0.079)	Loss 2.1861 (3.1596)	Acc@1 52.941 (41.836)	Acc@5 73.529 (68.985)\
 * Acc@1 41.836 Acc@5 68.985\
tensor(5.3607, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [8.837078743614603e-05]\
Epoch: [102][0/94]	Time 1.646 (1.646)	Data 1.615 (1.615)	Loss 0.0475 (0.0475)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [102][30/94]	Time 0.084 (0.128)	Data 0.000 (0.055)	Loss 0.0286 (0.0372)	Acc@1 98.438 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [102][60/94]	Time 0.072 (0.103)	Data 0.000 (0.029)	Loss 0.0164 (0.0375)	Acc@1 100.000 (99.232)	Acc@5 100.000 (100.000)\
Epoch: [102][90/94]	Time 0.065 (0.094)	Data 0.000 (0.020)	Loss 0.0126 (0.0351)	Acc@1 100.000 (99.330)	Acc@5 100.000 (100.000)\
 * Acc@1 99.316 Acc@5 100.000\
Test: [0/91]	Time 1.192 (1.192)	Loss 3.0401 (3.0401)	Acc@1 43.750 (43.750)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.206 (0.109)	Loss 3.7779 (3.1314)	Acc@1 26.562 (40.524)	Acc@5 59.375 (69.556)\
Test: [60/91]	Time 0.085 (0.085)	Loss 2.5751 (3.1741)	Acc@1 43.750 (41.035)	Acc@5 79.688 (69.288)\
Test: [90/91]	Time 0.012 (0.076)	Loss 2.4026 (3.1638)	Acc@1 50.000 (41.957)	Acc@5 73.529 (69.279)\
 * Acc@1 41.957 Acc@5 69.279\
tensor(5.3608, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [8.436736721624843e-05]\
Epoch: [103][0/94]	Time 1.357 (1.357)	Data 1.313 (1.313)	Loss 0.0499 (0.0499)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [103][30/94]	Time 0.088 (0.122)	Data 0.000 (0.055)	Loss 0.0639 (0.0385)	Acc@1 98.438 (99.244)	Acc@5 100.000 (100.000)\
Epoch: [103][60/94]	Time 0.067 (0.101)	Data 0.000 (0.030)	Loss 0.0531 (0.0365)	Acc@1 98.438 (99.308)	Acc@5 100.000 (100.000)\
Epoch: [103][90/94]	Time 0.065 (0.092)	Data 0.000 (0.020)	Loss 0.0653 (0.0357)	Acc@1 98.438 (99.262)	Acc@5 100.000 (100.000)\
 * Acc@1 99.249 Acc@5 100.000\
Test: [0/91]	Time 1.637 (1.637)	Loss 2.9473 (2.9473)	Acc@1 46.875 (46.875)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.032 (0.107)	Loss 2.3822 (3.1565)	Acc@1 54.688 (41.331)	Acc@5 73.438 (69.103)\
Test: [60/91]	Time 0.116 (0.095)	Loss 3.4451 (3.1637)	Acc@1 39.062 (41.726)	Acc@5 70.312 (69.211)\
Test: [90/91]	Time 0.012 (0.077)	Loss 3.7417 (3.1727)	Acc@1 50.000 (41.871)	Acc@5 61.765 (69.192)\
 * Acc@1 41.871 Acc@5 69.192\
tensor(5.3608, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [8.05453120596494e-05]\
Epoch: [104][0/94]	Time 1.141 (1.141)	Data 1.092 (1.092)	Loss 0.0351 (0.0351)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [104][30/94]	Time 0.063 (0.117)	Data 0.000 (0.051)	Loss 0.0235 (0.0349)	Acc@1 100.000 (99.345)	Acc@5 100.000 (100.000)\
Epoch: [104][60/94]	Time 0.066 (0.097)	Data 0.000 (0.027)	Loss 0.0380 (0.0346)	Acc@1 100.000 (99.411)	Acc@5 100.000 (100.000)\
Epoch: [104][90/94]	Time 0.072 (0.089)	Data 0.000 (0.019)	Loss 0.0468 (0.0344)	Acc@1 96.875 (99.399)	Acc@5 100.000 (100.000)\
 * Acc@1 99.399 Acc@5 100.000\
Test: [0/91]	Time 1.266 (1.266)	Loss 2.6579 (2.6579)	Acc@1 54.688 (54.688)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.052 (0.100)	Loss 3.7305 (3.1684)	Acc@1 43.750 (41.734)	Acc@5 64.062 (69.405)\
Test: [60/91]	Time 0.032 (0.081)	Loss 2.8287 (3.0941)	Acc@1 46.875 (42.828)	Acc@5 75.000 (70.184)\
Test: [90/91]	Time 0.012 (0.072)	Loss 3.7509 (3.1617)	Acc@1 38.235 (42.078)	Acc@5 52.941 (69.296)\
 * Acc@1 42.078 Acc@5 69.296\
tensor(5.3609, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [7.689640567018717e-05]\
Epoch: [105][0/94]	Time 1.210 (1.210)	Data 1.178 (1.178)	Loss 0.0342 (0.0342)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [105][30/94]	Time 0.088 (0.115)	Data 0.000 (0.040)	Loss 0.0212 (0.0378)	Acc@1 100.000 (99.244)	Acc@5 100.000 (100.000)\
Epoch: [105][60/94]	Time 0.080 (0.096)	Data 0.000 (0.021)	Loss 0.0253 (0.0364)	Acc@1 98.438 (99.232)	Acc@5 100.000 (100.000)\
Epoch: [105][90/94]	Time 0.066 (0.089)	Data 0.000 (0.015)	Loss 0.0292 (0.0359)	Acc@1 100.000 (99.279)	Acc@5 100.000 (100.000)\
 * Acc@1 99.283 Acc@5 100.000\
Test: [0/91]	Time 1.707 (1.707)	Loss 3.6281 (3.6281)	Acc@1 42.188 (42.188)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.032 (0.103)	Loss 3.3091 (3.1138)	Acc@1 42.188 (42.238)	Acc@5 71.875 (69.909)\
Test: [60/91]	Time 0.026 (0.082)	Loss 3.1056 (3.1270)	Acc@1 34.375 (42.597)	Acc@5 75.000 (69.877)\
Test: [90/91]	Time 0.012 (0.074)	Loss 3.0159 (3.1653)	Acc@1 47.059 (42.043)	Acc@5 70.588 (69.192)\
 * Acc@1 42.043 Acc@5 69.192\
tensor(5.3609, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [7.341280397070115e-05]\
Epoch: [106][0/94]	Time 1.096 (1.096)	Data 1.051 (1.051)	Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [106][30/94]	Time 0.077 (0.128)	Data 0.000 (0.053)	Loss 0.0136 (0.0301)	Acc@1 100.000 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [106][60/94]	Time 0.088 (0.102)	Data 0.000 (0.028)	Loss 0.0514 (0.0332)	Acc@1 98.438 (99.411)	Acc@5 100.000 (100.000)\
Epoch: [106][90/94]	Time 0.070 (0.092)	Data 0.000 (0.019)	Loss 0.0221 (0.0332)	Acc@1 100.000 (99.365)	Acc@5 100.000 (100.000)\
 * Acc@1 99.366 Acc@5 100.000\
Test: [0/91]	Time 1.930 (1.930)	Loss 3.8727 (3.8727)	Acc@1 37.500 (37.500)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.036 (0.119)	Loss 2.9810 (3.1947)	Acc@1 43.750 (42.540)	Acc@5 68.750 (69.103)\
Test: [60/91]	Time 0.059 (0.088)	Loss 3.0898 (3.1666)	Acc@1 43.750 (42.597)	Acc@5 65.625 (69.390)\
Test: [90/91]	Time 0.012 (0.077)	Loss 3.5704 (3.1750)	Acc@1 44.118 (41.923)	Acc@5 55.882 (69.175)\
 * Acc@1 41.923 Acc@5 69.175\
tensor(5.3610, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [7.008701824056907e-05]\
Epoch: [107][0/94]	Time 1.088 (1.088)	Data 1.042 (1.042)	Loss 0.0342 (0.0342)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [107][30/94]	Time 0.076 (0.117)	Data 0.000 (0.046)	Loss 0.0360 (0.0338)	Acc@1 100.000 (99.345)	Acc@5 100.000 (100.000)\
Epoch: [107][60/94]	Time 0.058 (0.096)	Data 0.000 (0.026)	Loss 0.0340 (0.0335)	Acc@1 100.000 (99.385)	Acc@5 100.000 (100.000)\
Epoch: [107][90/94]	Time 0.065 (0.088)	Data 0.000 (0.018)	Loss 0.0447 (0.0341)	Acc@1 98.438 (99.399)	Acc@5 100.000 (100.000)\
 * Acc@1 99.383 Acc@5 100.000\
Test: [0/91]	Time 1.067 (1.067)	Loss 2.6986 (2.6986)	Acc@1 45.312 (45.312)	Acc@5 78.125 (78.125)\
Test: [30/91]	Time 0.035 (0.109)	Loss 4.0081 (3.1906)	Acc@1 37.500 (41.885)	Acc@5 64.062 (70.060)\
Test: [60/91]	Time 0.144 (0.088)	Loss 3.2225 (3.1518)	Acc@1 39.062 (42.059)	Acc@5 64.062 (69.928)\
Test: [90/91]	Time 0.012 (0.075)	Loss 2.5486 (3.1625)	Acc@1 50.000 (41.871)	Acc@5 76.471 (69.106)\
 * Acc@1 41.871 Acc@5 69.106\
tensor(5.3610, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [6.691189901715636e-05]\
Epoch: [108][0/94]	Time 1.564 (1.564)	Data 1.521 (1.521)	Loss 0.0631 (0.0631)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [108][30/94]	Time 0.078 (0.123)	Data 0.000 (0.051)	Loss 0.0353 (0.0411)	Acc@1 100.000 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [108][60/94]	Time 0.093 (0.101)	Data 0.000 (0.026)	Loss 0.1509 (0.0402)	Acc@1 95.312 (99.257)	Acc@5 100.000 (99.974)\
Epoch: [108][90/94]	Time 0.065 (0.091)	Data 0.000 (0.019)	Loss 0.0348 (0.0361)	Acc@1 98.438 (99.382)	Acc@5 100.000 (99.983)\
 * Acc@1 99.399 Acc@5 99.983\
Test: [0/91]	Time 1.475 (1.475)	Loss 2.9797 (2.9797)	Acc@1 43.750 (43.750)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.020 (0.099)	Loss 3.1440 (3.2727)	Acc@1 39.062 (40.675)	Acc@5 68.750 (67.540)\
Test: [60/91]	Time 0.029 (0.084)	Loss 2.4779 (3.2010)	Acc@1 48.438 (41.240)	Acc@5 75.000 (68.417)\
Test: [90/91]	Time 0.012 (0.074)	Loss 3.9641 (3.1681)	Acc@1 35.294 (41.819)	Acc@5 55.882 (69.054)\
 * Acc@1 41.819 Acc@5 69.054\
tensor(5.3611, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [6.388062072657205e-05]\
Epoch: [109][0/94]	Time 1.150 (1.150)	Data 1.109 (1.109)	Loss 0.0474 (0.0474)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [109][30/94]	Time 0.092 (0.117)	Data 0.000 (0.045)	Loss 0.0227 (0.0392)	Acc@1 100.000 (99.042)	Acc@5 100.000 (100.000)\
Epoch: [109][60/94]	Time 0.065 (0.095)	Data 0.000 (0.024)	Loss 0.0404 (0.0355)	Acc@1 100.000 (99.206)	Acc@5 100.000 (100.000)\
Epoch: [109][90/94]	Time 0.070 (0.088)	Data 0.000 (0.016)	Loss 0.0254 (0.0370)	Acc@1 100.000 (99.176)	Acc@5 100.000 (100.000)\
 * Acc@1 99.199 Acc@5 100.000\
Test: [0/91]	Time 1.139 (1.139)	Loss 2.6645 (2.6645)	Acc@1 50.000 (50.000)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.040 (0.099)	Loss 3.4917 (3.1193)	Acc@1 37.500 (42.540)	Acc@5 68.750 (70.413)\
Test: [60/91]	Time 0.069 (0.084)	Loss 2.5912 (3.1749)	Acc@1 48.438 (42.418)	Acc@5 73.438 (69.365)\
Test: [90/91]	Time 0.016 (0.073)	Loss 3.6053 (3.2008)	Acc@1 44.118 (41.992)	Acc@5 64.706 (69.071)\
 * Acc@1 41.992 Acc@5 69.071\
tensor(5.3611, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [6.0986667010688885e-05]\
Epoch: [110][0/94]	Time 1.583 (1.583)	Data 1.557 (1.557)	Loss 0.0116 (0.0116)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [110][30/94]	Time 0.071 (0.128)	Data 0.000 (0.054)	Loss 0.0333 (0.0359)	Acc@1 98.438 (99.093)	Acc@5 100.000 (100.000)\
Epoch: [110][60/94]	Time 0.068 (0.102)	Data 0.000 (0.029)	Loss 0.0760 (0.0347)	Acc@1 98.438 (99.103)	Acc@5 100.000 (100.000)\
Epoch: [110][90/94]	Time 0.065 (0.092)	Data 0.000 (0.020)	Loss 0.0090 (0.0322)	Acc@1 100.000 (99.245)	Acc@5 100.000 (100.000)\
 * Acc@1 99.249 Acc@5 100.000\
Test: [0/91]	Time 1.555 (1.555)	Loss 3.6239 (3.6239)	Acc@1 40.625 (40.625)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.020 (0.105)	Loss 2.9209 (3.1267)	Acc@1 43.750 (41.482)	Acc@5 70.312 (69.960)\
Test: [60/91]	Time 0.020 (0.086)	Loss 3.4518 (3.1411)	Acc@1 42.188 (41.778)	Acc@5 79.688 (69.621)\
Test: [90/91]	Time 0.012 (0.073)	Loss 2.2830 (3.1670)	Acc@1 50.000 (41.836)	Acc@5 73.529 (69.210)\
 * Acc@1 41.836 Acc@5 69.210\
tensor(5.3611, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [5.82238167188866e-05]\
Epoch: [111][0/94]	Time 1.091 (1.091)	Data 1.045 (1.045)	Loss 0.0549 (0.0549)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [111][30/94]	Time 0.075 (0.124)	Data 0.000 (0.050)	Loss 0.0597 (0.0323)	Acc@1 98.438 (99.345)	Acc@5 100.000 (100.000)\
Epoch: [111][60/94]	Time 0.066 (0.100)	Data 0.000 (0.026)	Loss 0.0482 (0.0334)	Acc@1 98.438 (99.257)	Acc@5 100.000 (100.000)\
Epoch: [111][90/94]	Time 0.072 (0.092)	Data 0.000 (0.018)	Loss 0.0781 (0.0331)	Acc@1 98.438 (99.262)	Acc@5 100.000 (100.000)\
 * Acc@1 99.233 Acc@5 100.000\
Test: [0/91]	Time 1.656 (1.656)	Loss 3.3526 (3.3526)	Acc@1 43.750 (43.750)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.075 (0.107)	Loss 2.8923 (3.2403)	Acc@1 40.625 (41.935)	Acc@5 78.125 (68.599)\
Test: [60/91]	Time 0.065 (0.086)	Loss 2.0793 (3.2131)	Acc@1 57.812 (41.547)	Acc@5 78.125 (68.724)\
Test: [90/91]	Time 0.012 (0.073)	Loss 2.5647 (3.1874)	Acc@1 41.176 (41.957)	Acc@5 76.471 (69.123)\
 * Acc@1 41.957 Acc@5 69.123\
tensor(5.3612, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [5.5586130534405916e-05]\
Epoch: [112][0/94]	Time 1.112 (1.112)	Data 1.067 (1.067)	Loss 0.0124 (0.0124)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [112][30/94]	Time 0.066 (0.122)	Data 0.000 (0.050)	Loss 0.0079 (0.0371)	Acc@1 100.000 (99.042)	Acc@5 100.000 (100.000)\
Epoch: [112][60/94]	Time 0.079 (0.099)	Data 0.000 (0.026)	Loss 0.0085 (0.0354)	Acc@1 100.000 (99.206)	Acc@5 100.000 (100.000)\
Epoch: [112][90/94]	Time 0.071 (0.090)	Data 0.000 (0.018)	Loss 0.0473 (0.0366)	Acc@1 100.000 (99.090)	Acc@5 100.000 (100.000)\
 * Acc@1 99.099 Acc@5 99.983\
Test: [0/91]	Time 1.640 (1.640)	Loss 3.9191 (3.9191)	Acc@1 35.938 (35.938)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.026 (0.114)	Loss 3.5731 (3.0440)	Acc@1 39.062 (44.355)	Acc@5 65.625 (70.968)\
Test: [60/91]	Time 0.031 (0.091)	Loss 3.8695 (3.1431)	Acc@1 42.188 (42.546)	Acc@5 59.375 (69.442)\
Test: [90/91]	Time 0.012 (0.070)	Loss 2.9431 (3.1729)	Acc@1 35.294 (41.767)	Acc@5 73.529 (69.020)\
 * Acc@1 41.767 Acc@5 69.020\
tensor(5.3612, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [5.306793820656121e-05]\
Epoch: [113][0/94]	Time 0.791 (0.791)	Data 0.750 (0.750)	Loss 0.0284 (0.0284)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [113][30/94]	Time 0.075 (0.096)	Data 0.000 (0.026)	Loss 0.0483 (0.0347)	Acc@1 100.000 (99.244)	Acc@5 100.000 (100.000)\
Epoch: [113][60/94]	Time 0.062 (0.086)	Data 0.000 (0.014)	Loss 0.0215 (0.0351)	Acc@1 100.000 (99.257)	Acc@5 100.000 (100.000)\
Epoch: [113][90/94]	Time 0.072 (0.083)	Data 0.000 (0.010)	Loss 0.0525 (0.0349)	Acc@1 98.438 (99.193)	Acc@5 100.000 (100.000)\
 * Acc@1 99.199 Acc@5 100.000\
Test: [0/91]	Time 1.448 (1.448)	Loss 3.6977 (3.6977)	Acc@1 34.375 (34.375)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.071 (0.114)	Loss 2.7991 (3.1373)	Acc@1 46.875 (42.389)	Acc@5 73.438 (71.069)\
Test: [60/91]	Time 0.032 (0.088)	Loss 2.5970 (3.1552)	Acc@1 45.312 (42.213)	Acc@5 76.562 (69.775)\
Test: [90/91]	Time 0.012 (0.074)	Loss 3.3731 (3.1673)	Acc@1 44.118 (42.061)	Acc@5 79.412 (69.106)\
 * Acc@1 42.061 Acc@5 69.106\
tensor(5.3612, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [5.0663826361366494e-05]\
Epoch: [114][0/94]	Time 1.573 (1.573)	Data 1.532 (1.532)	Loss 0.0509 (0.0509)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [114][30/94]	Time 0.076 (0.124)	Data 0.000 (0.055)	Loss 0.0123 (0.0374)	Acc@1 100.000 (99.294)	Acc@5 100.000 (100.000)\
Epoch: [114][60/94]	Time 0.052 (0.100)	Data 0.000 (0.029)	Loss 0.0560 (0.0364)	Acc@1 100.000 (99.308)	Acc@5 100.000 (100.000)\
Epoch: [114][90/94]	Time 0.065 (0.091)	Data 0.000 (0.021)	Loss 0.0319 (0.0365)	Acc@1 100.000 (99.313)	Acc@5 100.000 (100.000)\
 * Acc@1 99.316 Acc@5 100.000\
Test: [0/91]	Time 1.235 (1.235)	Loss 3.7830 (3.7830)	Acc@1 37.500 (37.500)	Acc@5 59.375 (59.375)\
Test: [30/91]	Time 0.035 (0.101)	Loss 3.2170 (3.2110)	Acc@1 35.938 (40.726)	Acc@5 67.188 (68.901)\
Test: [60/91]	Time 0.360 (0.083)	Loss 3.4183 (3.2064)	Acc@1 48.438 (41.675)	Acc@5 70.312 (68.878)\
Test: [90/91]	Time 0.012 (0.069)	Loss 2.6254 (3.1670)	Acc@1 52.941 (41.923)	Acc@5 85.294 (69.210)\
 * Acc@1 41.923 Acc@5 69.210\
tensor(5.3612, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [4.836862686437171e-05]\
Epoch: [115][0/94]	Time 1.416 (1.416)	Data 1.390 (1.390)	Loss 0.0313 (0.0313)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [115][30/94]	Time 0.077 (0.126)	Data 0.000 (0.057)	Loss 0.0704 (0.0406)	Acc@1 96.875 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [115][60/94]	Time 0.073 (0.101)	Data 0.002 (0.030)	Loss 0.0255 (0.0384)	Acc@1 100.000 (99.180)	Acc@5 100.000 (99.974)\
Epoch: [115][90/94]	Time 0.065 (0.091)	Data 0.000 (0.021)	Loss 0.0119 (0.0349)	Acc@1 100.000 (99.313)	Acc@5 100.000 (99.983)\
 * Acc@1 99.333 Acc@5 99.983\
Test: [0/91]	Time 1.076 (1.076)	Loss 3.3714 (3.3714)	Acc@1 43.750 (43.750)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.021 (0.117)	Loss 2.9088 (3.1353)	Acc@1 39.062 (41.381)	Acc@5 75.000 (69.506)\
Test: [60/91]	Time 0.029 (0.091)	Loss 3.0854 (3.2422)	Acc@1 51.562 (40.676)	Acc@5 68.750 (68.340)\
Test: [90/91]	Time 0.012 (0.079)	Loss 3.0499 (3.1704)	Acc@1 41.176 (41.819)	Acc@5 70.588 (69.192)\
 * Acc@1 41.819 Acc@5 69.192\
tensor(5.3613, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [4.6177405710691065e-05]\
Epoch: [116][0/94]	Time 1.133 (1.133)	Data 1.083 (1.083)	Loss 0.0122 (0.0122)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [116][30/94]	Time 0.080 (0.127)	Data 0.000 (0.055)	Loss 0.0152 (0.0296)	Acc@1 100.000 (99.446)	Acc@5 100.000 (100.000)\
Epoch: [116][60/94]	Time 0.066 (0.101)	Data 0.000 (0.029)	Loss 0.0085 (0.0323)	Acc@1 100.000 (99.436)	Acc@5 100.000 (100.000)\
Epoch: [116][90/94]	Time 0.072 (0.091)	Data 0.000 (0.020)	Loss 0.0268 (0.0341)	Acc@1 100.000 (99.313)	Acc@5 100.000 (100.000)\
 * Acc@1 99.316 Acc@5 100.000\
Test: [0/91]	Time 1.184 (1.184)	Loss 2.7925 (2.7925)	Acc@1 46.875 (46.875)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.030 (0.096)	Loss 4.1609 (3.2545)	Acc@1 42.188 (41.431)	Acc@5 64.062 (68.498)\
Test: [60/91]	Time 0.042 (0.077)	Loss 3.6749 (3.2181)	Acc@1 39.062 (41.342)	Acc@5 65.625 (68.673)\
Test: [90/91]	Time 0.012 (0.067)	Loss 2.4302 (3.1626)	Acc@1 50.000 (41.871)	Acc@5 67.647 (69.279)\
 * Acc@1 41.871 Acc@5 69.279\
tensor(5.3613, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [4.40854524183412e-05]\
Epoch: [117][0/94]	Time 1.105 (1.105)	Data 1.055 (1.055)	Loss 0.0182 (0.0182)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [117][30/94]	Time 0.075 (0.116)	Data 0.000 (0.048)	Loss 0.0174 (0.0337)	Acc@1 100.000 (99.244)	Acc@5 100.000 (100.000)\
Epoch: [117][60/94]	Time 0.074 (0.096)	Data 0.000 (0.028)	Loss 0.0243 (0.0301)	Acc@1 100.000 (99.462)	Acc@5 100.000 (100.000)\
Epoch: [117][90/94]	Time 0.071 (0.088)	Data 0.000 (0.020)	Loss 0.0541 (0.0297)	Acc@1 98.438 (99.485)	Acc@5 100.000 (100.000)\
 * Acc@1 99.466 Acc@5 100.000\
Test: [0/91]	Time 1.077 (1.077)	Loss 3.6111 (3.6111)	Acc@1 45.312 (45.312)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.025 (0.109)	Loss 2.8583 (3.2452)	Acc@1 39.062 (41.583)	Acc@5 68.750 (68.196)\
Test: [60/91]	Time 0.021 (0.083)	Loss 3.8249 (3.1487)	Acc@1 34.375 (42.008)	Acc@5 60.938 (69.314)\
Test: [90/91]	Time 0.012 (0.072)	Loss 3.6809 (3.1719)	Acc@1 29.412 (41.905)	Acc@5 64.706 (69.054)\
 * Acc@1 41.905 Acc@5 69.054\
tensor(5.3613, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [4.208826990208889e-05]\
Epoch: [118][0/94]	Time 1.556 (1.556)	Data 1.496 (1.496)	Loss 0.0179 (0.0179)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [118][30/94]	Time 0.061 (0.121)	Data 0.000 (0.049)	Loss 0.0291 (0.0335)	Acc@1 98.438 (99.042)	Acc@5 100.000 (100.000)\
Epoch: [118][60/94]	Time 0.092 (0.099)	Data 0.000 (0.026)	Loss 0.0462 (0.0398)	Acc@1 100.000 (99.027)	Acc@5 100.000 (100.000)\
Epoch: [118][90/94]	Time 0.065 (0.091)	Data 0.000 (0.018)	Loss 0.0122 (0.0371)	Acc@1 100.000 (99.227)	Acc@5 100.000 (100.000)\
 * Acc@1 99.216 Acc@5 100.000\
Test: [0/91]	Time 1.381 (1.381)	Loss 3.2314 (3.2314)	Acc@1 40.625 (40.625)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.038 (0.101)	Loss 2.9888 (3.1955)	Acc@1 48.438 (42.188)	Acc@5 64.062 (69.304)\
Test: [60/91]	Time 0.032 (0.076)	Loss 2.7839 (3.1480)	Acc@1 43.750 (42.572)	Acc@5 73.438 (69.544)\
Test: [90/91]	Time 0.012 (0.070)	Loss 3.8569 (3.1770)	Acc@1 32.353 (41.992)	Acc@5 61.765 (69.089)\
 * Acc@1 41.992 Acc@5 69.089\
tensor(5.3614, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [4.018156480603808e-05]\
Epoch: [119][0/94]	Time 1.201 (1.201)	Data 1.150 (1.150)	Loss 0.0293 (0.0293)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [119][30/94]	Time 0.072 (0.121)	Data 0.000 (0.047)	Loss 0.0147 (0.0430)	Acc@1 100.000 (99.143)	Acc@5 100.000 (100.000)\
Epoch: [119][60/94]	Time 0.065 (0.098)	Data 0.005 (0.025)	Loss 0.0278 (0.0394)	Acc@1 98.438 (99.078)	Acc@5 100.000 (100.000)\
Epoch: [119][90/94]	Time 0.065 (0.089)	Data 0.000 (0.017)	Loss 0.0129 (0.0360)	Acc@1 100.000 (99.193)	Acc@5 100.000 (100.000)\
 * Acc@1 99.183 Acc@5 100.000\
Test: [0/91]	Time 1.121 (1.121)	Loss 3.4676 (3.4676)	Acc@1 37.500 (37.500)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.296 (0.110)	Loss 3.1602 (3.0708)	Acc@1 35.938 (41.835)	Acc@5 71.875 (70.161)\
Test: [60/91]	Time 0.040 (0.080)	Loss 3.2816 (3.1886)	Acc@1 45.312 (41.547)	Acc@5 73.438 (68.801)\
Test: [90/91]	Time 0.015 (0.074)	Loss 3.6476 (3.1559)	Acc@1 38.235 (42.061)	Acc@5 67.647 (69.382)\
 * Acc@1 42.061 Acc@5 69.382\
tensor(5.3614, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [3.836123827417535e-05]\
Epoch: [120][0/94]	Time 1.014 (1.014)	Data 0.946 (0.946)	Loss 0.0196 (0.0196)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [120][30/94]	Time 0.074 (0.116)	Data 0.000 (0.044)	Loss 0.0335 (0.0360)	Acc@1 98.438 (98.992)	Acc@5 100.000 (100.000)\
Epoch: [120][60/94]	Time 0.087 (0.096)	Data 0.000 (0.024)	Loss 0.0374 (0.0357)	Acc@1 98.438 (99.180)	Acc@5 100.000 (100.000)\
Epoch: [120][90/94]	Time 0.072 (0.088)	Data 0.000 (0.016)	Loss 0.0120 (0.0350)	Acc@1 100.000 (99.245)	Acc@5 100.000 (100.000)\
 * Acc@1 99.266 Acc@5 100.000\
Test: [0/91]	Time 1.405 (1.405)	Loss 2.6737 (2.6737)	Acc@1 45.312 (45.312)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.022 (0.111)	Loss 3.2722 (3.0964)	Acc@1 45.312 (42.137)	Acc@5 76.562 (69.960)\
Test: [60/91]	Time 0.024 (0.087)	Loss 2.6398 (3.2139)	Acc@1 46.875 (41.624)	Acc@5 76.562 (69.442)\
Test: [90/91]	Time 0.012 (0.074)	Loss 3.6075 (3.1777)	Acc@1 32.353 (42.061)	Acc@5 52.941 (69.330)\
 * Acc@1 42.061 Acc@5 69.330\
tensor(5.3614, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [3.662337713903369e-05]\
Epoch: [121][0/94]	Time 1.170 (1.170)	Data 1.113 (1.113)	Loss 0.0119 (0.0119)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [121][30/94]	Time 0.064 (0.124)	Data 0.000 (0.052)	Loss 0.0177 (0.0316)	Acc@1 100.000 (99.294)	Acc@5 100.000 (100.000)\
Epoch: [121][60/94]	Time 0.090 (0.101)	Data 0.000 (0.027)	Loss 0.0235 (0.0317)	Acc@1 98.438 (99.308)	Acc@5 100.000 (100.000)\
Epoch: [121][90/94]	Time 0.070 (0.091)	Data 0.000 (0.019)	Loss 0.0662 (0.0311)	Acc@1 98.438 (99.416)	Acc@5 100.000 (100.000)\
 * Acc@1 99.383 Acc@5 100.000\
Test: [0/91]	Time 1.288 (1.288)	Loss 3.5006 (3.5006)	Acc@1 31.250 (31.250)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.032 (0.102)	Loss 3.4328 (3.2815)	Acc@1 32.812 (41.129)	Acc@5 67.188 (68.246)\
Test: [60/91]	Time 0.078 (0.079)	Loss 3.4061 (3.2478)	Acc@1 48.438 (41.547)	Acc@5 70.312 (68.494)\
Test: [90/91]	Time 0.015 (0.073)	Loss 2.6903 (3.1667)	Acc@1 47.059 (41.957)	Acc@5 73.529 (69.020)\
 * Acc@1 41.957 Acc@5 69.020\
tensor(5.3614, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [3.496424550953137e-05]\
Epoch: [122][0/94]	Time 1.639 (1.639)	Data 1.596 (1.596)	Loss 0.0426 (0.0426)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [122][30/94]	Time 0.064 (0.127)	Data 0.000 (0.055)	Loss 0.0412 (0.0350)	Acc@1 100.000 (99.244)	Acc@5 100.000 (100.000)\
Epoch: [122][60/94]	Time 0.073 (0.102)	Data 0.000 (0.029)	Loss 0.0182 (0.0327)	Acc@1 100.000 (99.385)	Acc@5 100.000 (100.000)\
Epoch: [122][90/94]	Time 0.065 (0.092)	Data 0.000 (0.020)	Loss 0.0449 (0.0337)	Acc@1 100.000 (99.382)	Acc@5 100.000 (100.000)\
 * Acc@1 99.383 Acc@5 100.000\
Test: [0/91]	Time 1.638 (1.638)	Loss 3.3236 (3.3236)	Acc@1 46.875 (46.875)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.019 (0.108)	Loss 3.1306 (3.2297)	Acc@1 45.312 (41.583)	Acc@5 70.312 (68.800)\
Test: [60/91]	Time 0.086 (0.080)	Loss 2.8522 (3.2042)	Acc@1 40.625 (41.701)	Acc@5 73.438 (68.571)\
Test: [90/91]	Time 0.016 (0.069)	Loss 3.1205 (3.1563)	Acc@1 41.176 (42.009)	Acc@5 82.353 (69.330)\
 * Acc@1 42.009 Acc@5 69.330\
tensor(5.3614, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [3.338027673990308e-05]\
Epoch: [123][0/94]	Time 1.137 (1.137)	Data 1.100 (1.100)	Loss 0.0319 (0.0319)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [123][30/94]	Time 0.069 (0.114)	Data 0.000 (0.044)	Loss 0.0179 (0.0359)	Acc@1 100.000 (99.143)	Acc@5 100.000 (100.000)\
Epoch: [123][60/94]	Time 0.077 (0.096)	Data 0.000 (0.024)	Loss 0.0109 (0.0316)	Acc@1 100.000 (99.411)	Acc@5 100.000 (100.000)\
Epoch: [123][90/94]	Time 0.071 (0.089)	Data 0.000 (0.016)	Loss 0.0575 (0.0325)	Acc@1 98.438 (99.399)	Acc@5 100.000 (100.000)\
 * Acc@1 99.383 Acc@5 100.000\
Test: [0/91]	Time 1.093 (1.093)	Loss 2.1400 (2.1400)	Acc@1 54.688 (54.688)	Acc@5 78.125 (78.125)\
Test: [30/91]	Time 0.019 (0.099)	Loss 3.4022 (3.1611)	Acc@1 43.750 (42.288)	Acc@5 65.625 (68.296)\
Test: [60/91]	Time 0.056 (0.084)	Loss 3.2592 (3.1541)	Acc@1 43.750 (41.701)	Acc@5 64.062 (69.237)\
Test: [90/91]	Time 0.015 (0.071)	Loss 2.9106 (3.1568)	Acc@1 52.941 (41.905)	Acc@5 73.529 (69.382)\
 * Acc@1 41.905 Acc@5 69.382\
tensor(5.3615, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [3.186806576245907e-05]\
Epoch: [124][0/94]	Time 1.100 (1.100)	Data 1.056 (1.056)	Loss 0.0390 (0.0390)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [124][30/94]	Time 0.069 (0.119)	Data 0.000 (0.051)	Loss 0.0202 (0.0357)	Acc@1 100.000 (99.194)	Acc@5 100.000 (99.950)\
Epoch: [124][60/94]	Time 0.064 (0.099)	Data 0.000 (0.031)	Loss 0.0856 (0.0352)	Acc@1 96.875 (99.308)	Acc@5 100.000 (99.974)\
Epoch: [124][90/94]	Time 0.060 (0.090)	Data 0.000 (0.023)	Loss 0.0240 (0.0343)	Acc@1 100.000 (99.313)	Acc@5 100.000 (99.983)\
 * Acc@1 99.333 Acc@5 99.983\
Test: [0/91]	Time 1.210 (1.210)	Loss 2.8584 (2.8584)	Acc@1 42.188 (42.188)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.073 (0.102)	Loss 4.4278 (3.2311)	Acc@1 32.812 (41.381)	Acc@5 60.938 (68.044)\
Test: [60/91]	Time 0.021 (0.085)	Loss 4.2100 (3.1879)	Acc@1 35.938 (41.778)	Acc@5 60.938 (68.852)\
Test: [90/91]	Time 0.015 (0.075)	Loss 4.2003 (3.1866)	Acc@1 23.529 (42.043)	Acc@5 58.824 (69.123)\
 * Acc@1 42.043 Acc@5 69.123\
tensor(5.3615, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [3.0424361767690036e-05]\
Epoch: [125][0/94]	Time 1.108 (1.108)	Data 1.049 (1.049)	Loss 0.0239 (0.0239)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [125][30/94]	Time 0.064 (0.117)	Data 0.000 (0.047)	Loss 0.0363 (0.0351)	Acc@1 98.438 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [125][60/94]	Time 0.065 (0.095)	Data 0.000 (0.025)	Loss 0.0179 (0.0323)	Acc@1 100.000 (99.462)	Acc@5 100.000 (100.000)\
Epoch: [125][90/94]	Time 0.067 (0.087)	Data 0.000 (0.018)	Loss 0.0154 (0.0308)	Acc@1 100.000 (99.451)	Acc@5 100.000 (100.000)\
 * Acc@1 99.449 Acc@5 100.000\
Test: [0/91]	Time 1.090 (1.090)	Loss 3.7127 (3.7127)	Acc@1 29.688 (29.688)	Acc@5 56.250 (56.250)\
Test: [30/91]	Time 0.062 (0.105)	Loss 3.0575 (3.2428)	Acc@1 37.500 (40.877)	Acc@5 70.312 (68.044)\
Test: [60/91]	Time 0.019 (0.080)	Loss 3.7183 (3.2247)	Acc@1 37.500 (41.470)	Acc@5 70.312 (68.571)\
Test: [90/91]	Time 0.012 (0.071)	Loss 3.7675 (3.1738)	Acc@1 35.294 (41.854)	Acc@5 58.824 (69.175)\
 * Acc@1 41.854 Acc@5 69.175\
tensor(5.3615, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.904606121598052e-05]\
Epoch: [126][0/94]	Time 1.166 (1.166)	Data 1.109 (1.109)	Loss 0.0482 (0.0482)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [126][30/94]	Time 0.085 (0.121)	Data 0.000 (0.052)	Loss 0.0117 (0.0340)	Acc@1 100.000 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [126][60/94]	Time 0.083 (0.098)	Data 0.008 (0.028)	Loss 0.0141 (0.0346)	Acc@1 100.000 (99.462)	Acc@5 100.000 (100.000)\
Epoch: [126][90/94]	Time 0.065 (0.090)	Data 0.000 (0.020)	Loss 0.0189 (0.0329)	Acc@1 100.000 (99.485)	Acc@5 100.000 (100.000)\
 * Acc@1 99.466 Acc@5 100.000\
Test: [0/91]	Time 1.136 (1.136)	Loss 3.2620 (3.2620)	Acc@1 39.062 (39.062)	Acc@5 65.625 (65.625)\
Test: [30/91]	Time 0.028 (0.100)	Loss 4.0000 (3.2714)	Acc@1 37.500 (40.827)	Acc@5 60.938 (67.994)\
Test: [60/91]	Time 0.038 (0.077)	Loss 3.4292 (3.1819)	Acc@1 46.875 (41.726)	Acc@5 62.500 (68.929)\
Test: [90/91]	Time 0.012 (0.068)	Loss 3.3042 (3.1795)	Acc@1 35.294 (41.871)	Acc@5 73.529 (69.227)\
 * Acc@1 41.871 Acc@5 69.227\
tensor(5.3615, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.7730201165910607e-05]\
Epoch: [127][0/94]	Time 1.891 (1.891)	Data 1.842 (1.842)	Loss 0.0230 (0.0230)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [127][30/94]	Time 0.077 (0.133)	Data 0.000 (0.061)	Loss 0.0876 (0.0321)	Acc@1 96.875 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [127][60/94]	Time 0.065 (0.104)	Data 0.000 (0.032)	Loss 0.0068 (0.0301)	Acc@1 100.000 (99.513)	Acc@5 100.000 (100.000)\
Epoch: [127][90/94]	Time 0.072 (0.093)	Data 0.000 (0.022)	Loss 0.0186 (0.0293)	Acc@1 100.000 (99.502)	Acc@5 100.000 (100.000)\
 * Acc@1 99.500 Acc@5 100.000\
Test: [0/91]	Time 1.703 (1.703)	Loss 2.3901 (2.3901)	Acc@1 54.688 (54.688)	Acc@5 81.250 (81.250)\
Test: [30/91]	Time 0.020 (0.100)	Loss 4.0715 (3.2333)	Acc@1 39.062 (42.641)	Acc@5 64.062 (68.246)\
Test: [60/91]	Time 0.049 (0.084)	Loss 2.6830 (3.1879)	Acc@1 42.188 (42.649)	Acc@5 71.875 (69.237)\
Test: [90/91]	Time 0.012 (0.073)	Loss 3.2578 (3.1745)	Acc@1 38.235 (42.113)	Acc@5 70.588 (69.261)\
 * Acc@1 42.113 Acc@5 69.261\
tensor(5.3615, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.6473952904802308e-05]\
Epoch: [128][0/94]	Time 1.299 (1.299)	Data 1.240 (1.240)	Loss 0.0144 (0.0144)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [128][30/94]	Time 0.079 (0.121)	Data 0.000 (0.048)	Loss 0.0263 (0.0295)	Acc@1 100.000 (99.647)	Acc@5 100.000 (100.000)\
Epoch: [128][60/94]	Time 0.072 (0.099)	Data 0.000 (0.026)	Loss 0.0452 (0.0313)	Acc@1 98.438 (99.565)	Acc@5 100.000 (99.974)\
Epoch: [128][90/94]	Time 0.073 (0.090)	Data 0.000 (0.018)	Loss 0.0331 (0.0304)	Acc@1 100.000 (99.536)	Acc@5 100.000 (99.983)\
 * Acc@1 99.533 Acc@5 99.983\
Test: [0/91]	Time 1.166 (1.166)	Loss 3.6177 (3.6177)	Acc@1 40.625 (40.625)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.020 (0.092)	Loss 2.4826 (3.1877)	Acc@1 45.312 (41.129)	Acc@5 73.438 (68.044)\
Test: [60/91]	Time 0.023 (0.083)	Loss 2.8459 (3.1717)	Acc@1 35.938 (41.906)	Acc@5 71.875 (68.622)\
Test: [90/91]	Time 0.015 (0.074)	Loss 2.9299 (3.1656)	Acc@1 44.118 (41.854)	Acc@5 61.765 (69.123)\
 * Acc@1 41.854 Acc@5 69.123\
tensor(5.3616, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.527461586781732e-05]\
Epoch: [129][0/94]	Time 1.101 (1.101)	Data 1.057 (1.057)	Loss 0.0200 (0.0200)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [129][30/94]	Time 0.059 (0.127)	Data 0.000 (0.056)	Loss 0.0186 (0.0313)	Acc@1 100.000 (99.446)	Acc@5 100.000 (99.950)\
Epoch: [129][60/94]	Time 0.068 (0.102)	Data 0.000 (0.030)	Loss 0.0223 (0.0304)	Acc@1 100.000 (99.436)	Acc@5 100.000 (99.974)\
Epoch: [129][90/94]	Time 0.065 (0.093)	Data 0.000 (0.020)	Loss 0.0321 (0.0314)	Acc@1 100.000 (99.399)	Acc@5 100.000 (99.983)\
 * Acc@1 99.399 Acc@5 99.983\
Test: [0/91]	Time 1.108 (1.108)	Loss 2.3898 (2.3898)	Acc@1 51.562 (51.562)	Acc@5 78.125 (78.125)\
Test: [30/91]	Time 0.028 (0.100)	Loss 3.2049 (3.0802)	Acc@1 29.688 (41.935)	Acc@5 70.312 (70.060)\
Test: [60/91]	Time 0.024 (0.080)	Loss 3.3204 (3.1442)	Acc@1 39.062 (42.085)	Acc@5 68.750 (69.365)\
Test: [90/91]	Time 0.015 (0.073)	Loss 4.1134 (3.1653)	Acc@1 20.588 (41.923)	Acc@5 61.765 (69.192)\
 * Acc@1 41.923 Acc@5 69.192\
tensor(5.3616, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.4129611832536074e-05]\
Epoch: [130][0/94]	Time 1.361 (1.361)	Data 1.323 (1.323)	Loss 0.0295 (0.0295)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [130][30/94]	Time 0.072 (0.124)	Data 0.000 (0.054)	Loss 0.0338 (0.0387)	Acc@1 98.438 (99.143)	Acc@5 100.000 (99.899)\
Epoch: [130][60/94]	Time 0.070 (0.099)	Data 0.000 (0.029)	Loss 0.0360 (0.0407)	Acc@1 100.000 (98.975)	Acc@5 100.000 (99.949)\
Epoch: [130][90/94]	Time 0.066 (0.090)	Data 0.000 (0.020)	Loss 0.0326 (0.0375)	Acc@1 100.000 (99.141)	Acc@5 100.000 (99.966)\
 * Acc@1 99.149 Acc@5 99.967\
Test: [0/91]	Time 1.249 (1.249)	Loss 3.3093 (3.3093)	Acc@1 42.188 (42.188)	Acc@5 64.062 (64.062)\
Test: [30/91]	Time 0.021 (0.112)	Loss 3.1523 (3.2117)	Acc@1 45.312 (41.835)	Acc@5 71.875 (69.103)\
Test: [60/91]	Time 0.269 (0.101)	Loss 4.3843 (3.1655)	Acc@1 34.375 (42.059)	Acc@5 57.812 (69.390)\
Test: [90/91]	Time 0.016 (0.082)	Loss 3.5769 (3.1607)	Acc@1 38.235 (41.888)	Acc@5 67.647 (69.365)\
 * Acc@1 41.888 Acc@5 69.365\
tensor(5.3616, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.3036479376536948e-05]\
Epoch: [131][0/94]	Time 1.123 (1.123)	Data 1.069 (1.069)	Loss 0.0416 (0.0416)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [131][30/94]	Time 0.058 (0.129)	Data 0.000 (0.060)	Loss 0.0201 (0.0297)	Acc@1 100.000 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [131][60/94]	Time 0.165 (0.108)	Data 0.133 (0.042)	Loss 0.0381 (0.0301)	Acc@1 98.438 (99.436)	Acc@5 100.000 (100.000)\
Epoch: [131][90/94]	Time 0.078 (0.096)	Data 0.004 (0.031)	Loss 0.0351 (0.0330)	Acc@1 98.438 (99.296)	Acc@5 100.000 (100.000)\
 * Acc@1 99.299 Acc@5 100.000\
Test: [0/91]	Time 1.149 (1.149)	Loss 3.2279 (3.2279)	Acc@1 43.750 (43.750)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.029 (0.110)	Loss 2.8270 (3.2872)	Acc@1 42.188 (41.784)	Acc@5 70.312 (68.397)\
Test: [60/91]	Time 0.109 (0.096)	Loss 3.0546 (3.2348)	Acc@1 32.812 (41.240)	Acc@5 71.875 (68.519)\
Test: [90/91]	Time 0.012 (0.085)	Loss 3.1463 (3.1733)	Acc@1 44.118 (41.767)	Acc@5 67.647 (68.985)\
 * Acc@1 41.767 Acc@5 68.985\
tensor(5.3616, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.1992868586060324e-05]\
Epoch: [132][0/94]	Time 1.525 (1.525)	Data 1.491 (1.491)	Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [132][30/94]	Time 0.137 (0.135)	Data 0.097 (0.074)	Loss 0.0233 (0.0305)	Acc@1 100.000 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [132][60/94]	Time 0.074 (0.109)	Data 0.027 (0.049)	Loss 0.0149 (0.0315)	Acc@1 100.000 (99.334)	Acc@5 100.000 (100.000)\
Epoch: [132][90/94]	Time 0.065 (0.099)	Data 0.000 (0.037)	Loss 0.0373 (0.0327)	Acc@1 100.000 (99.330)	Acc@5 100.000 (100.000)\
 * Acc@1 99.283 Acc@5 100.000\
Test: [0/91]	Time 1.643 (1.643)	Loss 3.2572 (3.2572)	Acc@1 40.625 (40.625)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.019 (0.113)	Loss 3.2041 (3.1734)	Acc@1 43.750 (42.389)	Acc@5 65.625 (68.750)\
Test: [60/91]	Time 0.019 (0.091)	Loss 2.8922 (3.1515)	Acc@1 46.875 (42.316)	Acc@5 71.875 (69.518)\
Test: [90/91]	Time 0.015 (0.083)	Loss 3.6678 (3.1708)	Acc@1 32.353 (42.078)	Acc@5 58.824 (69.313)\
 * Acc@1 42.078 Acc@5 69.313\
tensor(5.3616, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.099653600438442e-05]\
Epoch: [133][0/94]	Time 1.170 (1.170)	Data 1.125 (1.125)	Loss 0.0257 (0.0257)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [133][30/94]	Time 0.047 (0.138)	Data 0.000 (0.070)	Loss 0.0168 (0.0307)	Acc@1 100.000 (99.496)	Acc@5 100.000 (100.000)\
Epoch: [133][60/94]	Time 0.078 (0.109)	Data 0.000 (0.038)	Loss 0.0111 (0.0292)	Acc@1 100.000 (99.462)	Acc@5 100.000 (100.000)\
Epoch: [133][90/94]	Time 0.063 (0.097)	Data 0.000 (0.026)	Loss 0.0284 (0.0305)	Acc@1 100.000 (99.485)	Acc@5 100.000 (100.000)\
 * Acc@1 99.449 Acc@5 100.000\
Test: [0/91]	Time 1.310 (1.310)	Loss 2.0019 (2.0019)	Acc@1 54.688 (54.688)	Acc@5 84.375 (84.375)\
Test: [30/91]	Time 0.020 (0.131)	Loss 2.5018 (3.1935)	Acc@1 50.000 (41.986)	Acc@5 73.438 (68.700)\
Test: [60/91]	Time 0.033 (0.103)	Loss 3.2681 (3.2003)	Acc@1 40.625 (42.264)	Acc@5 65.625 (69.032)\
Test: [90/91]	Time 0.012 (0.088)	Loss 2.7855 (3.1751)	Acc@1 52.941 (41.854)	Acc@5 70.588 (69.158)\
 * Acc@1 41.854 Acc@5 69.158\
tensor(5.3616, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [2.00453398090524e-05]\
Epoch: [134][0/94]	Time 1.160 (1.160)	Data 1.132 (1.132)	Loss 0.0604 (0.0604)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [134][30/94]	Time 0.074 (0.125)	Data 0.000 (0.057)	Loss 0.0163 (0.0343)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [134][60/94]	Time 0.056 (0.100)	Data 0.000 (0.030)	Loss 0.0368 (0.0322)	Acc@1 98.438 (99.385)	Acc@5 100.000 (100.000)\
Epoch: [134][90/94]	Time 0.055 (0.090)	Data 0.000 (0.021)	Loss 0.0068 (0.0330)	Acc@1 100.000 (99.365)	Acc@5 100.000 (100.000)\
 * Acc@1 99.366 Acc@5 100.000\
Test: [0/91]	Time 1.484 (1.484)	Loss 3.3094 (3.3094)	Acc@1 50.000 (50.000)	Acc@5 68.750 (68.750)\
Test: [30/91]	Time 0.036 (0.120)	Loss 2.3900 (3.2393)	Acc@1 53.125 (42.641)	Acc@5 81.250 (69.204)\
Test: [60/91]	Time 0.027 (0.104)	Loss 2.8943 (3.1645)	Acc@1 43.750 (42.572)	Acc@5 67.188 (69.493)\
Test: [90/91]	Time 0.012 (0.090)	Loss 3.2317 (3.1705)	Acc@1 44.118 (42.026)	Acc@5 73.529 (69.123)\
 * Acc@1 42.026 Acc@5 69.123\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.9137235207582584e-05]\
Epoch: [135][0/94]	Time 1.528 (1.528)	Data 1.490 (1.490)	Loss 0.0089 (0.0089)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [135][30/94]	Time 0.057 (0.120)	Data 0.000 (0.051)	Loss 0.0259 (0.0293)	Acc@1 100.000 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [135][60/94]	Time 0.084 (0.105)	Data 0.052 (0.038)	Loss 0.0307 (0.0299)	Acc@1 98.438 (99.513)	Acc@5 100.000 (100.000)\
Epoch: [135][90/94]	Time 0.060 (0.096)	Data 0.000 (0.031)	Loss 0.0254 (0.0298)	Acc@1 100.000 (99.519)	Acc@5 100.000 (99.983)\
 * Acc@1 99.533 Acc@5 99.983\
Test: [0/91]	Time 1.280 (1.280)	Loss 3.0227 (3.0227)	Acc@1 46.875 (46.875)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.137 (0.135)	Loss 3.5328 (3.0580)	Acc@1 40.625 (44.204)	Acc@5 57.812 (70.665)\
Test: [60/91]	Time 0.055 (0.106)	Loss 3.4722 (3.1040)	Acc@1 43.750 (43.417)	Acc@5 68.750 (69.775)\
Test: [90/91]	Time 0.016 (0.092)	Loss 3.0023 (3.1690)	Acc@1 44.118 (41.974)	Acc@5 70.588 (69.210)\
 * Acc@1 41.974 Acc@5 69.210\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.8270270041765414e-05]\
Epoch: [136][0/94]	Time 1.410 (1.410)	Data 1.340 (1.340)	Loss 0.0715 (0.0715)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [136][30/94]	Time 0.074 (0.132)	Data 0.018 (0.066)	Loss 0.0109 (0.0329)	Acc@1 100.000 (99.345)	Acc@5 100.000 (100.000)\
Epoch: [136][60/94]	Time 0.062 (0.109)	Data 0.000 (0.047)	Loss 0.0258 (0.0334)	Acc@1 100.000 (99.283)	Acc@5 100.000 (100.000)\
Epoch: [136][90/94]	Time 0.061 (0.101)	Data 0.000 (0.040)	Loss 0.0153 (0.0309)	Acc@1 100.000 (99.433)	Acc@5 100.000 (100.000)\
 * Acc@1 99.433 Acc@5 100.000\
Test: [0/91]	Time 1.216 (1.216)	Loss 3.0686 (3.0686)	Acc@1 45.312 (45.312)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.260 (0.110)	Loss 3.4750 (3.2833)	Acc@1 45.312 (40.272)	Acc@5 71.875 (67.994)\
Test: [60/91]	Time 0.025 (0.089)	Loss 3.2448 (3.1697)	Acc@1 45.312 (41.598)	Acc@5 68.750 (69.083)\
Test: [90/91]	Time 0.012 (0.079)	Loss 3.2660 (3.1530)	Acc@1 41.176 (41.992)	Acc@5 79.412 (69.365)\
 * Acc@1 41.992 Acc@5 69.365\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.7442580591096616e-05]\
Epoch: [137][0/94]	Time 1.406 (1.406)	Data 1.362 (1.362)	Loss 0.1497 (0.1497)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [137][30/94]	Time 0.055 (0.141)	Data 0.000 (0.079)	Loss 0.0194 (0.0420)	Acc@1 100.000 (99.042)	Acc@5 100.000 (100.000)\
Epoch: [137][60/94]	Time 0.085 (0.111)	Data 0.004 (0.045)	Loss 0.0327 (0.0353)	Acc@1 100.000 (99.129)	Acc@5 100.000 (100.000)\
Epoch: [137][90/94]	Time 0.072 (0.099)	Data 0.000 (0.031)	Loss 0.0383 (0.0337)	Acc@1 100.000 (99.227)	Acc@5 100.000 (100.000)\
 * Acc@1 99.249 Acc@5 100.000\
Test: [0/91]	Time 1.235 (1.235)	Loss 3.4673 (3.4673)	Acc@1 40.625 (40.625)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.030 (0.112)	Loss 2.7208 (3.1096)	Acc@1 46.875 (41.683)	Acc@5 75.000 (69.052)\
Test: [60/91]	Time 0.043 (0.092)	Loss 2.5971 (3.1803)	Acc@1 48.438 (41.983)	Acc@5 70.312 (68.673)\
Test: [90/91]	Time 0.016 (0.080)	Loss 2.7233 (3.1564)	Acc@1 38.235 (41.992)	Acc@5 70.588 (69.123)\
 * Acc@1 41.992 Acc@5 69.123\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.6652387566325352e-05]\
Epoch: [138][0/94]	Time 1.303 (1.303)	Data 1.246 (1.246)	Loss 0.0462 (0.0462)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [138][30/94]	Time 0.148 (0.122)	Data 0.095 (0.057)	Loss 0.0276 (0.0305)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [138][60/94]	Time 0.061 (0.101)	Data 0.000 (0.032)	Loss 0.0089 (0.0325)	Acc@1 100.000 (99.257)	Acc@5 100.000 (100.000)\
Epoch: [138][90/94]	Time 0.072 (0.091)	Data 0.020 (0.022)	Loss 0.0434 (0.0354)	Acc@1 98.438 (99.227)	Acc@5 100.000 (100.000)\
 * Acc@1 99.249 Acc@5 100.000\
Test: [0/91]	Time 1.511 (1.511)	Loss 3.5348 (3.5348)	Acc@1 35.938 (35.938)	Acc@5 67.188 (67.188)\
Test: [30/91]	Time 0.021 (0.106)	Loss 3.0804 (3.0997)	Acc@1 37.500 (42.238)	Acc@5 64.062 (69.657)\
Test: [60/91]	Time 0.023 (0.089)	Loss 2.6572 (3.1078)	Acc@1 48.438 (43.058)	Acc@5 76.562 (70.056)\
Test: [90/91]	Time 0.016 (0.078)	Loss 3.7549 (3.1744)	Acc@1 44.118 (42.113)	Acc@5 70.588 (69.451)\
 * Acc@1 42.113 Acc@5 69.451\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.589799228450477e-05]\
Epoch: [139][0/94]	Time 1.505 (1.505)	Data 1.448 (1.448)	Loss 0.0204 (0.0204)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [139][30/94]	Time 0.156 (0.136)	Data 0.130 (0.078)	Loss 0.0110 (0.0312)	Acc@1 100.000 (99.446)	Acc@5 100.000 (100.000)\
Epoch: [139][60/94]	Time 0.246 (0.116)	Data 0.218 (0.055)	Loss 0.0343 (0.0327)	Acc@1 100.000 (99.283)	Acc@5 100.000 (100.000)\
Epoch: [139][90/94]	Time 0.065 (0.107)	Data 0.000 (0.046)	Loss 0.0220 (0.0318)	Acc@1 100.000 (99.399)	Acc@5 100.000 (100.000)\
 * Acc@1 99.366 Acc@5 100.000\
Test: [0/91]	Time 1.120 (1.120)	Loss 3.1759 (3.1759)	Acc@1 35.938 (35.938)	Acc@5 71.875 (71.875)\
Test: [30/91]	Time 0.020 (0.130)	Loss 2.4100 (3.1783)	Acc@1 56.250 (42.792)	Acc@5 82.812 (68.901)\
Test: [60/91]	Time 0.020 (0.108)	Loss 2.1212 (3.1612)	Acc@1 54.688 (42.444)	Acc@5 78.125 (69.518)\
Test: [90/91]	Time 0.012 (0.093)	Loss 3.5949 (3.1667)	Acc@1 32.353 (42.113)	Acc@5 64.706 (69.210)\
 * Acc@1 42.113 Acc@5 69.210\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.5177773017322715e-05]\
Epoch: [140][0/94]	Time 1.076 (1.076)	Data 1.040 (1.040)	Loss 0.0768 (0.0768)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [140][30/94]	Time 0.076 (0.137)	Data 0.000 (0.083)	Loss 0.0183 (0.0380)	Acc@1 100.000 (99.244)	Acc@5 100.000 (100.000)\
Epoch: [140][60/94]	Time 0.082 (0.119)	Data 0.000 (0.061)	Loss 0.0230 (0.0342)	Acc@1 100.000 (99.385)	Acc@5 100.000 (100.000)\
Epoch: [140][90/94]	Time 0.066 (0.104)	Data 0.000 (0.042)	Loss 0.0230 (0.0330)	Acc@1 100.000 (99.399)	Acc@5 100.000 (100.000)\
 * Acc@1 99.416 Acc@5 100.000\
Test: [0/91]	Time 1.313 (1.313)	Loss 2.6599 (2.6599)	Acc@1 45.312 (45.312)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.135 (0.116)	Loss 3.3549 (3.2289)	Acc@1 39.062 (41.482)	Acc@5 65.625 (68.800)\
Test: [60/91]	Time 0.033 (0.102)	Loss 2.9831 (3.1364)	Acc@1 46.875 (42.495)	Acc@5 68.750 (69.851)\
Test: [90/91]	Time 0.012 (0.088)	Loss 3.2245 (3.1703)	Acc@1 41.176 (41.888)	Acc@5 61.765 (69.123)\
 * Acc@1 41.888 Acc@5 69.123\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.4490181504862008e-05]\
Epoch: [141][0/94]	Time 1.220 (1.220)	Data 1.191 (1.191)	Loss 0.0278 (0.0278)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [141][30/94]	Time 0.093 (0.119)	Data 0.057 (0.052)	Loss 0.0133 (0.0338)	Acc@1 100.000 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [141][60/94]	Time 0.086 (0.100)	Data 0.000 (0.031)	Loss 0.0116 (0.0335)	Acc@1 100.000 (99.513)	Acc@5 100.000 (100.000)\
Epoch: [141][90/94]	Time 0.065 (0.092)	Data 0.000 (0.022)	Loss 0.0332 (0.0327)	Acc@1 100.000 (99.519)	Acc@5 100.000 (100.000)\
 * Acc@1 99.466 Acc@5 100.000\
Test: [0/91]	Time 1.144 (1.144)	Loss 3.2155 (3.2155)	Acc@1 46.875 (46.875)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.027 (0.113)	Loss 3.2272 (3.0425)	Acc@1 43.750 (42.843)	Acc@5 62.500 (70.514)\
Test: [60/91]	Time 0.130 (0.099)	Loss 2.6448 (3.1548)	Acc@1 51.562 (42.034)	Acc@5 70.312 (69.288)\
Test: [90/91]	Time 0.012 (0.084)	Loss 2.9902 (3.1609)	Acc@1 44.118 (41.888)	Acc@5 67.647 (69.140)\
 * Acc@1 41.888 Acc@5 69.140\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.3833739627296222e-05]\
Epoch: [142][0/94]	Time 1.205 (1.205)	Data 1.134 (1.134)	Loss 0.0191 (0.0191)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [142][30/94]	Time 0.060 (0.125)	Data 0.021 (0.062)	Loss 0.0529 (0.0340)	Acc@1 98.438 (99.194)	Acc@5 100.000 (100.000)\
Epoch: [142][60/94]	Time 0.091 (0.104)	Data 0.063 (0.041)	Loss 0.0056 (0.0323)	Acc@1 100.000 (99.257)	Acc@5 100.000 (100.000)\
Epoch: [142][90/94]	Time 0.059 (0.096)	Data 0.000 (0.037)	Loss 0.0347 (0.0323)	Acc@1 98.438 (99.262)	Acc@5 100.000 (100.000)\
 * Acc@1 99.283 Acc@5 100.000\
Test: [0/91]	Time 1.796 (1.796)	Loss 4.6466 (4.6466)	Acc@1 29.688 (29.688)	Acc@5 60.938 (60.938)\
Test: [30/91]	Time 0.158 (0.122)	Loss 3.5788 (3.2289)	Acc@1 39.062 (41.935)	Acc@5 70.312 (69.304)\
Test: [60/91]	Time 0.106 (0.106)	Loss 3.0326 (3.2269)	Acc@1 42.188 (41.419)	Acc@5 62.500 (68.827)\
Test: [90/91]	Time 0.016 (0.089)	Loss 2.5240 (3.1824)	Acc@1 50.000 (42.130)	Acc@5 76.471 (69.330)\
 * Acc@1 42.130 Acc@5 69.330\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.320703622736631e-05]\
Epoch: [143][0/94]	Time 0.930 (0.930)	Data 0.897 (0.897)	Loss 0.0316 (0.0316)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [143][30/94]	Time 0.079 (0.120)	Data 0.000 (0.053)	Loss 0.0356 (0.0310)	Acc@1 98.438 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [143][60/94]	Time 0.068 (0.098)	Data 0.000 (0.032)	Loss 0.0216 (0.0297)	Acc@1 100.000 (99.590)	Acc@5 100.000 (100.000)\
Epoch: [143][90/94]	Time 0.071 (0.091)	Data 0.000 (0.023)	Loss 0.0231 (0.0301)	Acc@1 100.000 (99.605)	Acc@5 100.000 (100.000)\
 * Acc@1 99.616 Acc@5 100.000\
Test: [0/91]	Time 1.124 (1.124)	Loss 2.9659 (2.9659)	Acc@1 48.438 (48.438)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.032 (0.115)	Loss 2.1073 (3.0991)	Acc@1 53.125 (41.633)	Acc@5 79.688 (69.304)\
Test: [60/91]	Time 0.116 (0.103)	Loss 3.0204 (3.1589)	Acc@1 46.875 (41.650)	Acc@5 64.062 (69.083)\
Test: [90/91]	Time 0.037 (0.091)	Loss 2.6806 (3.1638)	Acc@1 44.118 (42.061)	Acc@5 73.529 (69.399)\
 * Acc@1 42.061 Acc@5 69.399\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.260872407680682e-05]\
Epoch: [144][0/94]	Time 1.266 (1.266)	Data 1.236 (1.236)	Loss 0.0375 (0.0375)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [144][30/94]	Time 0.059 (0.124)	Data 0.000 (0.054)	Loss 0.0369 (0.0317)	Acc@1 98.438 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [144][60/94]	Time 0.069 (0.102)	Data 0.000 (0.037)	Loss 0.0587 (0.0334)	Acc@1 98.438 (99.488)	Acc@5 100.000 (100.000)\
Epoch: [144][90/94]	Time 0.064 (0.093)	Data 0.000 (0.029)	Loss 0.0381 (0.0355)	Acc@1 98.438 (99.382)	Acc@5 100.000 (99.966)\
 * Acc@1 99.383 Acc@5 99.967\
Test: [0/91]	Time 1.284 (1.284)	Loss 2.3645 (2.3645)	Acc@1 53.125 (53.125)	Acc@5 75.000 (75.000)\
Test: [30/91]	Time 0.027 (0.103)	Loss 2.6752 (3.0682)	Acc@1 42.188 (43.044)	Acc@5 71.875 (70.817)\
Test: [60/91]	Time 0.042 (0.084)	Loss 4.5923 (3.1819)	Acc@1 32.812 (41.931)	Acc@5 53.125 (69.109)\
Test: [90/91]	Time 0.012 (0.076)	Loss 2.0099 (3.1654)	Acc@1 52.941 (41.957)	Acc@5 82.353 (69.175)\
 * Acc@1 41.957 Acc@5 69.175\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.2037516980200696e-05]\
Epoch: [145][0/94]	Time 1.394 (1.394)	Data 1.334 (1.334)	Loss 0.1042 (0.1042)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)\
Epoch: [145][30/94]	Time 0.078 (0.125)	Data 0.037 (0.056)	Loss 0.0163 (0.0346)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [145][60/94]	Time 0.078 (0.110)	Data 0.000 (0.047)	Loss 0.0290 (0.0370)	Acc@1 100.000 (99.232)	Acc@5 100.000 (100.000)\
Epoch: [145][90/94]	Time 0.066 (0.097)	Data 0.000 (0.033)	Loss 0.0569 (0.0374)	Acc@1 100.000 (99.159)	Acc@5 100.000 (100.000)\
 * Acc@1 99.166 Acc@5 100.000\
Test: [0/91]	Time 1.080 (1.080)	Loss 3.7584 (3.7584)	Acc@1 31.250 (31.250)	Acc@5 62.500 (62.500)\
Test: [30/91]	Time 0.019 (0.111)	Loss 2.6041 (3.1320)	Acc@1 45.312 (42.389)	Acc@5 76.562 (69.254)\
Test: [60/91]	Time 0.282 (0.106)	Loss 3.5977 (3.2047)	Acc@1 32.812 (41.035)	Acc@5 65.625 (68.750)\
Test: [90/91]	Time 0.016 (0.086)	Loss 2.8890 (3.1784)	Acc@1 47.059 (41.974)	Acc@5 70.588 (69.106)\
 * Acc@1 41.974 Acc@5 69.106\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.1492187010036997e-05]\
Epoch: [146][0/94]	Time 1.267 (1.267)	Data 1.219 (1.219)	Loss 0.0109 (0.0109)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [146][30/94]	Time 0.076 (0.125)	Data 0.000 (0.053)	Loss 0.0168 (0.0281)	Acc@1 100.000 (99.597)	Acc@5 100.000 (100.000)\
Epoch: [146][60/94]	Time 0.063 (0.101)	Data 0.000 (0.028)	Loss 0.0231 (0.0291)	Acc@1 100.000 (99.667)	Acc@5 100.000 (100.000)\
Epoch: [146][90/94]	Time 0.066 (0.092)	Data 0.000 (0.019)	Loss 0.0275 (0.0286)	Acc@1 98.438 (99.691)	Acc@5 100.000 (100.000)\
 * Acc@1 99.683 Acc@5 100.000\
Test: [0/91]	Time 1.392 (1.392)	Loss 2.9026 (2.9026)	Acc@1 37.500 (37.500)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.034 (0.114)	Loss 4.0563 (3.1345)	Acc@1 29.688 (41.381)	Acc@5 67.188 (69.002)\
Test: [60/91]	Time 0.023 (0.104)	Loss 3.0396 (3.1666)	Acc@1 37.500 (42.008)	Acc@5 71.875 (68.801)\
Test: [90/91]	Time 0.012 (0.086)	Loss 1.6673 (3.1548)	Acc@1 70.588 (41.940)	Acc@5 79.412 (69.192)\
 * Acc@1 41.940 Acc@5 69.192\
tensor(5.3617, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.0971561867027284e-05]\
Epoch: [147][0/94]	Time 1.138 (1.138)	Data 1.090 (1.090)	Loss 0.0166 (0.0166)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [147][30/94]	Time 0.071 (0.129)	Data 0.000 (0.062)	Loss 0.0104 (0.0357)	Acc@1 100.000 (99.294)	Acc@5 100.000 (100.000)\
Epoch: [147][60/94]	Time 0.080 (0.101)	Data 0.000 (0.033)	Loss 0.0927 (0.0334)	Acc@1 96.875 (99.308)	Acc@5 100.000 (100.000)\
Epoch: [147][90/94]	Time 0.072 (0.092)	Data 0.000 (0.023)	Loss 0.0224 (0.0340)	Acc@1 100.000 (99.330)	Acc@5 100.000 (100.000)\
 * Acc@1 99.333 Acc@5 100.000\
Test: [0/91]	Time 1.171 (1.171)	Loss 3.7942 (3.7942)	Acc@1 34.375 (34.375)	Acc@5 57.812 (57.812)\
Test: [30/91]	Time 0.054 (0.104)	Loss 3.0547 (3.1008)	Acc@1 35.938 (41.230)	Acc@5 64.062 (69.204)\
Test: [60/91]	Time 0.019 (0.094)	Loss 3.4661 (3.1459)	Acc@1 35.938 (42.085)	Acc@5 71.875 (69.134)\
Test: [90/91]	Time 0.012 (0.084)	Loss 4.4113 (3.1609)	Acc@1 29.412 (42.026)	Acc@5 64.706 (69.279)\
 * Acc@1 42.026 Acc@5 69.279\
tensor(5.3618, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1.0474522360006343e-05]\
Epoch: [148][0/94]	Time 1.534 (1.534)	Data 1.497 (1.497)	Loss 0.0344 (0.0344)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)\
Epoch: [148][30/94]	Time 0.071 (0.127)	Data 0.000 (0.058)	Loss 0.0545 (0.0320)	Acc@1 100.000 (99.446)	Acc@5 100.000 (100.000)\
Epoch: [148][60/94]	Time 0.066 (0.101)	Data 0.000 (0.033)	Loss 0.0354 (0.0314)	Acc@1 100.000 (99.488)	Acc@5 100.000 (100.000)\
Epoch: [148][90/94]	Time 0.072 (0.093)	Data 0.000 (0.024)	Loss 0.0134 (0.0314)	Acc@1 100.000 (99.468)	Acc@5 100.000 (100.000)\
 * Acc@1 99.466 Acc@5 100.000\
Test: [0/91]	Time 1.781 (1.781)	Loss 3.2565 (3.2565)	Acc@1 45.312 (45.312)	Acc@5 70.312 (70.312)\
Test: [30/91]	Time 0.030 (0.116)	Loss 3.8681 (3.1833)	Acc@1 39.062 (42.339)	Acc@5 64.062 (69.304)\
Test: [60/91]	Time 0.023 (0.102)	Loss 2.8217 (3.1987)	Acc@1 46.875 (42.239)	Acc@5 73.438 (68.852)\
Test: [90/91]	Time 0.012 (0.088)	Loss 2.6421 (3.1714)	Acc@1 52.941 (42.043)	Acc@5 76.471 (69.054)\
 * Acc@1 42.043 Acc@5 69.054\
tensor(5.3618, device='cuda:0', grad_fn=<SqrtBackward>)\
tensor(0.0049, grad_fn=<SelectBackward>)\
lr: [1e-05]\
Epoch: [149][0/94]	Time 1.096 (1.096)	Data 1.061 (1.061)	Loss 0.0590 (0.0590)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)\
Epoch: [149][30/94]	Time 0.071 (0.120)	Data 0.000 (0.048)	Loss 0.0153 (0.0320)	Acc@1 100.000 (99.395)	Acc@5 100.000 (100.000)\
Epoch: [149][60/94]	Time 0.068 (0.098)	Data 0.000 (0.029)	Loss 0.0124 (0.0322)	Acc@1 100.000 (99.411)	Acc@5 100.000 (100.000)\
Epoch: [149][90/94]	Time 0.067 (0.089)	Data 0.000 (0.021)	Loss 0.0600 (0.0332)	Acc@1 100.000 (99.399)	Acc@5 100.000 (100.000)\
 * Acc@1 99.399 Acc@5 100.000\
Test: [0/91]	Time 1.076 (1.076)	Loss 2.8016 (2.8016)	Acc@1 43.750 (43.750)	Acc@5 73.438 (73.438)\
Test: [30/91]	Time 0.019 (0.117)	Loss 2.6992 (3.1950)	Acc@1 40.625 (41.482)	Acc@5 75.000 (68.851)\
Test: [60/91]	Time 0.342 (0.100)	Loss 2.1569 (3.1789)	Acc@1 51.562 (42.085)	Acc@5 79.688 (68.750)\
Test: [90/91]	Time 0.012 (0.089)	Loss 3.7359 (3.1768)	Acc@1 35.294 (41.974)	Acc@5 67.647 (69.192)\
 * Acc@1 41.974 Acc@5 69.192\
tensor([0.0000, 0.0014, 0.0016, 0.0018, 0.0021, 0.0023, 0.0026, 0.0028, 0.0030,\
        0.0032, 0.0033, 0.0035, 0.0037, 0.0038, 0.0039, 0.0041, 0.0042, 0.0043,\
        0.0043, 0.0044, 0.0045, 0.0045, 0.0046, 0.0046, 0.0047, 0.0047, 0.0047,\
        0.0048, 0.0048, 0.0048, 0.0048, 0.0048, 0.0048, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049,\
        0.0049, 0.0049, 0.0049, 0.0049, 0.0049, 0.0049], grad_fn=<CopySlices>)\
\
}